\documentclass[letterpaper,12pt,openany,leqno]{book}
\usepackage{amssymb} 
\usepackage{amsmath}
\usepackage{fullpage}
\usepackage{perpage}
%\usepackage[T1]{fontenc} %Can be omitted
\usepackage[utf8]{inputenc}
\usepackage[hidelinks,pdfencoding=unicode]{hyperref}
\usepackage{enumitem}
\usepackage{moreenum}
\usepackage[fulladjust]{marginnote}
\usepackage[letterpaper,twoside,margin=1in]{geometry}
\usepackage[perpage,symbol]{footmisc}
\DeclareUnicodeCharacter{274B}{\pmast}
\global\let\cleardoublepage=\clearpage
\usepackage{principia}
\usepackage{graphicx} %This loads commands that flip iota for definite descriptions, Lambda for the universal class, and so on. The (superseded) graphics package should also work here, but is not recommended.
\usepackage{marvosym} %This loads the male and female symbol.
\usepackage{pifont} %This loads the symbols such as the eight-pointed asterisk.
\newcommand{\pagefirst}[1]{\marginnote[\boxed{\text{#1}}]{\boxed{\text{#1}}}}
\newcommand{\pmfd}{\begin{center} \rule{5cm}{.5pt} \end{center}}
\newcommand{\pmhp}{\text{Hp}}
	%Already added to package
\newcommand{\pmbr}[1]{\bigg \lbrack \normalsize #1 \bigg \rbrack} %These are larger brackets for substitution.
\newcommand{\pmithm}{\pmimp\;\pmthm}
\newcommand{\pmprop}{\text{Prop}}
\newcommand{\pmdemi}{\indent \pmdem}
\newcommand{\pmsUb}[2]{\small \begin{array}{c} #1 \\ \hline #2 \end{array}} %This is the substitution command.
\newcommand{\pmsUbb}[4]{\small \begin{array}{c c} #1, & #3 \\ \hline #2, & #4 \end{array}} %This is the substitution command.
\newcommand{\pmsUbbb}[6]{\small \begin{array}{c c c} #1, & #3, & #5 \\ \hline #2, & #4, & #6 \end{array}} %This is the substitution command.
\newcommand{\pmsUbbbb}[8]{\small \begin{array}{c c c c} #1, & #3, & #5, & #7 \\ \hline #2, & #4, & #6, & #8 \end{array}} %This is the substitution command.
\newcommand{\pmSUb}[3]{\normalsize #1 \text{ } \small \begin{array}{c} #2 \\ \hline #3 \end{array}} %This is the substitution command.
\newcommand{\pmSUbb}[5]{\normalsize #1 \text{ } \small \begin{array}{c c} #2, & #4 \\ \hline #3, & #5 \end{array}} %This is the substitution command.
\newcommand{\pmSUbbb}[7]{\normalsize #1 \text{ } \small \begin{array}{c c c} #2, & #4, & #6 \\ \hline #3, & #5, & #7 \end{array}} %This is the substitution command.
\newcommand{\pmSUbbbb}[9]{\normalsize #1 \text{ } \small \begin{array}{c c c c} #1, & #3, & #5, & #7 \\ \hline #2, & #4, & #6, & #8 \end{array}} %This is the substitution command.

%Title
\title{\Huge \textbf{PRINCIPIA MATHEMATICA}}
\author{BY \\ \\ 
	ALFRED NORTH WHITEHEAD, Sc.D., F.R.S. \\ 
	\begin{small} Fellow and late Lecturer of Trinity College, Cambridge \end{small}
	\\ \\ \begin{small} AND \end{small} \\ \\
	BERTRAND RUSSELL, M.A., F.R.S. \\ 
	\begin{small} Lecturer and late Fellow of Trinity College, Cambridge \end{small}}
\date{\vspace{3cm}
	VOLUME I \\
	\vspace{3cm} 
	Critical edition by Landon D. C. Elkind \\ 
	 \begin{small} Killam Postdoctoral Fellow of University of Alberta \end{small} \\
	 \vspace{2cm}
	Version date \today}

\begin{document} 

\maketitle

\frontmatter

\chapter*{\centering PREFACE} \addcontentsline{toc}{part}{PREFACE} \setcounter{page}{5}\pagefirst{v}

THE mathematical treatment of the principles of mathematics, which is the subject of the present work, as arisen from the conjunction of two different studies, both in the main very modern. On the one hand we have the work of analysts and geometers, in the way of formulating an systematising their axioms, and the work of Cantor and others on such matters as the theory of aggregates. On the other hand we have symbolic logic, which, after a necessary period of growth, has now, thanks to Peano and his followers, acquired the technical adaptability and the logical comprehensiveness that are essential to a mathematical instrument for dealing with what have hitherto been the beginnings of mathematics. From the combination of these two studies two results emerge, namely (1) that what were formerly taken, tacitly or explicitly, as axioms, are either unnecessary or demonstrable; (2) that the same methods by which supposed axioms are demonstrated will give valuable results in regions, such as infinite number, which had formerly been regarded as inaccessible to human knowledge. Hence the scope of mathematics is enlarged both by the addition of new subjects and by a backward extension into provinces hitherto abandoned to philosophy. 

The present work was originally intended by us to be comprised in a second volume of \textit{The Principles of Mathematics}. With that object in view, the writing of it was begun in 1900. But as we advanced, it became increasingly evident that the subject is a very much larger one than we had supposed; moreover on many fundamental questions which had been left obscure and doubtful in the former work, we have now arrived at what we believe to be satisfactory solutions. It therefore became necessary to make our book independent of \textit{The Principles of Mathematics}. We have, however, avoided both controversy and general philosophy, and made our statements dogmatic in form. The justification for this is that the chief reason in favour of any theory on the principles of mathematics must always be inductive, \textit{i.e.}\ it must lie in the fact that the theory in question enables us to deduce ordinary mathematics. In mathematics, the greatest degree of self-evidence is usually not to be found quite at the beginning, but at some later point; hence the early deductions, until they reach this point, give reasons rather \pagefirst{vi} for believing the premisses because true consequences follow from them, than for believing the consequences because they follow from the premisses.

In constructing a deductive system such as that contained in the present work, there are two opposite tasks which have to be concurrently performed. On the one hand, we have to analyse existing mathematics, with a view to discovering what premisses are employed, whether these premisses are mutually consistent, and whether they are capable of reduction to more fundamental premisses. On the other hand, when we have decided upon our premisses, we have to build up again as much as may seem necessary of the data previously analysed, and as many other consequences of our premisses as are of sufficient general interest to deserve statement. The preliminary labour of analysis does not appear in the final presentation, which merely sets forth the outcome of the analysis in certain undefined ideas and undemonstrated propositions. It is not claimed that the analysis could not have been carried farther: we have no reason to suppose that it is impossible to find simpler ideas and axioms by means of which those with which we start could be defined and demonstrated. All that is affirmed is that the ideas and axioms with which we start are sufficient, not that they are necessary.

In making deductions from our premisses, we have considered it essential to carry them up to the point where we have proved as much as is true in whatever would ordinarily be taken for granted. But we have not thought it desirable to limit ourselves too strictly to this task. It is customary to consider only particular cases, even when, with our apparatus, it is just as easy to deal with the general case. For example, cardinal arithmetic is usually conceived in connection with \textit{finite} numbers, but its general laws hold equally for infinite numbers, and are most easily proved without any mention of the distinction between finite and infinite. Again, many of the properties commonly associated with series hold of arrangements which are not strictly serial, but have only some of the distinguishing properties of serial arrangements. In such cases, it is a defect in logical style to prove for a particular class of arrangements what might just as well have been proved more generally. An analogous process of generalization is involved, to a greater or less degree, in all our work. We have sought always the most general reasonably simple hypothesis from which any given conclusion could be reached. For this reason, especially in the later parts of the book, the importance of a proposition usually lies in its hypothesis. The conclusion will often be something which, in a certain class of cases, is familiar, but the hypothesis will, whenever possible, be wide enough to admit many cases besides those in which the conclusion is familiar.

We have found it necessary to give very full proofs, because otherwise it is scarcely possible to see what hypotheses are really required, or whether \pagefirst{vii} our results follow from our explicit premisses. (It must be remembered that we are not affirming merely that such and such propositions are true, but also that the axioms stated by us are sufficient to prove them.) At the same time, though full proofs are necessary for the avoidance of errors, and for convincing those who may feel doubtful as to our correctness, yet the proofs of propositions may usually be omitted by a reader who is not specially interested in that part of the subject concerned, and who feels no doubt of our substantial accuracy on the matter in hand. The reader who is specially interested in some particular portion of the book will probably find it sufficient, as regards earlier portions, to read the summaries of previous parts, sections, and numbers, since these give explanations of the ideas involved and statements of the principal propositions proved. The proofs in Part I, Section A, however, are necessary, since in the course of them the manner of stating proofs is explained. The proofs of the earliest propositions are given without the omission of any step, but as the work proceeds the proofs are gradually compressed, retaining however sufficient detail to enable the reader by the help of the references to reconstruct proofs in which no step is omitted.

The order adopted is to some extent optional. For example, we have treated cardinal arithmetic and relation-arithmetic before series, but we might have treated series first. To a great extent, however, the order is determined by logical necessities.

A very large part of the labour involved in writing the present work has been expended on the contradictions and paradoxes which have infected logic and the theory of aggregates. We have examined a great number of hypotheses for dealing with these contradictions; many such hypotheses have been advanced by others, and about as many have been invented by ourselves. Sometimes it has cost us several months' work to convince ourselves that a hypothesis was untenable. In the course of such a prolonged study, we have been led, as was to be expected, to modify our views from time to time; but it gradually became evident to us that some form of the doctrine of types must be adopted if the contradictions were to be avoided. The particular form of the doctrine of types advocated in the present work is not logically indispensable, and there are various other forms equally compatible with the truth of our deductions. We have particularized, both because the form of the doctrine which we advocate appears to us the most probable, and because it was necessary to give at least one perfectly definite theory which avoids the contradictions. But hardly anything in our book would be changed by the adoption of a different form of the doctrine of types. In fact, we may go farther, and say that, supposing some other way of avoiding the contradictions to exist, not very much of our book, except what explicitly deals with types, is dependent upon the adoption of the doctrine of types in any form, so soon as it has been shown (as we claim \pagefirst{viii} that we have shown) that it is \textit{possible} to construct a mathematical logic which does not lead to contradictions. It should be observed that the whole effect of the doctrine of types is negative: it forbids certain inferences which would otherwise be valid, but does not permit any which would otherwise be invalid. Hence we may reasonably expect that the inferences which the doctrine of types permits would remain valid even if the doctrine should be found to be invalid.

Our logical system is wholly contained in the numbered propositions, which are independent of the Introduction and the Summaries. The Introduction and the Summaries are wholly explanatory, and form no part of the chain of deductions. The explanation of the hierarchy of types in the Introduction differs slightly from that given in $\pmast12$ of the body of the work. The later explanation is stricter and is that which is assumed throughout the rest of the book.

The symbolic form of the work has been forced upon us by necessity: without its help we should have been unable to perform the requisite reasoning. It has been developed as the result of actual practice, and is not an excrescence introduced for the mere purpose of exposition. The general method which guides our handling of logical symbols is due to Peano. His great merit consists not so much in his definite logical discoveries nor in the details of his notations (excellent as both are), as in the fact that he first showed how symbolic logic was to be freed from its undue obsession with the forms of ordinary algebra, and thereby made it a suitable instrument for research. Guided by our study of his methods, we have used great freedom in constructing, or reconstructing, a symbolism which shall be adequate to deal with all parts of the subject. No symbol has been introduced except on the ground of its practical utility for the immediate purposes of our reasoning.

A certain number of forward references will be found in the notes and explanations. Although we have taken every reasonable precaution to secure the accuracy of these forward references, we cannot of course guarantee their accuracy with the same confidence as is possible in the case of backward references.

Detailed acknowledgments of obligations to previous writers have not very often been possible, as we have had to transform whatever we have borrowed, in order to adapt it to our system and our notation. Our chief obligations will be obvious to every reader who is familiar with the literature of the subject. In the matter of notation, we have as far as possible followed Peano, supplementing his notation, when necessary, by that of Frege or by that of Schr{\"o}der. A great deal of the symbolism, however, has had to be new, not so much through dissatisfaction with the symbolism of others, as through the fact that we deal with ideas not previously symbolised. In all \pagefirst{ix} questions of logical analysis, our chief debt is to Frege. Where we differ from him, it is largely because the contradictions showed that he, in common with all other logicians ancient and modern, had allowed some error to creep into his premises; but apart from the contradictions, it would have been almost impossible to detect this error. In Arithmetic and the theory of series, our whole work is based on that of Georg Cantor. In Geometry we have had continually before us the writings of v. Staudt, Pasch, Peano, Pieri, and Veblen.

We have derived assistance at various stages from the criticisms of friends, notably Mr G. G. Berry of the Bodleian Library and Mr R. G. Hawtrey.

We have to thank the Council of the Royal Society for a grant towards the expenses of printing of \pounds200 from the Government Publication Fund, and also the Syndics of the University Press who have liberally undertaken the greater portion of the expense incurred in the production of the work. The technical excellence, in all departments, of the University Press, and the zeal and courtesy of its officials, have materially lightened the task of proof-correction. 

The second volume is already in the press, and both it and the third will appear as soon as the printing can be completed.

\bigskip

\hspace{12cm} A. N. W. 

\smallskip

\hspace{12cm} B. R.

\bigskip \bigskip \bigskip \bigskip

Cambridge,

\smallskip

\hspace{20pt} \textit{November}, 1910.

\tableofcontents

\chapter*{\centering \Large ALPHABETICAL LIST OF PROPOSITIONS REFERRED TO BY NAMES} \thispagestyle{empty}

\begin{center}
	\begin{tabular}{l l l l l}
			Name && Number && \\
			Abs && $\pmast2\pmcdot01$. && $\pmthm \pmdott p \pmimp \pmnot p \pmdot \pmimp \pmdot \pmnot p$ \\
			Add && $\pmast1\pmcdot3$. && $\pmthm \pmdott q \pmdot \pmimp \pmdot p \pmor q$ \\
			Ass && $\pmast3\pmcdot35$. && $\pmthm \pmdott p \pmand p \pmimp q \pmdot \pmimp \pmdot q$ \\
			Assoc && $\pmast1\pmcdot5$. && $\pmthm \pmdott p \pmor (q \pmor r) \pmdot \pmimp \pmdot q \pmor (p \pmor r)$ \\
			Comm && $\pmast2\pmcdot04$. && $\pmthm \pmdottt  p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott q \pmdot \pmimp \pmdot p \pmimp r$ \\
			Comp && $\pmast3\pmcdot43$. && $\pmthm \pmdottt  p \pmimp q \pmand p \pmimp r \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmand r$ \\
			Exp && $\pmast3\pmcdot3$. && $\pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmimp r$ \\
			Fact && $\pmast3\pmcdot45$. && $\pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott p \pmand r \pmdot \pmimp \pmdot q \pmand r $ \\
			Id && $\pmast2\pmcdot08$. && $\pmthm \pmdot p \pmimp p$ \\
			Imp && $\pmast3\pmcdot31$. && $\pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r$ \\
			Perm && $\pmast1\pmcdot4$. && $\pmthm \pmdott p \pmor q \pmdot \pmimp \pmdot q \pmor p$ \\
			Simp && $\pmast2\pmcdot02$. && $\pmthm \pmdott q \pmdot \pmimp \pmdot p \pmimp q$ \\
			'' && $\pmast3\pmcdot26$. && $\pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot p$ \\
			'' && $\pmast3\pmcdot27$. && $\pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot q$ \\
			Sum && $\pmast1\pmcdot6$. && $\pmthm \pmdott q \pmimp r \pmdot \pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot p \pmor r$ \\
			Syll && $\pmast2\pmcdot05$. && $\pmthm \pmdottt q \pmimp r \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r$ \\
			'' && $\pmast2\pmcdot06$. && $\pmthm \pmdottt p \pmimp r \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r$ \\
			'' && $\pmast3\pmcdot33$. && $\pmthm \pmdott p \pmimp q \pmand q \pmimp r \pmdot \pmimp \pmdot p \pmimp r$ \\
			'' && $\pmast3\pmcdot34$. && $\pmthm \pmdott q \pmimp r \pmand p \pmimp q \pmdot \pmimp \pmdot p \pmimp r$ \\
			Taut && $\pmast1\pmcdot2$. && $\pmthm \pmdott p \pmor p \pmdot \pmimp \pmdot p$ \\
			Trans && $\pmast2\pmcdot03$. && $\pmthm \pmdott p \pmimp \pmnot q \pmdot \pmimp \pmdot q \pmimp \pmnot p$ \\
			'' && $\pmast2\pmcdot15$. && $\pmthm \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp p$ \\
			'' && $\pmast2\pmcdot16$. && $\pmthm \pmdott p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot p$ \\
			'' && $\pmast2\pmcdot17$. && $\pmthm \pmdott \pmnot q \pmimp \pmnot p \pmdot \pmimp \pmdot p \pmimp q$ \\
			'' && $\pmast3\pmcdot37$. && $\pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmimp \pmdott p \pmand \pmnot r \pmdot \pmimp \pmdot \pmnot q$ \\
			'' && $\pmast4\pmcdot1$. && $\pmthm \pmdott p \pmimp q \pmdot \pmiff \pmdot \pmnot q \pmimp \pmnot p$ \\
			'' && $\pmast4\pmcdot11$. && $\pmthm \pmdott p \pmiff q \pmdot \pmiff \pmdot \pmnot p \pmiff \pmnot q$ \\
	\end{tabular}
\end{center} 

\chapter*{\centering \Large ERRATA} \thispagestyle{empty}
p. 14, line 2, \textit{for} ``states'' \textit{read} ``allows us to infer.'' \\
p. 14, line 7, \textit{after} ``$\pmast3\pmcdot03$'' \textit{insert} ``$\pmast1\pmcdot7$, $\pmast1\pmcdot71$, and $\pmast1\pmcdot72$.''\\
p. 15, last line but one, \textit{for} ``function of $\pmpf{\phi}{\pmhat{x}}$'' \textit{read} ``function $\pmpf{\phi}{\pmhat{x}}$.''\\
p. 34, line 15, \textit{for} ``$x$'' \textit{read} ``$R$.''\\
p. 68, line 20, \textit{for} ``classes'' \textit{read} ``classes of classes.''\\
p. 86, line 2, \textit{after} ``must'' \textit{insert} ``neither be nor.''\\
p. 91, line 2, \textit{delete} ``and in $\pmast3\pmcdot03$.''\\
p. 103, line 7, \textit{for} ``assumption'' \textit{read} ``assertion.''\\
p. 103, line 7, \textit{for} ``$q$'' \textit{read} ``$r$.''\\
p. 218, last line but one, \textit{for} ``$\pmcnull$'' \textit{read} ``$\pmrnull$'' [owing to brittleness of the type, the \\
\indent \indent \indent same error is liable to occur elsewhere].\\
p. 382, last line but one, \textit{delete} ``in the theory of selections ($\pmast88\pmcdot92$) and.''\\
p. 487, line 13, \textit{for} ``$\pmast95$'' \textit{read} ``$\pmast94$.''\\
p. 503, line 14, \textit{for} ``$\pmast88\pmcdot38$'' \textit{read} ``$\pmast88\pmcdot36$.''

\mainmatter

\chapter*{\centering INTRODUCTION} \addcontentsline{toc}{chapter}{INTRODUCTION} \pagefirst{1}

THE mathematical logic which occupies Part I of the present work has been constructed under the guidance of three different purposes. In the first place, it aims at effecting the greatest possible analysis of the ideas with which it deals and of the processes by which it conducts demonstrations, and at diminishing to the utmost the number of the undefined ideas and undemonstrated propositions (called respectively \textit{primitive ideas} and \textit{primitive propositions}) from which it starts. In the second place it is framed with a view to the perfectly precise expression, in its symbols, of mathematical propositions: to secure such expression, and to secure it in the simplest and most convenient notation possible, is the chief motive in the choice of topics. In the third place the system is specially framed to solve the paradoxes which, in recent years, have troubled students of symbolic logic and the theory of aggregates; it is believed that the theory of types, as set forth in what follows, leads both to the avoidance of contradictions, and to the detection of the precise fallacy which has given rise to them. 

Of the above three purposes, the first and third often compel us to adopt methods, definitions, and notations which are more complicated or more difficult than they would be if we had the second object alone in view. This applies especially to the theory of descriptive expressions ($\pmast14$ and $\pmast30$) and to the theory of classes and relations ($\pmast20$ and  $\pmast21$). On these two points, and to a lesser degree on others, it has been found necessary to make some sacrifice of lucidity to correctness. The sacrifice is, however, in the main only temporary: in each case, the notation ultimately adopted though its real meaning is very complicated, has an apparently simple meaning which, except at certain crucial points, can without danger be substituted in thought for the real meaning. It is therefore convenient, in a preliminary explanation of the notation, to treat these apparently simple meanings as primitive ideas, \textit{i.e.}\ as ideas introduced without definition. When the notation has grown more or less familiar, it is easier to follow the more complicated explanations which we believe to be more correct. In the body of the work, where it is necessary to it here rigidly to the strict logical order, \pagefirst{2} the easier order of development could not be adopted; it is therefore given in the Introduction. The explanations given in Chapter I of the Introduction are such as place lucidity before correctness; the full explanations are partly supplied in succeeding Chapters of the Introduction, partly given in the body of the work. 

Use of symbolism, other than that of words, in all parts of the book which aim at embodying strictly accurate demonstrative reasoning, has been forced on us by the consistent pursuit of the above three purposes. The reasons for this extension of symbolism beyond the familiar regions of number and allied ideas are many: 

\begin{enumerate}[wide, label=(\arabic*), labelwidth=!, labelindent=20pt]
	\item The ideas here employed are more abstract than those familiarly considered in language. Accordingly there are no words which are used mainly in the exact consistent senses which are required here. Any use of words would require unnatural limitation to their ordinary meaning, which would be in fact more difficult to remember consistently then are the definitions of entirely new symbols. 
	\item The grammatical structure of language is adapted to a wide variety of usages. Thus it possesses no unique simplicity in representing the few simple, though highly abstract, processes and ideas are rising in the deductive trains of reasoning employed here. In fact the very abstract simplicity of the ideas of this work defeats language. Language can represent complex ideas bored easily. The proposition ``a whale is big'' represents language at its best, giving terse expression to a complicated fact; while the true analysis of ``one is a number'' leads, in language, to an intolerable prolixity. Accordingly terseness is gained by using a symbolism especially designed to represent the ideas and processes of deduction which occur in this work.
	\item The adaptation of the rules of the symbolism to the processes of deduction aids the intuition in regions too abstract for the imagination readily to present to the mind the true relation between the ideas employed. For various collocations of symbols become familiar as representing important collocations of ideas; and in turn the possible relations---according to the rules of the symbolism---between these collocations of symbols become familiar, and these further collocations represent still more complicated relations between the abstract ideas. And thus the mind is finally led to construct rains of reasoning in regions of thought in which the imagination would be entirely unable to sustain itself without symbolic help. Ordinary language yields no such help. Its grammatical structure does not represent uniquely the relations between the ideas involved. Thus, ``a whale is big'' and ``one is a number'' both look alike, so that the eye gives no help to the imagination.
	\item \pagefirst{3} The terseness of the symbolism enables a whole proposition to be represented to the eyesight as one whole, or at most in two or three parts divided where the natural breaks, represented in the symbolism, occur. This is a humble property, but is in fact a very important in connection with the advantages enumerated under the heading (3). 
	\item The attainment of the first-mentioned object of this work, namely the complete enumeration of all the ideas and steps in reasoning employed in mathematics, necessitates both terseness and the presentation of each proposition with the maximum of formality in a form is characteristic of itself as possible. 
\end{enumerate}

Further light on the methods and symbolism of this book is thrown by a slight consideration of the limits to their useful employment:

\begin{enumerate}[wide, label=(\greek*), labelwidth=!, labelindent=20pt]
	\item Most mathematical investigation is concerned not with the analysis of the complete process of reasoning, but with the presentation of such an abstract of the proof as is sufficient to convince a properly instructed mind. For such investigations that detailed presentation of steps in reasoning is of course unnecessary, provided that the detail is carried far enough to guard against error. In this connection it may be remembered that the investigations of Weierstrass and others of the same school have shown that, even in the common topics of mathematical thought, much more detail is necessary than previous generations of mathematicians had anticipated. 
	\item In proportion as the imagination works easily in any region of thought, symbolism (except for the express purpose of analysis) becomes only necessary as a convenient shorthand writing to register results obtained without its help. It is a subsidiary of object of this work to show that, with the aid of symbolism, deductive reasoning can be extended to regions of thought not usually supposed amenable to mathematical treatment. And until the ideas of such branches of knowledge have become more familiar, the detailed type of reasoning, which is also required for the analysis of the steps, is appropriate to the investigation of the general truth concerning these subjects. 
\end{enumerate}

\renewcommand{\thechapter}{\Roman{chapter}} %\renewcommand{\thechapter}{\arabic{chapter}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}} %\renewcommand{\thefootnote}{\arabic{footnote}}

\chapter*{\centering CHAPTER I. \\ PRELIMINARY EXPLANATIONS OF IDEAS AND NOTATIONS}  \addcontentsline{toc}{chapter}{CHAPTER I. PRELIMINARY EXPLANATIONS OF IDEAS AND NOTATIONS} \pagefirst{4}

THE notation adopted in the present work is based upon that of Peano, and the following explanations are to some extent modeled on those which he prefixes to his \textit{Formulario Mathematico}. His use of dots as brackets is adopted, and so are many of his symbols. 

\textit{Variables}. The idea of a variable, as it occurs in the present work, is more general than that which is explicitly used in ordinary mathematics. in ordinary mathematics, a variable generally stands for an undetermined number or quantity. In mathematical logic, any symbol whose meaning is not determinate it is called a \textit{variable}, and the various determinations of which its meaning is susceptible are called the \textit{values} of the variable. The values may be any set of entities, propositions, functions, classes or relations, according to circumstances. If a statement is made about ``Mr A'' and Mr B,'' ``Mr A'' and ``Mr B'' are variables whose values are confined to men. A variable may either have a conventionally-assigned range of values or may (in the absence of any indication of the range of values) have as the range of its values all determinations which render the statement in which it occurs significant. Thus when a text-book of logic asserts that ``$A$ is $A$,'' without any indication as to what $A$ may be, what is meant is that \textit{any} statement of the form ``$A$ is $A$'' is true. We may call a variable \textit{restricted} when its values are confined to some only of those of which it is capable; otherwise, we shall call it \textit{unrestricted}. Thus when an unrestricted variable occurs, it represents any object such that the statement concerned can be made significantly (\textit{i.e.}\ either truly or falsely) concerning that object for the purposes of logic, the unrestricted variable is more convenient than the restricted variable, and we shall always employ it. We shall find the unrestricted variable is still subject to limitations imposed by the manner of its occurrence, \textit{i.e.}\ things which can be said significantly concerning a proposition cannot be said significantly concerning a class or a relation, and so on. But the limitations to which the unrestricted variable is subject do not need to be explicitly indicated since they are the limits of significance of the statement in which the variable occurs, and are therefore intrinsically determined by this statement. This will be more fully explained later\footnote{Cf. Chapter II of the Introduction.}.

\pagefirst{5} To sum up, the three salient facts connected with the use of the variable are: (1) that a variable is ambiguous in its denotation and accordingly undefined: (2) that a variable preserves a recognizable identity in various occurrences throughout the same context, so that many variables can occur together in the same context each with its separate identity: and (3) that either the range of possible determinations of two variables may be the same, so that a possible determination of one variable is also a possible determination of the other, or the ranges of two variables may be different, so that, if a possible determination of one variable is given to the other, the resulting complete phrase is meaningless instead of becoming a complete unambiguous proposition (true or false) as would be the case if all variables in it had been given any \textit{suitable} determinations.

\textit{The uses of various letters}. Variables will be denoted by single letters, and so will certain constants; but a letter which has once been assigned to a constant by a definition must not afterwards be used to denote a variable. The small letters of the ordinary alphabet will all be used for variables, except $p$ and $s$ after $\pmast40$, in which constant meanings are assigned to these two letters. The following capital letters will receive constant meanings: $B$, $C$, $D$, $E$, $F$, $I$ and $J$. Among small Greek letters, we shall give constant meanings to $\varepsilon$, $\iota$, and (at a later stage) to $\eta$, $\theta$, and $\omega$. Certain Greek capitals will from time to time be introduced for constants, but Greek capitals will not be used for variables. Of the remaining letters, $p$, $q$, $r$ will be called \textit{propositional letters}, and will stand for variable propositions (except that, from $\pmast40$ onwards, $p$ must not be used for a variable); $f$, $g$, $\phi$, $\chi$, $\theta$ and (until $\pmast33$) $F$ will be called \textit{functional letters}, and will be used for variable functions.

The small Greek letters not already mentioned will be used for variables whose values are classes, and will be referred to simply as \textit{Greek letters}. Ordinary capital letters not already mentioned will be used for variables whose values are relations, and will be referred to simply as \textit{capital letters}. Ordinary small letters other than $p$, $q$, $r$, $s$, $f$, $g$ will be used for variables whose values are not known to be functions, classes, or relations; these letters will be referred to simply as \textit{small Latin letters}. 

After the early part of the work, variable propositions and variable functions will hardly ever occur. We shall then have three main kinds of variables: variable classes, denoted by small Greek letters; variable relations, denoted by capitals; and variables not given as necessarily classes or relations, which will be denoted by small Latin letters. 

In addition to this usage of small Greek letters for variable classes, capital letters for variable relations, small Latin letters for variables of type wholly undetermined by the context (these arise from the possibility of \pagefirst{6} ``systematic ambiguity,'' explained later in the explanations of the theory of types), the reader need only remember that all letters represent variables, unless they have been defined as constants in some previous place in the book. In general the structure of the context determines the scope of the variables contained in it; but the special indication of the nature of the variables employed, as here proposed, saves considerable labour of thought.

\textit{The fundamental functions of propositions}. An aggregation of propositions, considered as wholes not necessarily unambiguously determined, into a single proposition more complex than its constituents, is a function \textit{with propositions as arguments}. The general idea of such an aggregation of propositions, or of variables representing propositions, will not be employed in this work. But there are four special cases which are of fundamental importance, since all the aggregations of subordinate propositions into one complex proposition which occur in the sequel are formed out of them step by step.

They are (1) the Contradictory Function, (2) the Logical Sum, or Disjunctive Function, (3) the Logical Product, or Conjunctive Function, (4) the Implicative Function. These functions in the sense in which they are required in this work are not all independent; and if two of them are taken as primitive undefined ideas, the other two can be defined in terms of them. It is to some extent---though not entirely---arbitrary as to which functions are taken as primitive. Simplicity of primitive ideas and symmetry of treatment seem to be gained by taking the first two functions as primitive ideas. 

The Contradictory Function with argument $p$, where $p$ is any proposition, is the proposition which is the contradictory of $p$, that is, the proposition asserting that $p$ is not true. This is denoted by $\pmnot p$. Thus $\pmnot p$ is the contradictory function with $p$ as argument and means the negation of the proposition $p$. It will also be referred to as the proposition not-$p$. Thus $\pmnot p$ means not-$p$, which means the negation of $p$. 

The Logical Sum is a propositional function with two arguments $p$ and $q$, and is the proposition asserting $p$ or $q$ disjunctively, that is, asserting that at least one of the two $p$ and $q$ is true. This is denoted by $p \pmor q$. Thus $p \pmor q$ is the logical sum with $p$ and $q$ as arguments. It is also called the logical sum of $p$ and $q$. Accordingly $p \pmor q$ means that at least $p$ or $q$ is true, not excluding the case in which both are true.

The Logical Product is a propositional function with two arguments $p$ and $q$, and is the proposition asserting $p$ and $q$ conjunctively, that is, asserting that both $p$ and $q$ are true. This is denoted by $p \pmand q$, or---in order to make the dots act as brackets in a way to be explained immediately---by $p \pmandd q$, or by $p \pmanddd q$, or by $p \pmandddd q$, Thus $p \pmand q$ is the logical product with \pagefirst{7} $p$ and $q$ as arguments. It is also called the logical product of $p$ and $q$. Accordingly $p \pmand q$ means that both $p$ and $q$ are true. It is easily seen that this function can be defined in terms of the two preceding functions. For when $p$ and $q$ are both true it must be false that either $\pmnot p$ or $\pmnot q$ is true. Hence in this book $p \pmand q$ is merely a shortened form of symbolism for
\[ 
\pmnot (\pmnot p \pmor \pmnot q).
\]
If any further idea attaches to the proposition ''both $p$ and $q$ are true,''
it is not required here.

The Implicative Function is a propositional function with two arguments $p$ and $q$, and is the proposition that either not-$p$ or $q$ is true, that is, it is the proposition $\pmnot p \pmor q$. Thus if $p$ is true, $\pmnot p$ is false, and accordingly the only alternative left by the proposition $\pmnot p \pmor q$ is that $q$ is true. In other words if $p$ and $\pmnot p \pmor q$ are both true, then $q$ is true. In this sense the proposition $\pmnot p \pmor q$ will be quoted as stating that $p$ implies $q$. The idea contained in this propositional function is so important that it requires a symbolism which with direct simplicity represents the proposition as connecting $p$ and $q$ without the intervention of $\pmnot p$. But ``implies'' as used here expresses nothing else than the connection between $p$ and $q$ also expressed by the disjunction ``not-$p$ or $q$.'' The symbol employed for ``$p$ implies q,'' \textit{i.e.}\ for ``$\pmnot p \pmor q$,'' is ``$p \pmimp q$.'' This symbol may also be read ``if $p$, then $q$.'' The association of implication with the use of an apparent variable produces an extension called ``formal implication.'' This is explained later: it is an idea derivative from ``implication'' as here defined. When it is necessary explicitly to discriminate ``implication'' from ``formal implication,'' it is called ``material implication.'' Thus ``material implication'' is simply ``implication'' as here defined. The process of inference, which in common usage is often confused with implication, is explained immediately.

These four functions of propositions are the fundamental constant (\textit{i.e.}\ definite) propositional functions with \textit{propositions as arguments}, and all other constant propositional functions with propositions as arguments, so far as they are required in the present work, are formed out of them by successive steps. No \textit{variable} propositional functions of this kind occur in this work.

\textit{Equivalence}. The simplest example of the formation of a more complex function of propositions by the use of these four fundamental forms is furnished by ``equivalence.'' Two propositions $p$ and $q$ are said to be ``equivalent'' when $p$ implies $q$ and $q$ implies $p$. This relation between $p$ and $q$ is denoted by ``$p \pmiff q$.'' Thus ``$p \pmiff q$'' stands for ``$(p \pmimp q) \pmdot (q \pmimp p)$.'' It is easily seen that two propositions are equivalent when, and only when, they are both true or are both false. Equivalence rises in the scale of importance when we come to ``formal implication'' and thus to ``formal equivalence.'' It must not be supposed that two propositions which are equivalent are in \pagefirst{8} any sense identical or even remotely concerned with the same topic. Thus ``Newton was a man'' and ``the sun is hot'' are equivalent as being both true, and ``Newton was not a man'' and ``the sun is cold'' are equivalent as being both false. But here we have anticipated deductions which follow later from our formal reasoning. Equivalence in its origin is merely mutual implication as stated above.

\textit{Truth-values}. The ``truth-value'' of a proposition is truth if it is true, and falsehood if it is false\footnote{This phrase is due to Frege}. It will be observed that the truth-values of $p \pmor q$, $p \pmand q$, $p \pmimp q$, $\pmnot p$, $p \pmiff q$ depend only upon those of $p$ and $q$, namely the truth-value of ``$p \pmor q$'' is truth if the truth-value of either p or q is truth, and is falsehood otherwise; that of ``$p \pmand q$'' is truth if that of both $p$ and $q$ is truth, and is falsehood otherwise; that of ``$p \pmimp q$'' is truth if either that of $p$ is falsehood or that of $q$ is truth; that of ``$\pmnot p$'' is the opposite of that of $p$; and that of ``$p \pmiff q$'' is truth if $p$ and $q$ have the same truth-value, and is falsehood otherwise. Now the only ways in which propositions will occur in the present work are ways derived from the above by combinations and repetitions. Hence it is easy to see (though it cannot be formally proved except in each particular case) that if a proposition p occurs in any proposition $f(p)$ which we shall ever have occasion to deal with, the truth-value of $f(p)$ will depend, not upon the particular proposition $p$, but only upon its truth-value; \textit{i.e.}\ if $p \pmiff q$, we shall have $f(p) \pmiff f(q)$. Thus whenever two
propositions are known to be equivalent, either may be substituted for the other in any formula with which we shall have occasion to deal.

We may call a function $f(p)$ a ``truth-function'' when its argument $p$ is a proposition, and the truth-value of $f(p)$ depends only upon the truth-value of $p$. Such functions are by no means the only common functions of propositions. For example, ``$A$ believes $p$'' is a function of $p$ which will vary its truth-value for different arguments having the same truth-value: $A$ may believe one true proposition without believing another, and may believe one false proposition without believing another. Such functions are not excluded from our consideration, and are included in the scope of any general propositions we may make about functions; but the particular functions of propositions which we shall have occasion to construct or to consider explicitly are .all truth-functions. This fact is closely connected with a characteristic of mathematics, namely, that mathematics is always concerned with extensions rather than intensions. The connection, if not now obvious,
will become more so when we have considered the theory of classes and relations.

\textit{Assertion-sign}. The sign ``$\pmthm$,'' called the ``assertion-sign,'' means that what follows is asserted. It is required for distinguishing a complete proposition, which we assert, from any subordinate propositions contained in it but \pagefirst{9} not asserted. In ordinary written language a sentence contained between full stops denotes an asserted proposition, and if it is false the book is in error. The sign ``$\pmthm$'' prefixed to a proposition serves this same purpose in our symbolism. For example, if ``$\pmthm (p \pmimp p)$'' occurs, it is to be taken as a complete assertion convicting the authors of error unless the proposition ``$p \pmimp p$'' is true (as it is). Also a proposition stated in symbols without this sign ``$\pmthm$'' prefixed is not asserted, and is merely put forward for consideration, or as a subordinate part of an asserted proposition.

\textit{Inference}. The process of inference is as follows: a proposition ``$p$'' is asserted, and a proposition ``$p$ implies $q$'' is asserted, and then as a sequel the proposition ``$q$'' is asserted. The trust in inference is the belief that if the two former assertions are not in error, the final assertion is not in error. Accordingly whenever, in symbols, where $p$ and $q$ have of course special determinations,
\[ 
	\text{``}\pmthm p\text{''} \text{ and } \text{``}\pmthm (p \pmimp q)\text{''}
\]
have occurred, then ``$\pmthm q$'' will occur if it is desired to put it on record. The process of the inference cannot be reduced to symbols. Its sole record is the occurrence of ``$\pmthm q$.'' It is of course convenient, even at the risk of repetition, to write ``$\pmthm p$'' and ``$\pmthm (p \pmimp q)$'' in close juxtaposition before proceeding to ``$\pmthm q$'' as the result of an inference. When this is to be done, for the sake of drawing attention to the inference which is being made, we shall write instead
\[ 
	\text{``} \pmthm p \;\pmimp\; \pmthm q,\text{''}
\]
which is to be considered as a mere abbreviation of the threefold statement
\[ 
	\text{``} \pmthm p\text{''} \text{ and } \text{``} \pmthm (p \pmimp q)\text{''} \text{ and } \text{``} \pmthm q.\text{''}
\]
Thus ``$\pmthm p \;\pmimp\; \pmthm q$'' may be read ``$p$, therefore $q$,'' being in fact the same abbreviation, essentially, as this is; for ``$p$, therefore $q$'' does not explicitly state, what is part of its meaning, that $p$ implies $q$. An inference is the dropping of a true premiss; it is the dissolution of an implication.

\textit{The use of dots}. Dots on the line of the symbols have two uses, one to bracket off propositions, the other to indicate the logical product of two propositions. Dots immediately preceded or followed by ``$\pmor$'' or ``$\pmimp$'' or ``$\pmiff$'' or ``$\pmthm$,'' or by ``$(x)$,'' ``$(x, y)$,'' ``$(x, y, z)$''... or ``$\pmsome{x}$,'' ``$\pmsome{x, y}$,'' ``$\pmsome{x,y,z}$''... or ``$[\pmdsc{x}(\phi x)]$'' or ``$[\pmdscf{R}{y}]$'' or analogous expressions, serve to bracket off a proposition; dots occurring otherwise serve to mark a logical product. The general principle is that a larger number of dots indicates an outside bracket, a smaller number indicates an inside bracket. The exact rule as to the scope of the bracket indicated by dots is arrived at by dividing the occurrences of dots into three groups which we will name I, II, and III. Group I consists of dots adjoining a sign of implication $(\pmimp)$ or of equivalence $(\pmiff)$ or of disjunction $(\pmor)$ or of equality by definition $(\pmiddf \text{ Df})$. Group II consists of dots following brackets indicative of an apparent variable, such as $(x)$ or $(x, y)$ or $\pmsome{x}$ or \pagefirst{10} $\pmsome{x,y}$ or $[\pmdsc{x}(\phi x)]$ or analogous expressions\footnote{The meaning of these expressions will be explained later, and examples of the use of dots in connection with them will be given on pp. 17, 18.}. Group III consists of dots which stand between propositions in order to indicate a logical product. Group I is of greater force than Group II, and Group II than Group III. The scope of the bracket indicated by any collection of dots extends backwards or forwards beyond any smaller number of dots, or any equal number from a group of less force, until we reach either the end of the asserted proposition or a greater number of dots or an equal number belonging to a group of equal or superior force. Dots indicating a logical product have a scope which works both backwards and forwards; other dots only work away from the adjacent sign of disjunction, implication, or equivalence, or forward from the adjacent symbol of one of the other kinds enumerated in Group II.

Some examples will serve to illustrate the use of dots. 

``$p \pmor q \pmdot \pmimp \pmdot q \pmor p$'' means the proposition ```$p$ or $q$' implies `$q$ or $p$.''' When we assert this proposition, instead of merely considering it, we write
\[
	\text{``} \pmthm \pmdott p \pmor q \pmdot \pmimp \pmdot q \pmor p, \text{''}
\]
where the two dots after the assertion-sign show that what is asserted is the whole of what follows the assertion-sign, since there are not as many as two dots anywhere else. If we had written ``$p \pmdott \pmor \pmdott q \pmdot \pmimp \pmdot q \pmor p$,'' that would mean the proposition ``either $p$ is true, or $q$ implies `$q$ or $p$.''' If we wished to assert this, we should have to put three dots after the assertion-sign. If we had written ``$p \pmor q \pmdot \pmimp \pmdot q \pmdott \pmor \pmdott p$,'' that would mean the proposition ``either `$p$ or $q$' implies $q$, or $p$ is true.'' The forms ``$p\pmdot \pmor \pmdot q \pmdot \pmimp \pmdot q \pmor p$'' and ``$p \pmor q \pmdot \pmimp \pmdot q \pmdot \pmor \pmdot  p$'' have no meaning.

``$p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r$'' will mean ``if $p$ implies $q$, then if $q$ implies $r$, $p$ implies $r$.'' If we wish to assert this (which is true) we write
\[
	\text{``}\pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r.\text{''}
\]
Again ``$p \pmimp q \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdot p \pmimp r$'' will mean ``if `$p$ implies $q$' implies `$q$ implies $r$,' then $p$ implies $r$.'' This is in general untrue. (Observe that ``$p \pmimp q$'' is sometimes most conveniently read as ``$p$ implies $q$,'' and sometimes as ``if $p$, then $q$.'') ``$p \pmimp q \pmdot q \pmimp r \pmdot \pmimp \pmdot p \pmimp r$'' will mean ``if $p$ implies $q$, and $q$ implies $r$, then $p$ implies $r$.'' In this formula, the first dot indicates a logical product; hence the scope of the second dot extends backwards to the  beginning of the proposition. ``$p \pmimp q \pmdott q \pmimp  r \pmdot \pmimp \pmdot p \pmimp r$'' will mean ``$p$ implies $q$; and if $q$ implies $r$, then $p$ implies $r$.'' (This is not true in general.) Here the two dots indicate a logical product; since two dots do not occur anywhere else, the scope of these two dots extends backwards to the beginning of the proposition, and forwards to the end.

``$p \pmor q \pmdot \pmimp \pmdottt p \pmdot \pmor \pmdot q \pmimp r \pmdott \pmimp \pmdot p \pmor r$'' will mean ``if either $p$ or $q$ is true, then if either $p$ or `$q$ implies $r$' is true, it follows that either $p$ or $r$ is true.'' \pagefirst{11} If this is to be asserted, we must put four dots after the assertion-sign, thus:
\[
	\text{``}\pmthm \pmdotttt p \pmor q \pmdot \pmimp \pmdottt p \pmdot \pmor \pmdot q \pmimp r \pmdott \pmimp \pmdot p \pmor r.\text{''} 
\]
(This proposition is proved in the body of the work; it is $\pmast2\pmcdot75$.) If we wish to assert (what is equivalent to the above) the proposition: ``if either $p$ or $q$ is true, and either $p$ or `$q$ implies $r$' is true, then either p or r is true,'' we  write
\[
	\text{``}\pmthm \pmdottt p \pmor q \pmdott p \pmdot \pmor \pmdot q \pmimp r \pmdott \pmimp \pmdot p \pmor r.\text{''}
\]
Here the first pair of dots indicates a logical product, while the second pair does not. Thus the scope of the second pair of dots passes over the first pair, and back until we reach the three dots after the assertion-sign. 

Other uses of dots follow the same principles, and will be explained as they are introduced. In reading a proposition, the dots should be noticed first, as they show its structure. In a proposition containing several signs of implication or equivalence, the one with the greatest number of dots before or after it is the principal one: everything that goes before this one is stated by the proposition to imply or be equivalent to everything that comes after it.

\textit{Definitions}. A definition is a declaration that a certain newly-introduced symbol or combination of symbols is to mean the same as a certain other combination of symbols of which the meaning is already known. Or, if the defining combination of symbols is one which only acquires meaning when combined in a suitable manner with other symbols\footnote{This case will be fully considered in Chapter III of the Introduction. It need not further concern us at present.}, what is meant is that any combination of symbols in which the newly-defined symbol or combination of symbols occurs is to have that meaning (if any) which results from substituting the defining combination of symbols for the newly-defined symbol or combination of symbols wherever the latter occurs. We will give the names of \textit{definiendum} and \textit{definiens} respectively to what is defined and to that which it is defined as meaning. We express a definition by putting the \textit{definiendum} to the left and the \textit{definiens} to the right, with the sign ``$=$'' between, and the letters ``Df'' to the right of the \textit{definiens}. It is to be understood that the sign ``$=$'' and the letters ``Df'' are to be regarded as together forming one symbol. The sign ``$=$'' without the letters ``Df '' will have a different meaning, to be explained shortly.

An example of a definition is
\[ 
	p \pmimp q \pmdot = \pmdot \pmnot p \pmor q \pmdf.
\]
It is to be observed that a definition is, strictly speaking, no part of the subject in which it occurs. For a definition is concerned wholly with the symbols, not with what they symbolise. Moreover it is not true or false, being the expression of a volition, not of a proposition. (For this reason, \pagefirst{12} definitions are not preceded by the assertion-sign.) Theoretically, it is unnecessary ever to give a definition: we might always use the \textit{definiens} instead, and thus wholly dispense with the \textit{definiendum}. Thus although we employ definitions and do not define ``definition,'' yet ``definition'' does not appear among our primitive ideas, because the definitions are no part of our subject, but are, strictly speaking, mere typographical conveniences. Practically, of course, if we introduced no definitions, our formulae would very soon become so lengthy as to be unmanageable; but theoretically, all definitions are superfluous.

In spite of the fact that definitions are theoretically superfluous, it is nevertheless true that they often convey more important information than is contained in the propositions in which they are used. This arises from two causes. First, a definition usually implies that the \textit{definiens} is worthy of careful consideration. Hence the collection of definitions embodies our choice of subjects and our judgment as to what is most important. Secondly, when what is defined is (as often occurs) something already familiar, such as cardinal or ordinal numbers, the definition contains an analysis of a common idea, and may therefore express a notable advance. Cantor's definition of the continuum illustrates this: his definition amounts to the statement that what he is defining is the object which has the properties commonly associated with the word ``continuum,'' though what precisely constitutes these properties had not before been known. In such cases, a definition is a ``making definite'': it gives definiteness to an idea which had previously been more or less vague.

For these reasons, it will be found, in what follows, that the definitions are what is most important, and what most deserves the reader's prolonged attention.

Some important remarks must be made respecting the variables occurring in the \textit{definiens} and the \textit{definiendum}. But these will be deferred till the notion of an ``apparent variable'' has been introduced, when the subject can be considered as a whole.

\textit{Summary of preceding statements}. There are, in the above, three primitive ideas -which are not'' defined'' but only descriptively explained. Their primitiveness is only relative to our exposition of logical connection and is not absolute; though of course such an exposition gains in importance according to the simplicity of its primitive ideas. These ideas are symbolised by ``$\pmnot p$'' and ``$p \pmor q$,'' and by ``$\pmthm$'' prefixed to a proposition.

Three definitions have been introduced:
\begin{center}
\begin{tabular}{c | c}
	\multicolumn{1}{l}{$p \pmdot q \pmdot = \pmdot \pmnot(\pmnot p \pmor \pmnot q)$} & Df, \\
	\multicolumn{1}{l}{$p \pmimp q \pmdot = \pmdot \pmnot p \pmor q$} & Df, \\
	\multicolumn{1}{l}{$p \pmiff q \pmdot = \pmdot \pmnot(\pmnot p \pmor \pmnot q)$} & Df.
\end{tabular}
\end{center}
\pagefirst{13} \textit{Primitive propositions.} Some propositions must be assumed without proof, since all inference proceeds from propositions previously asserted. These, as far as they concern the functions of propositions mentioned above, will be found stated in $\pmast1$, where the formal and continuous exposition of the subject commences. Such propositions will be called ``primitive propositions.'' These, like the primitive ideas, are to some extent a matter of arbitrary choice; though, as in the previous case, a logical system grows in importance according as the primitive propositions are few and simple. It will be found that owing to the weakness of the imagination in dealing with simple abstract ideas no very great stress can be laid upon their obviousness. They are obvious to the instructed mind, but then so are many propositions which cannot be quite true, as being disproved by their contradictory consequences. The proof of a logical system is its adequacy and its coherence. That is: (1) the system must embrace among its deductions all those propositions which we believe to be true and capable of deduction from logical premisses alone, though possibly they may require some slight limitation in the form of an increased stringency of enunciation; and (2) the system must lead to no contradictions, namely in pursuing our inferences we must never be led to assert both $p$ and not-$p$, \textit{i.e.}\ both ``$\pmthm \pmdot p$'' and ``$\pmthm \pmdot \pmnot p$'' cannot legitimately appear.

The following are the primitive propositions employed in the calculus of propositions. The letters ``Pp'' stand for ``primitive proposition.'' 

(1) \indent Anything implied by a true premiss is true $\pmpp$.

This is the rule which justifies inference.

(2) \indent $\pmthm\pmdott p\pmor p\pmdot\pmimp\pmdot p \pmpp$,\\
\textit{i.e.}\ if $p$ or $p$ is true, then $p$ is true.

(3) \indent $\pmthm\pmdott q \pmdot\pmimp\pmdot p \pmor q \pmpp$,\\
\textit{i.e.}\ if $q$ is true, then $p$ or $q$ is true.

(4) \indent $\pmthm\pmdott p \pmor q \pmdot\pmimp\pmdot q \pmor p \pmpp$,\\
\textit{i.e.}\ if $p$ or $q$ is true, then $q$ or $p$ is true.

(5) \indent $\pmthm\pmdottt p \pmor (q\pmor r) \pmdot\pmimp\pmdot q \pmor (p\pmor r) \pmpp$, \\
\textit{i.e.}\ if either $p$ is true or ``$q$ or $p$'' is true, then either $q$ is true or ``$p$ or $r$'' is true.

(6) \indent $\pmthm\pmdottt q \pmimp r \pmdot\pmimp\pmdott p\pmor q \pmdot\pmimp \pmdot p \pmor r \pmpp$,\\
\textit{i.e.}\ if $q$ implies $r$, then ``$p$ or $q$'' implies ``$p$ or $r$.''

(7) \indent Besides the above primitive propositions, we require a primitive proposition called ``the axiom of identification of real variables.'' When we have separately asserted two different functions of $x$, where $x$ is undetermined, it is often important to know whether we can identify the $x$ in one \pagefirst{14} assertion with the $x$ in the other. This will be the case---so our axiom allows us to infer---if both assertions present $x$ as the argument to some one function, that is to say, if $\phi x$ is a constituent in both assertions (whatever propositional function $\phi$ may be), or, more generally, if $\phi(x, y, z, ...)$ is a constituent in one assertion, and $\phi(x, u, v, ...)$ is a constituent in the other. This axiom introduces notions which have not yet been explained; for a fuller account, see the remarks accompanying $\pmast3\pmcdot03$, $\pmast1\pmcdot7$, $\pmast1\pmcdot71$, and $\pmast1\pmcdot72$ (which is the statement of this axiom) in the body of the work, as well as the explanation of propositional functions and ambiguous assertion to be given shortly.

\textit{Some simple propositions}. In addition to the primitive propositions we have already mentioned, the following are among the most important of the elementary properties of propositions appearing among the deductions.

The law of excluded middle:
\[
	\pmthm \pmdot p\pmor \pmnot p.
\]
This is $\pmast2\pmcdot11$ below. We shall indicate in brackets the numbers given to the following propositions in the body of the work.

The law of contradiction ($\pmast3\pmcdot24$):
\[
\pmthm \pmdot \pmnot(p \pmand \pmnot p).
\]

The law of double negation ($\pmast4\pmcdot13$):
\[
\pmthm \pmdot p \pmiff \pmnot p.
\]

The principle of \textit{transposition}, \textit{i.e.}\ ``if $p$ implies $q$, then not-$q$ implies not-$p$,'' and vice versa: this principle has various forms, namely
\begin{align*}
	(\pmast4\pmcdot1) \hspace{.6cm} & \pmthm\pmdott p\pmimp q\pmdot\pmiff\pmdot\pmnot p \pmiff \pmnot q, \\ 
	(\pmast4\pmcdot11) \hspace{.4cm} & \pmthm \pmdott p \pmiff q \pmdot \pmiff \pmdot \pmnot p \pmiff \pmnot q, \\ 
	(\pmast4\pmcdot14) \hspace{.4cm} & \pmthm \pmdottt p\pmand q\pmdot \pmimp\pmdot r\pmdott\pmiff\pmdott p \pmand \pmnot r \pmdot\pmimp\pmdot\pmnot q, 
\end{align*}
as well as others which are variants of these.

The law of tautology, in the two forms:
\begin{align*}
	(\pmast4\pmcdot24) \hspace{.4cm} & \pmthm\pmdott p \pmdot\pmiff\pmdot p \pmand p, \\ 
	(\pmast4\pmcdot11) \hspace{.4cm} & \pmthm \pmdott p \pmiff q \pmdot \pmiff \pmdot p \pmor p, 
\end{align*}
\textit{i.e.}\ ``$p$ is true'' is equivalent to ``$p$ is true and $p$ is true,'' as well as to ``$p$ is true or $p$ is true.'' From a formal point of view, it is through the law of tautology and its consequences that the algebra of logic is chiefly distinguished from ordinary algebra.

The law of absorption:
\begin{align*}
	(\pmast4\pmcdot71) \hspace{.4cm} & \pmthm\pmdottt p\pmimp q \pmdot\pmiff\pmdott p \pmdot \pmiff \pmdot p \pmand q, 
\end{align*}
\textit{i.e.}\ ``$p$ implies $q$'' is equivalent to ``$p$ is equivalent to $p$$\pmand q$.'' This is called the law of absorption because it shows that the factor $q$ in the  product is \pagefirst{15} absorbed by the factor $p$, if $p$ implies $q$. This principle enables us to replace an implication $(p \pmimp q)$ by an equivalence $(p \pmdot \pmiff \pmdot p \pmdot q)$ whenever it is convenient to do so.

An analogous and very important principle is the following:
\begin{align*}
	(\pmast4\pmcdot73) \hspace{.4cm} & \pmthm\pmdottt q \pmdot \pmimp \pmdott p \pmdot \pmiff \pmdot p \pmand q.
\end{align*}

Logical addition and multiplication of propositions obey the associative and commutative laws, and the distributive law in two forms, namely
\begin{align*}
	(\pmast4\pmcdot4) \hspace{.6cm} & \pmthm\pmdottt p \pmand q\pmor r\pmdot\pmiff\pmdott p \pmand q \pmdot \pmor\pmdot p\pmand r, \\ 
	(\pmast4\pmcdot41) \hspace{.4cm} & \pmthm\pmdottt p \pmdot \pmor \pmdot q\pmand r\pmdott\pmiff\pmdott p \pmor q \pmand p \pmor r. 
\end{align*}
The second of these distinguishes the relations of logical addition and multiplication from those of arithmetical addition and multiplication.

\textit{Propositional functions}. Let $\phi x$ be a statement containing a variable $x$ and such that it becomes a proposition when $x$ is given any fixed determined meaning. Then $\phi x$ is called a ``propositional function''; it is not a proposition, since owing to the ambiguity of $x$ it really makes no assertion at all. Thus ``$x$ is hurt'' really makes no assertion at all, till we have settled who $x$ is. Yet owing to the individuality retained by the ambiguous variable $x$, it is an ambiguous example from the collection of propositions arrived at by giving all possible determinations to $x$ in ``$x$ is hurt'' which yield a proposition, true or false. Also if ``$x$ is hurt'' and ``$y$ is hurt'' occur \textit{in the same context}, where $y$ is another variable, then according to the determinations given to $x$ and $y$, they can be settled to be (possibly) the same proposition or (possibly) different propositions. But apart from some determination given to x and $y$, they retain in that context their ambiguous differentiation. Thus ``$x$ is hurt'' is an ambiguous ``value'' of a propositional function. When we wish to speak of the propositional function corresponding to ``$x$ is hurt,'' we shall write ``$\pmpf{\pmhat{x}}{\text{ is hurt}}$.'' Thus ``$\pmpf{\pmhat{x}}{\text{ is hurt}}$'' is the propositional function and ``$x$ is hurt'' is an ambiguous value of that function. Accordingly though ``$x$ is hurt'' and ``$y$ is hurt'' \textit{occurring in the same context} can be distinguished, ``$\pmpf{\pmhat{x}}{\text{ is hurt}}$'' and ``$\pmpf{\pmhat{y}}{\text{ is hurt}}$'' convey no distinction of meaning at all. More generally, $\phi x$ is an ambiguous value of the propositional function $\pmpf{\phi}{\pmhat{x}}$, and when a definite signification $A$ is substituted for $x$, $\phi a$ is an unambiguous value of $\pmpf{\phi}{\pmhat{x}}$.

Propositional functions are the fundamental kind from which the more usual kinds of function, such as ``$\sin x$'' or ``$\log x$'' or ``the father of $x$,'' are derived. These derivative functions are considered later, and are called ``descriptive functions.'' The functions of propositions considered above are a particular case of propositional functions.

\textit{The range of variables and total variation}. Thus corresponding to any propositional function $\pmpf{\phi}{\pmhat{x}}$, there is a range, or collection, of values, consisting of all the propositions (true or false) which can be obtained by giving \pagefirst{16} every possible determination to $x$ in $\phi x$. A value of $x$ for which $\phi x$ is true will be said to ``satisfy'' $\pmpf{\phi}{\pmhat{x}}$. Now in respect to the truth or falsehood of propositions of this range three important cases must be noted and symbolised. These cases are given by three propositions of which one at least must be true. Either (1) all propositions of the range are true, or (2) some propositions of the range are true, or (3) no proposition of the range is true. The statement (1) is symbolised by ``$\pmall{x}\pmdot\phi x$'' and (2) is symbolised by ``$\pmsome{x}\pmdot\phi x$.'' No definition is given of these two symbols, which accordingly embody two new primitive ideas in our system. The symbol ``$\pmall{x}\pmdot\phi x$'' may be read ``$\phi x$ always,'' or ``$\phi x$ is always true,'' or ``$\phi x$ is true for all possible values of $x$.'' The symbol ``$\pmsome{x}\pmdot\phi x$'' may be read ''there exists an $x$ for which $\phi x$ is true,'' or ``there exists an $x$ satisfying $\phi x$,'' and thus conforms to the natural form of the expression of thought.

Proposition (3) can be expressed in terms of the fundamental ideas now on hand. In order to do this, note that ``$\pmnot \phi x$'' stands for the contradictory of $\phi x$. Accordingly $\pmpf{\phi}{\pmhat{x}}$ is another propositional function such that each value of $\pmpf{\phi}{\pmhat{x}}$ contradicts a value of $\pmnot\pmpf{\phi}{\pmhat{x}}$, and vice versa. Hence ``$\pmall{x}\pmdot\pmnot \phi x$'' symbolises the proposition that every value of $\pmpf{\phi}{\pmhat{x}}$ is untrue. This is number (3) as stated above.

It is an obvious error, though one easy to commit, to assume that cases (1) and (3) are each other's contradictories. The symbolism exposes this fallacy at once, for (1) is $\pmall{x}\pmdot \phi x$, and (3) is $\pmall{x}\pmdot \pmnot \phi x$, while the contradictory of (1) is $\pmnot\{\pmall{x}\pmdot \phi x\}$. For the sake of brevity of symbolism a definition is made, namely
\[
	\pmnot\pmall{x}\pmdot \phi x \pmdot \pmiddf \pmdot \pmnot\{\pmall{x}\pmdot \phi x\}. \pmdf
\]

Definitions of which the object is to gain some trivial advantage in brevity by a slight adjustment of symbols will be said to be of ``merely symbolic import,'' in contradistinction to those definitions which invite consideration of an important idea.

The proposition $\pmall{x}\pmdot \phi x$ is called the ``total variation'' of the function $\pmpf{\phi}{\pmhat{x}}$.

For reasons which will be explained in Chapter II, we do not take negation as a primitive idea when propositions of the forms $\pmall{x}\pmdot \phi x$ and $\pmsome{x}\pmdot \phi x$ are concerned, but we \textit{define} the negation of $\pmall{x}\pmdot \phi x$, \textit{i.e.}\ of ``$\phi x$ is always true,'' as being ``$\phi x$ is sometimes false,'' \textit{i.e.}\ ``$\pmsome{x}\pmdot \pmnot \phi x$,'' and similarly we \textit{define} the negation of $\pmsome{x}\pmdot \phi x$ as being $\pmall{x}\pmdot \pmnot \phi x$. Thus we put
\begin{align*}
	\pmnot \{\pmall{x}\pmdot\phi x \} \pmiddf \pmsome{x}\pmdot \pmnot \phi x \pmdf, \\
	\pmnot \{\pmsome{x}\pmdot\phi x \} \pmiddf \pmall{x}\pmdot \pmnot \phi  x \pmdf.
\end{align*}
In like manner we define a disjunction in which one of the propositions is of the form ``$\pmall{x}\pmdot \phi x$'' or ``$\pmsome{x}\pmdot \phi x$'' in terms of a disjunction of propositions not of this form, putting \[
	\pmall{x}\pmdot \phi x \pmdot \pmor \pmdot p \pmdott \pmiddf \pmdot \pmall{x}\pmdot \phi x\pmor p \pmdf,
\]
\pagefirst{17} \textit{i.e.}\ ``either $\phi x$ is always true, or $p$ is true'' is to mean ```$\phi x$ or $p$' is always true,'' with similar definitions in other cases. This subject is resumed in Chapter II, and in $\pmast9$ in the body of the work.

\textit{Apparent variables}. The symbol ``$\pmall{x}\pmdot \phi x$'' denotes one definite proposition, and there is no distinction in meaning between ``$\pmall{x}\pmdot \phi x$'' and ``$\pmall{y}\pmdot \phi y$'' when they occur in the same context. Thus the ``$x$'' in ``$\pmall{x}\pmdot \phi x$'' is not an ambiguous constituent of any expression in which ``$\pmall{x}\pmdot \phi x$'' occurs; and such an expression does not cease to convey a determinate meaning by reason of the ambiguity of the $x$ in the ``$\phi x$.'' The symbol ``$\pmall{x}\pmdot \phi x$'' has some analogy to the symbol
\[
	\text{``}\int_a^b \phi(x)dx\text{''}
\]
for definite integration, since in neither case is the expression a function of $x$.

The range of $x$ in ``$\pmall{x}\pmdot \phi x$'' or ``$\pmsome{x}\pmdot \phi x$'' extends over the complete field of the values of $x$ for which ``$\phi x$'' has meaning, and accordingly the meaning of ``$\pmall{x}\pmdot \phi x$'' or ``$\pmsome{x}\pmdot \phi x$'' involves the supposition that such a field is determinate. The $x$ which occurs in ``$\pmall{x}\pmdot \phi x$'' or ``$\pmsome{x}\pmdot \phi x$'' is called (following Peano) an ``apparent variable.'' It follows from the meaning of ``$\pmall{x}\pmdot \phi x$'' that the $x$ in this expression is also an apparent variable. A proposition in which $x$ occurs as an apparent variable is not a function of $x$. Thus \textit{e.g.}\ ``$\pmall{x}\pmdot x = x$'' will mean ``everything is equal to itself.'' This is an absolute constant, not a function of a variable $x$. This is why the $x$ is called an apparent variable in such cases .

Besides the ''\textit{range}'' of $x$ in ``$\pmall{x}\pmdot \phi x$'' or ``$\pmsome{x}\pmdot \phi x$,'' which is the field of the values that x may have, we shall speak of the ``\textit{scope}'' of $x$, meaning the function of which all values or some value are being affirmed. If we are asserting all values (or some value) of ``$\phi x$,'' ``$\phi x$'' is the scope of $x$; if we are asserting all values (or some value) of ``$\phi x \pmimp p$,'' ``$\phi x \pmimp p$'' is the scope of $x$; if we are asserting all values (or some value) of ``$\phi x\pmimp \psi x$,'' ``$\phi x\pmimp \psi x$'' will be the scope of $x$, and so on. The scope of $x$ is indicated by the number of dots after the ``$\pmall{x}$'' or ``$\pmsome{x}$''; that is to say, the scope extends forwards until we reach an equal number of dots not indicating a logical product, or a greater number indicating a logical product, or the end of the asserted proposition in which the ``$\pmall{x}$'' or ``$\pmsome{x}$'' occurs, whichever of these happens first\footnote{This agrees with the rules for the occurrences of dots of the type of Group II as explained above, pp. 9 and 10.}. Thus \textit{e.g.}\
\[ 
	\text{``}\pmall{x}\pmdott \phi x \pmdot \pmimp\pmdot \psi x\text{''}
\]
will mean ``$\phi x$ always implies $\psi x$,'' but
\[ 
	\text{``}\pmall{x}\pmdot \phi x \pmdot \pmimp\pmdot \psi x\text{''}
\]
will mean ''if $\phi x$ is always true, then $\psi x$ is true for the argument $x$.''

Note that in the proposition
\[ 
	\pmall{x}\pmdot \phi x \pmdot \pmimp\pmdot \psi x
\]
\pagefirst{18} the two $x$'s have no connection with each other. Since only one dot follows the $x$ in brackets, the scope of the first $x$ is limited to the ``$\phi x$'' immediately following the $x$ in brackets. It usually conduces to clearness to write
\[ 
\pmall{x}\pmdot \phi x \pmdot \pmimp\pmdot \psi y
\]
rather than 
\[ 
\pmall{x}\pmdot \phi x \pmdot \pmimp\pmdot \psi x,
\]
since the use of different letters emphasises the absence of connection between the two variables; but there is no logical necessity to use different letters, and it is \textit{sometimes} convenient to use the same letter.

\textit{Ambiguous assertion and the real variable}. Any value ``$\phi x$'' of the function ``$\pmpf{\phi}{\pmhat{x}}$'' can be asserted. Such an assertion of an ambiguous member of the values of ``$\pmpf{\phi}{\pmhat{x}}$ is symbolised by
\[  
	\text{``}\pmthm\pmdot \phi x.\text{''}
\]

Ambiguous assertion of this kind is a primitive idea, which cannot be defined in terms of the assertion of propositions. This primitive idea is the one which embodies the use of the variable. Apart from ambiguous assertion, the consideration of ``$\phi x$,'' which is an ambiguous member of the values of $\pmpf{\phi}{\pmhat{x}}$, would be of little consequence. When we are considering or asserting ``$\phi x$,'' the variable $x$ is called a ``real variable.'' Take, for example, the law of excluded middle in the form which it has in traditional formal logic:
\begin{center}
	``$A$ is either \textit{b} or not \textit{b}.''
\end{center}
Here $A$ and \textit{b} are real variables: as they vary, different propositions are expressed, though all of them are true. While $A$ and \textit{b} are undetermined, as in the above enunciation, no one definite proposition is asserted, but what is asserted is \textit{any} value of the propositional function in question. This can only be legitimately asserted if, whatever value may be chosen, that value is true, \textit{i.e.}\ if all the values are true. Thus the above form of the law of excluded middle is equivalent to
\begin{center}
	``$\pmall{a, b}\pmdot A$ is either \textit{b} or not \textit{b},''
\end{center}
\textit{i.e.}\ to ``it is always true that $A$ is either \textit{b} or not \textit{b}.'' But these two, though equivalent, are not identical, and we shall find it necessary to keep them distinguished.

When we assert something containing a real variable, as in e.g.
\[
	\text{``}\pmthm \pmdot x = x\text{''}
\]
we are asserting any value of a propositional function. When we assert something containing an apparent variable, as in \textit{e.g.}\
\begin{flalign*}
	 && &\text{''}\pmthm \pmdot \pmall{x} \pmdot x = x\text{''} & \\
	\text{or} && &\text{''}\pmthm \pmdot \pmsome{x} \pmdot x = x,\text{''} & 
\end{flalign*}
we are asserting, in the first case \textit{all} values, in the second case \textit{some} value (undetermined), of the propositional function in question. It is plain that \pagefirst{19} we can only legitimately assert ``\textit{any} value'' if \textit{all} values are true; for otherwise, since the value of the variable remains to be determined, it might be so determined as to give a false proposition. Thus in the above instance, since we have
\begin{flalign*}
	&& &\pmthm \pmdot x = x & &&\\
	\text{we may infer} && &\pmthm \pmdot \pmall{x} \pmdot x = x.& &&
\end{flalign*}
And generally, given an assertion containing a real variable $x$, we may transform the real variable into an apparent one by placing the $x$ in brackets at the beginning, followed by as many dots as there are after the assertion-sign.

When we assert something containing a real variable, we cannot strictly be said to be asserting a \textit{proposition}, for we only obtain a definite proposition by assigning a value to the variable, and then our assertion only applies to one definite case, so that it has not at all the same force as before. When what we assert contains a real variable, we are asserting a wholly undetermined one of all the propositions that result from giving various values to the variable. It will be convenient to speak of such assertions as \textit{asserting a propositional function}. The ordinary formulae of mathematics contain such assertions; for example
\[
	\text{``}\sin^2 x + \cos^2 x = 1\text{''}
\]
does not assert this or that particular case of the formula, nor does it assert that the formula holds for \textit{all} possible values of $x$, though it is equivalent to this latter assertion; it simply asserts that the formula holds, leaving $x$ wholly undetermined; and it is able to do this legitimately, because, however $x$ may be determined, a true proposition results.

Although an assertion containing a real variable does not, in strictness, assert a proposition, yet it will be spoken of as asserting a proposition except when the nature of the ambiguous assertion involved is under discussion.

\textit{Definition and real variables}. When the \textit{definiens} contains one or more real variables, the \textit{definiendum} must also contain them. For in this case we have a function of the real variables, and the \textit{definiendum} must have the same meaning as the \textit{definiens} for all values of these variables, which requires that the symbol which is the \textit{definiendum} should contain the letters representing the real variables. This rule is not always observed by mathematicians, and its infringement has sometimes caused important confusions of thought, notably in geometry and the philosophy of space.

In the definitions given above of ``$p \pmand q$'' and ``$p \pmimp q$'' and ``$p \pmiff q$,'' $p$ and $q$ are real variables, and therefore appear on both sides of the definition. In the definition of ``$\pmnot\{\pmall{x} \pmdot \phi x\}$'' only the function considered, namely $\phi \pmhat{z}$, is a real variable; thus so far as concerns the rule in question, $x$ need not appear on the left. But when a real variable is a function, it is necessary to indicate \pagefirst{20} how the argument is to be supplied, and therefore there are objections to omitting an apparent variable where (as in the case before us) this is the argument to the function which is the real variable. This appears more plainly if, instead of a general function $\pmpf{\phi}{\pmhat{x}}$, we take some particular function, say ``$x=a$,'' and consider the definition of $\pmnot\{\pmall{x}\pmdot x = a\}$. Our definition gives
\[
	\pmnot\{\pmall{x}\pmdot x = a\} \pmdot \pmiddf \pmdot \pmsome{x}\pmdot \pmnot (x = a) \pmdf.
\]
But if we had adopted a notation in which the ambiguous value ``$x = a$,'' containing the apparent variable $x$, did not occur in the \textit{definiendum}, we should have had to construct a notation employing the function itself, namely ``$\pmpf{\pmhat{x}}{=a}$.'' This does not involve an apparent variable, but would be clumsy in practice. In fact we have found it convenient and possible---except in the explanatory portions---to keep the explicit use of symbols of the type ``$\pmpf{\phi}{\pmhat{x}}$,'' either as constants [\textit{e.g.}\ $\pmpf{\pmhat{x}}{=a}$] or as real variables, almost entirely out of this work.

\textit{Propositions connecting real and apparent variables}. The most important propositions connecting real and apparent variables are the following:

(1) ``When a propositional function can be asserted, so can the proposition that all values of the function are true.'' More briefly, if less exactly, ``what holds of any, however chosen, holds of all.'' This translates itself into the rule that when a real variable occurs in an assertion, we may turn it into an apparent variable by putting the letter representing it in brackets immediately after the assertion-sign.

(2) ``What holds of all, holds of any,'' \textit{i.e.}\
\[ 
	\pmthm\pmdott \pmall{x}\pmdot \phi x \pmdot \pmimp \pmdot \phi y,
\]
This states ``if $\phi x$ is always true, then $\phi y$ is true.''

(3) '' If $\phi y$ is true, then $\phi x$ is sometimes true,'' \textit{i.e.}\
\[ 
	\pmthm\pmdott \phi y \pmdot \pmimp \pmdot \pmsome{x}\pmdot \phi x,
\]
An asserted proposition of the form ``$\pmsome{x}\pmdot\phi x$'' expresses an ``existence-theorem,'' namely ``there exists an $x$ for which $\phi x$ is true.'' The above proposition gives what is in practice the only way of proving existence-theorems: we always have to find some particular $y$ for which $\phi y$ holds, and thence to infer ``$\pmsome{x} \pmdot \phi x$.'' If we were to assume what is called the multiplicative axiom, or the equivalent axiom enunciated by Zermelo, that would, in an important class of cases, give an existence-theorem where no particular instance of its truth can be found.

In virtue of ``$\pmthm \pmdott \pmall{x}\pmdot \phi x \pmdot\pmimp\pmdot \phi y$'' and ``$\pmthm \pmdott \phi y \pmdot \pmimp\pmdot \pmsome{x} \pmdot \phi x$,'' we have ``$\pmthm \pmdott \pmall{x}\pmdot \phi x \pmdot \pmimp \pmdot \pmsome{x} \pmdot \phi x$,'' \textit{i.e.}\ ``what is always true is sometimes true.'' This would not be the case if nothing existed; thus our assumptions contain the assumption that there is something. This is involved in the principle \pagefirst{21} that what holds of all, holds of any; for this would not be true if there were no ``any.''

(4) ``If $\phi x$ is always true, and $\psi x$ is always true, then `$\phi x \pmand \psi x$' is always true,'' \textit{i.e.}\
\[ 
	\pmthm\pmdottt \pmall{x}\pmdot \phi x \pmandd \pmall{x}\pmdot \psi x \pmdott \pmimp \pmdot \pmall{x}\pmdot \phi x \pmand \psi x.
\]
(This requires that $\phi$ and $\psi$ should be functions which take arguments of the same type. We shall explain this requirement at a later stage.) The converse also holds; \textit{i.e.}\ we have
\[ 
	\pmthm\pmdottt \pmall{x}\pmdot \phi x \pmand \psi x \pmdot \pmimp \pmdott \pmall{x}\pmdot \phi x \pmandd \pmall{x}\pmdot \psi x.
\]

It is to some extent optional which of the propositions connecting real and apparent variables are taken as primitive propositions. The primitive propositions assumed, on this subject, in the body of the work ($\pmast9$), are the following:
\begin{align*}
	(1) \hspace{.4cm} & \pmthm \pmdott \phi x \pmdot \pmimp \pmdot \pmsome{z} \pmdot \phi z.\\
	(2) \hspace{.4cm} & \pmthm \pmdott \phi x \pmor \phi y \pmdot \pmimp \pmdot \pmsome{z} \pmdot \phi z,
\end{align*}
\textit{i.e.}\ if either $\phi x$ is true, or $\phi y$ is true, then $\pmsome{x}\pmdot\phi z$ is true. (On the necessity for this primitive proposition, see remarks on $\pmast9\pmcdot11$ in the body of the work.)

(3) If we can assert $\phi y$, where $y$ is a real variable, then we can assert $\pmall{x}\pmdot \phi x$; \textit{i.e.}\ what holds of any, however chosen, holds of all.

\textit{Formal implication and formal equivalence}. When an implication, say $\phi x \pmdot \pmimp \pmdot \psi x$, is said to hold always, \textit{i.e.}\ when $\pmall{x} \pmdott \phi x \pmdot \pmimp \pmdot \psi x$, we shall say that $\phi x$ \textit{formally implies} $\psi x$; and propositions of the form ``$\pmall{x} \pmdott \phi x \pmdot \pmimp \pmdot \psi x$'' will be said to state \textit{formal implications}. In the usual instances of implication, such as ```Socrates is a man' implies `Socrates is mortal,'\text{''} we have a proposition of the form ``$\phi x \pmdot \pmimp \pmdot \psi x$'' in a case in which ``$\pmall{x}\pmdott\phi x\pmdot\pmimp\pmdot\psi x$'' is true. In such a case, we feel the implication as a particular case of a formal implication. Thus it has come about that implications which are not particular cases of formal implications have not been regarded as implications at all. There is also a practical ground for the neglect of such implications, for, speaking generally, they can only be \textit{known} when it is already known either that their hypothesis is false or that their conclusion is true; and in neither of these cases do they serve to make us know the conclusion, since in the first case the conclusion need not be true, and in the second it is known already. Thus such implications do not serve the purpose for which implications are chiefly useful, namely that of making us know, by deduction, conclusions of which we were previously ignorant. \textit{Formal} implications, on the contrary, do serve this purpose, owing to the psychological fact that we often know ``$\pmall{x} \pmdott \phi x\pmdot \pmimp \pmdot \psi x$'' and $\phi y$, in cases where $\psi y$ (which follows from these premisses) cannot easily be known directly.

\pagefirst{22} These reasons, though they do not warrant the complete neglect of implications that are not instances of formal implications, are reasons which make formal implication very important. A formal implication states that, for all possible values of $x$, if the hypothesis $\phi x$ is true, the conclusion $\psi x$ is true. Since ``$\phi x \pmdot \pmimp \pmdot \psi x$'' will always be true when $\phi x$ is false, it is only the values of $x$ that make $\phi x$ true that are \textit{important} in a formal implication; what is effectively stated is that, for all these values, $\psi x$ is true. Thus propositions of the form ``all $\alpha$ is $\beta$,'' ``no $\alpha$ is $\beta$'' state formal implications, since the first (as appears by what has just been said) states 
\[
	\pmall{x}\pmdott x \text{ is an } \alpha \pmdot \pmimp \pmdot x \text{ is a } \beta,
\]
while the second states
\[
	\pmall{x}\pmdott x \text{ is an } \alpha \pmdot \pmimp \pmdot x \text{ is not a } \beta.
\]
And any formal implication ``$\pmall{x} \pmdott \phi x \pmdot \pmimp\pmdot \psi x$'' may be interpreted as: ``All values of $x$ which satisfy\footnote{A value of $x$ is said to \textit{satisfy} $\phi x$ or $\pmpf{\phi}{\pmhat{x}}$ when $\phi x$ is true for that value of $x$.} ``$\phi x$ satisfy $\psi x$,'' while the formal implication ``$\pmall{x}\pmdott\phi x \pmdot \pmimp \pmdot \pmnot \psi x$'' may be interpreted as: ``No values of $x$ which satisfy $\phi x$ satisfy $\psi x$.''

We have similarly for ``some $\alpha$ is $\beta$'' the formula
\[
	\pmsome{x}\pmdot x \text{ is an } \alpha \pmand x \text{ is a } \beta,
\]
and for ``some $\alpha$ is not $\beta$'' the formula
\[
	\pmsome{x}\pmdot x \text{ is an } \alpha \pmand x \text{ is not a } \beta,
\]

Two functions $\phi x$, $\psi x$ are called \textit{formally equivalent} when each always implies the other, \textit{i.e.}\ when
\[
	\pmall{x} \pmdott \phi x \pmdot \pmiff \pmdot \psi x,
\]
and a proposition of this form is called a \textit{formal equivalence}. In virtue of what was said about truth-values, if $\phi x$ and $\psi x$ are formally equivalent, either may replace the other in any truth-function. Hence for all the purposes of mathematics or of the present work, $\pmpf{\phi}{\pmhat{z}}$ may replace $\pmpf{\psi}{\pmhat{z}}$ or vice versa in any proposition with which we shall be concerned. Now to say that $\phi x$ and $\psi x$ are formally equivalent is the same thing as to say that $\pmpf{\phi}{\pmhat{z}}$ and $\pmpf{\psi}{\pmhat{z}}$ have the same \textit{extension}, \textit{i.e.}\ that any value of $x$ which satisfies either satisfies the other. Thus whenever a constant function occurs in our work, the truth-value of the proposition in which it occurs depends only upon the extension of the function. A proposition containing a function $\pmpf{\phi}{\pmhat{z}}$ and having this property (\textit{i.e.}\ that its truth-value depends only upon the extension of $\pmpf{\phi}{\pmhat{z}}$) will be called an \textit{extensional} function of $\pmpf{\phi}{\pmhat{z}}$. Thus the functions of functions with which we shall be specially concerned will all be extensional functions of functions.

What has just been said explains the connection (noted above) between the fact that the functions of propositions with which mathematics is specially \pagefirst{23} concerned are all truth-functions and the fact that mathematics is concerned with extensions rather than intensions.

\textit{Convenient abbreviation}. The following definitions give alternative and often more convenient notations:
\begin{align*}
	\phi x \pmdot \pmimp_x \pmdot \psi x \pmdott \pmiddf  \pmdott \pmall{x}\pmdot\phi x\pmdot \pmimp \pmdot \psi x \pmdf, \\
	\phi x \pmdot \pmiff_x \pmdot \psi x \pmdott \pmiddf \pmdott \pmall{x}\pmdot\phi x\pmdot \pmiff \pmdot \psi x \pmdf.
\end{align*}
This notation ``$\phi x \pmdot \pmimp_x \pmdot \psi x$'' is due to Peano, who, however, has no notation for the general idea ``$\pmall{x}\pmdot \phi x$.'' It may be noticed as an exercise in the use of dots as brackets that we might have written 
\begin{align*}
	\phi x \pmimp_x \psi x \pmdot \pmiddf \pmdot \pmall{x}\pmdot\phi x \pmimp \psi x \pmdf, \\
	\phi x \pmiff_x \psi x \pmdot \pmiddf \pmdot \pmall{x}\pmdot\phi x \pmiff  \psi x \pmdf.
\end{align*}
In practice however, when $\pmpf{\phi}{\pmhat{x}}$ and $\pmpf{\psi}{\pmhat{x}}$ are special functions, it is not possible to employ fewer dots than in the first form, and often more are required. 

The following definitions give abbreviated notations for functions of two or more variables:
\[
	\pmall{x, y} \pmdot \phi(x,y) \pmdot \pmiddf \pmdott \pmall{x} \pmdott \pmall{y} \pmdot \phi(x,y) \pmdf,
\]
and so on for any number of variables;
\[
	\phi(x,y) \pmdot \pmimp_{x,y} \pmdot \psi(x,y) \pmdott \pmiddf \pmdott \pmall{x, y} \pmdott \phi(x,y) \pmdot \pmimp \pmdot \psi(x,y) \pmdf,
\]
and so on for any number of variables.

\textit{Identity}. The propositional function ``$x$ identical with $y$'' is expressed by
\[ 
	x=y.
\]
This will be defined (cf. $\pmast13\pmcdot01$), but, owing to certain difficult points involved in the definition, we shall here omit it (cf. Chapter II). We have, of course,
\begin{flalign*}
	&& \pmthm \pmdot x=x \hspace{.4cm} \text{(the law of identity)}, &&\\
	&& \pmthm \pmdott x=y \pmdot \pmiff \pmdot y=x, \hspace{2.16cm} && \\
	&& \pmthm \pmdott x=y \pmand y=z \pmdot \pmimp \pmdot x=z \hspace{1cm} &&
\end{flalign*}
The first of these expresses the \textit{reflexive} property of identity: a relation is called \textit{reflexive} when it holds between a term and itself, either universally, or whenever it holds between that term and some term. The second of the above propositions expresses that identity is a \textit{symmetrical} relation: a relation is called \textit{symmetrical} if, whenever it holds between $x$ and $y$, it also holds between $y$ and $x$. The third proposition expresses that identity is a \textit{transitive} relation: a relation is called \textit{transitive} if, whenever it holds between $x$ and $y$ and between $y$ and $z$, it holds also between $x$ and $z$.

We shall find that no new definition of the sign of equality is required in mathematics: all mathematical equations in which the sign of equality is \pagefirst{24} used in the ordinary way express some identity, and thus use the sign of equality in the above sense.

If $x$ and $y$ are identical, either can replace the other in any proposition without altering the truth-value of the proposition; thus we have
\[
	\pmthm \pmdott x=y \pmdot \pmimp \pmdot \phi x \pmiff \phi y.
\]
This is a fundamental property of identity, from which the remaining properties mostly follow.

It might be thought that identity would not have much importance, since it can only hold between $x$ and $y$ if $x$ and $y$ are different symbols for the same object. This view, however, does not apply to what we shall call ``descriptive phrases,'' \textit{i.e.}\ ``the so-and-so.'' It is in regard to such phrases that identity is important, as we shall shortly explain. A proposition such as ``Scott was the author of Waverley'' expresses an identity in which there is a descriptive phrase (namely ``the author of Waverley''); this illustrates how, in such cases, the assertion of identity may be important. It is essentially the same case when the newspapers say ``the identity of the criminal has not transpired.'' In such a case, the criminal is known by a descriptive phrase, namely ``the man who did the deed,'' and we wish to find an $x$ of whom it is true that ``$x =$ the man who did the deed.'' When such an $x$ has been found, the identity of the criminal has transpired.

\textit{Classes and relations}. A \textit{class} (which is the same as a manifold or aggregate) is all the objects satisfying some propositional function. If $\alpha$ is the class composed of the objects satisfying $\pmpf{\phi}{\pmhat{x}}$, we shall say that $\alpha$ is the class \textit{determined} by $\pmpf{\phi}{\pmhat{x}}$. Every propositional function thus determines a class, though if the propositional function is one which is always false, the class will be \textit{null}, \textit{i.e.}\ will have no members. The class determined by the function $\pmpf{\phi}{\pmhat{x}}$ will be represented by $\pmcls{z}{\phi z}$\footnote{Any other letter may be used instead of $z$.}. Thus for example if $\phi x$ is an equation, $\pmcls{z}{\phi z}$ will be the class of its roots; if $\phi x$ is ``$x$ has two legs and no feathers,'' $\pmcls{z}{\phi z}$ will be the class of men; if $\phi x$ is ``$0 < x < 1$,'' $\pmcls{z}{\phi z}$ will be the class of proper fractions, and so on.

It is obvious that the same class of objects will have many determining functions. When it is not necessary to specify a determining function of a class, the class may be conveniently represented by a single Greek letter. Thus Greek letters, other than those to which some constant meaning is assigned, will be exclusively used for classes.

There are two kinds of difficulties which arise in formal logic; one kind arises in connection with classes and relations and the other in connection with descriptive functions. The point of the difficulty for classes and relations, so far as it concerns classes, is that a class cannot be an, object suitable as an argument to any of its determining functions. If $\alpha$ represents \pagefirst{25} a class and $\pmpf{\phi}{\pmhat{x}}$ one of its determining functions [so that $\alpha=\pmcls{z}{\phi z}$], it is not sufficient that $\phi \alpha$ be a false proposition, it must be nonsense. Thus a certain classification of what appear to be objects into things of essentially different types seems to be rendered necessary. This whole question is discussed in Chapter II, on the theory of types, and the formal treatment in the systematic exposition, which forms the main body of this work, is guided by this discussion. The part of the systematic exposition which is specially concerned with the theory of classes is $\pmast20$, and in this Introduction it is discussed in Chapter III. It is sufficient to note here that, in the complete treatment of $\pmast20$, we have avoided the decision as to whether a class of things has in any sense an existence as one object. A decision of this question in either way is indifferent to our logic, though perhaps, if we had regarded some solution which held classes and relations to be in some real sense objects as both true and likely to be universally received, we might have simplified one or two definitions and a few preliminary propositions. Our symbols, such as ``$\pmcls{x}{\phi x}$'' and $\alpha$ and others, which represent classes and relations, are merely defined in their use, just as $\nabla^2$, standing for
\[
	\frac{\partial^2}{\partial x^2} + \frac{\partial^2}{\partial y^2} + \frac{\partial^2}{\partial z^2},
\]
has no meaning apart from a suitable function of $x, y, z$ on which to operate. The result of our definitions is that the way in which we use classes corresponds in general to their use in ordinary thought and speech; and whatever may be the ultimate interpretation of the one is also the interpretation of  the other. Thus in fact our classification of types in Chapter II really performs the single, though essential, service of justifying us in refraining from entering on trains of reasoning which lead to contradictory conclusions. The justification is that what seem to be propositions are really nonsense.

The definitions which occur in the theory of classes, by which the idea of a class (at least in use) is based on the other ideas assumed as primitive, cannot be understood without a fuller discussion than can be given now (cf. Chapter II of this Introduction and also $\pmast20$). Accordingly, in this preliminary survey, we proceed to state the more important simple propositions which result from those definitions, leaving the reader to employ in his mind the ordinary unanalysed idea of a class of things. Our symbols in their usage conform to the ordinary usage of this idea in language. It is to be noticed that in the systematic exposition our treatment of classes and relations requires no new primitive ideas and only two new primitive propositions, namely the two forms of the ``Axiom of Reducibility'' (cf. next Chapter) for one and two variables respectively.

The propositional function ``$x$ is a member of the class $\alpha$'' will be expressed, following Peano, by the notation
\[
	x \pmcin \alpha.
\]
\pagefirst{26} Here $\pmcin$ is chosen as the initial of the word $\epsilon\sigma\tau\iota$. ``$x \pmcin \alpha$'' may be read ``$x$ is an $\alpha$.'' Thus ``$x \pmcin$ man'' will mean ``$x$ is a man,'' and so on. For typographical convenience we shall put
\begin{align*}
	x \pmnot \pmcin \alpha \pmdot \pmiddf \pmdot \pmnot (x \pmcin \alpha) \pmdf, \\
	x, y \pmcin \alpha \pmdot \pmiddf \pmdot x \pmcin \alpha \pmand y \pmcin \alpha \pmdf.
\end{align*}

For ``class'' we shall write ``$\pmCls$''; thus ``$\alpha \pmcin \pmCls$'' means ``$\alpha$ is a class.''

We have
\[
	\pmthm \pmdott x \pmcin \pmcls{z}{\phi z}\pmdot\pmiff\pmdot\phi x,
\]
\textit{i.e.}\ ```$x$ is a member of the class determined by $\pmpf{\phi}{\pmhat{z}}$' is equivalent to `$x$ satisfies $\pmpf{\phi}{\pmhat{z}}$,' or to `$\phi x$ is true.'''

A class is wholly determinate when its membership is known, that is, there cannot be two different classes having the same membership. Thus if $\phi x, \psi x$ are formally equivalent functions, they determine the same class; for in that case, if $x$ is a member of the class determined by $\pmpf{\phi}{\pmhat{x}}$, and therefore satisfies $\phi x$, it also satisfies $\psi x$, and is therefore a member of the class determined by $\pmpf{\psi}{\pmhat{x}}$. Thus we have
\[
	\pmthm\pmdottt \pmcls{z}{\phi z}=\pmcls{z}{\psi z} \pmdot \pmiff \pmdott \phi x \pmdot \pmiff_x \pmdot \phi x.
\]

The following propositions are obvious and important:
\[
	\pmthm\pmdottt \alpha = \pmcls{z}{\phi z} \pmdot \pmiff \pmdott x \pmcin \alpha \pmdot \pmiff_x \pmdot \phi x,
\]
\textit{i.e.}\ $\alpha$ is identical with the class determined by $\pmpf{\phi}{\pmhat{x}}$ when, and only when, ``$x$ is an $\alpha$'' is formally equivalent to $\phi x$;
\[
	\pmthm\pmdottt \alpha = \beta \pmdot \pmiff \pmdott x \pmcin \alpha \pmdot \pmiff_x \pmdot x \pmcin \beta,
\]
\textit{i.e.}\ two classes $\alpha$ and $\beta$ are identical when, and only when, they have the same membership;
\[
	\pmthm\pmdot \pmcls{x}{x \pmcin \alpha}=\alpha,
\]
\textit{i.e.}\ the class whose determining function is ``$x$ is an $\alpha$'' is $\alpha$, in other words, $\alpha$ is the class of objects which are members of $\alpha$;
\[
	\pmthm\pmdot \pmcls{z}{\phi z}\pmcin\pmCls,
\]
\textit{i.e.}\ the class determined by the function $\pmpf{\phi}{\pmhat{z}}$ is a class.

It will be seen that, according to the above, any function of one variable can be replaced by an equivalent function of the form ``$x \pmcin \alpha$.'' Hence any extensional function of functions which holds when its argument is a function of the form ``$\pmhat{z}\pmcin\alpha$,'' whatever possible value $\alpha$ may have, will hold also when its argument is any function $\pmpf{\phi}{\pmhat{z}}$. Thus variation of classes can replace variation of functions of one variable in all the propositions of the sort with which we are concerned.
	
In an exactly analogous manner we introduce dual or dyadic relations, \textit{i.e.}\ relations between two terms. Such relations will be called simply ``relations''; relations between more than two terms will be distinguished \pagefirst{27} as \textit{multiple} relations, or (when the number of their terms is specified) as triple, quadruple, ... relations, or as triadic, tetradic, ... relations. Such relations will not concern us until we come to Geometry. For the present, the only relations we are concerned with are \textit{dual} relations.

Relations, like classes, are to be taken in \textit{extension}, \textit{i.e.}\ if $R$ and $S$ are relations which hold between the same pairs of terms, $R$ and $S$ are to be identical. We may regard a relation, in the sense in which it is required for our purposes, as a class of couples; \textit{i.e.}\ the couple $(x, y)$ is to be one of the class of couples constituting the relation $R$ if $x$ has the relation $R$ to $y$\footnote{Such a couple has a \textit{sense}, \textit{i.e.}\ the couple $(x, y)$ is different from the couple $(y, x)$, unless $x=y$. We shall call it a ``couple with sense,'' to distinguish it from the class consisting of $x$ and $y$. It may also be called an \textit{ordered} couple.}. This view of relations as classes of couples will not, however, be introduced into our symbolic treatment, and is only mentioned in order to show that it is possible so to understand the meaning of the word \textit{relation} that a relation shall be determined by its extension.

Any function $\phi(x, y)$ determines a relation $R$ between $x$ and $y$. If we regard a relation as a class of couples, the relation determined by $\phi(x, y)$ is the class of couples $(x, y)$ for which $\phi(x, y)$ is true. The relation determined by the function $\phi(x, y)$ will be denoted by
\[
	\pmrel{x}{y}{\phi(x,y)}.
\]
We shall use a capital letter for a relation when it is not necessary to specify the determining function. Thus whenever a capital letter occurs, it is to be understood that it stands for a relation.

The propositional function ``$x$ has the relation $R$ to $y$'' will be expressed by the notation
\[
	xRy.
\]
This notation is designed to keep as near as possible to common language, which, when it has to express a relation, generally mentions it between its terms, as in ``$x$ loves $y$,'' ``$x$ equals $y$,'' ``$x$ is greater than $y$,'' and so on. For ``relation'' we shall write $\pmRel$''; thus ``$R \pmcin \pmRel$'' means ``$R$ is a relation.''

Owing to our taking relations in extension, we shall have
\[
	\pmthm\pmdottt \pmrel{x}{y}{\phi(x,y)}=\pmrel{x}{y}{\psi(x,y)} \pmdot \pmiff \pmdott \phi(x, y) \pmdot \pmiff_{x,y} \pmdot \psi(x, y),
\]
\textit{i.e.}\ two functions of two variables determine the same relation when, and only when, the two functions are formally equivalent.

\begin{flalign*}
\text{We have} & & \pmthm\pmdottt  z\{\pmrel{x}{y}{\phi(x,y)}\}w \pmdot \pmiff \pmdot \phi(z, w), & &
\end{flalign*}
\textit{i.e.}\ ``$z$ has to $w$ the relation determined by the function $\phi(x, y)$'' is equivalent
to $\phi(z, w)$;
\begin{flalign*}
	& & & \pmthm\pmdottt R=\pmrel{x}{y}{\phi(x,y)}\pmdot\pmiff\pmdott xRy\pmdot\pmiff_{x,y}\pmdot\phi(x,y), & \\
	& & & \pmthm\pmdottt R=\pmrel{x}{y}{\phi(x,y)}\pmdot\pmiff\pmdott xRy\pmdot\pmiff_{x,y}\pmdot\phi(x,y), & \\
	& & &\pmthm\pmdot\pmrel{x}{y}{(xRy)}=R, & \\
	& & & \pmthm\pmdot\{\pmrel{x}{y}{\phi(x,y)}\}\pmcin\pmRel. &
\end{flalign*}
\pagefirst{28} These propositions are analogous to those previously given for classes. It results from them that any function of two variables is formally equivalent to some function of the form $xRy$; hence, in extensional functions of two variables, variation of relations can replace variation of functions of two variables.

Both classes and relations have properties analogous to most of those of propositions that result from negation and the logical sum. The \textit{logical product} of two classes $\alpha$ and $\beta$ is their common part, \textit{i.e.}\ the class of terms which are members of both. This is represented by an $\alpha \pmccap \beta$. Thus we put
\begin{flalign*}
	&& & \alpha \pmccap \beta \pmiddf \pmcls{x}{x \pmcin \alpha \pmand x \pmcin \beta} \pmdf. & \\
	& \text{This gives us} & & \pmthm\pmdott x \pmcin \alpha \pmccap \beta \pmdot \pmiff \pmdot x\pmcin \alpha \pmand x \pmcin \beta, &
\end{flalign*}
\textit{i.e.}\ ``$x$ is a member of the logical product of $\alpha$ and $\beta$'' is equivalent to the logical product of ``$x$ is a member of $\alpha$'' and ``$x$ is a member of $\beta$.'' 

Similarly the \textit{logical sum} of two classes $\alpha$ and $\beta$ is the class of terms which are members of either; we denote it by $\alpha \pmccup \beta$. The definition is
\[
	\alpha \pmccup \beta \pmiddf \pmcls{x}{x \pmcin \alpha \pmor x \pmcin \beta} \pmdf,
\]
and the connection with the logical sum of propositions is given by
\[
	\pmthm\pmdottt x \pmcin \alpha \pmccup \beta \pmdot \pmiff \pmdott x\pmcin \alpha \pmor x \pmcin \beta.
\]

The \textit{negation} of a class $\alpha$ consists of those terms $x$ for which ``$x \pmcin \alpha$'' can be significantly and truly denied. We shall find that there are terms of other types for which ``$x \pmcin \alpha$'' is neither true nor false, but nonsense. These terms are not members of the negation of $\alpha$.

Thus the \textit{negation} of a class $\alpha$ is the class of terms of suitable type which are not members of it, \textit{i.e.}\ the class $\pmcls{x}{x\pmnot\pmcin\alpha}$. We call this class ``$\pmccmp{\alpha}$'' (read ``not-$\alpha$''); thus the definition is
\[
	\pmccmp{\alpha} \pmiddf \pmcls{x}{x \pmnot \pmcin \alpha} \pmdf,
\]
and the connection with the negation of propositions is given by
\[
	\pmthm\pmdott x \pmcin \pmccmp{\alpha} \pmdot \pmiff \pmdot x\pmnot \pmcin \alpha.
\]

In place of implication we have the relation of \textit{inclusion}. A class $\alpha$ is said to be included or contained in a class $\beta$ if all members of $\alpha$ are members of $\beta$, \textit{i.e.}\ if $x \pmcin \alpha \pmdot\pmimp_x\pmdot x\pmcin \beta$. We write ``$\alpha \pmcinc \beta$'' for ``$\alpha$ is contained in $\beta$.'' Thus we put
\[
	\alpha \pmcinc \beta \pmdot \pmiddf \pmdott x \pmcin \alpha \pmdot\pmimp_x\pmdot x\pmcin \beta \pmdf.
\]

Most of the formulae concerning $p \pmand q$, $p \pmor q$, $\pmnot p$, $p \pmimp q$ remain true if we substitute $\alpha \pmccap \beta$, $\alpha \pmccup \beta$, $\pmccmp{\alpha}$, $\alpha \pmcinc \beta$. In place of equivalence, we substitute identity; for ``$p \pmiff q$'' was defined as ``$p \pmimp q \pmand q \pmimp p$,'' but ``$\alpha \pmcinc \beta \pmand \beta \pmcinc \alpha$'' gives $x \pmcin \alpha \pmdot \pmiff_x \pmdot x \pmcin \beta$, whence $\alpha = \beta$.
				
\pagefirst{29} The following are some propositions concerning classes which are analogues of propositions previously given concerning propositions:
\[
	\pmthm\pmdot \alpha\pmccap\beta = \pmccmp{(\pmccmp{\alpha}\pmccup\pmccmp{\beta})},
\]
\textit{i.e.}\ the common part of $\alpha$ and $\beta$ is the negation of ``not-$\alpha$ or not-$\beta$'';
\[
	\pmthm\pmdot x \pmcin (\alpha \pmccup \pmccmp{\alpha}),
\]
\textit{i.e.}\ ``$x$ is a member of $\alpha$ or not-$\alpha$'';
\[
	\pmthm\pmdot x \pmnot \pmcin (\alpha \pmccup \pmccmp{\alpha}),
\]
\textit{i.e.}\ ``$x$ is not a member of both $\alpha$ and not-$\alpha$'';
\begin{flalign*}
	&& &\pmthm\pmdot\alpha = \pmccmp{\pmccmp{\alpha}}, & \\
	&& &\pmthm\pmdott\alpha\pmcinc\beta\pmdot\pmiff\pmdot\pmccmp{\beta}\pmcinc\pmccmp{\alpha}, & \\
	&& &\pmthm\pmdott\alpha=\beta\pmdot\pmiff\pmdot\pmccmp{\alpha}=\pmccmp{\beta}, & \\
	&& &\pmthm\pmdott\alpha=\alpha\pmccap\alpha, & \\
	&& &\pmthm\pmdott\alpha=\alpha\pmccup\alpha. &
\end{flalign*}

The two last are the two forms of the law of tautology.

The law of absorption holds in the form
\[
	\pmthm\pmdott\alpha\pmcinc\beta\pmdot\pmiff\pmdot\alpha=\alpha\pmccap\beta.
\]

Thus for example ``all Cretans are liars'' is equivalent to ``Cretans are identical with lying Cretans.''

\begin{flalign*}
	&\text{\indent Just as we have} & &\pmthm\pmdott p\pmimp q\pmand q\pmimp r\pmdot\pmimp\pmdot p\pmimp r, &&& \\
	&\text{so we have} & &\pmthm\pmdott\alpha\pmcinc \beta\pmand\beta\pmcinc \gamma\pmdot\pmimp\pmdot\alpha\pmcinc \gamma. &&&
\end{flalign*}

This expresses the ordinary syllogism in Barbara (with the premisses interchanged); for ``$\alpha\pmcinc \beta$'' means the same as ``all $\alpha$'s are $\beta$'s,'' so that the above proposition states: ``If all $\alpha$'s are $\beta$'s, and all $\beta$'s are $\gamma$'s, then all $\alpha$'s are $\gamma$'s.'' (It should be observed that syllogisms are traditionally expressed with ``therefore,'' as if they asserted both premisses and conclusion. This is, of course, merely a slipshod way of speaking, since what is really asserted is only the connection of premisses with conclusion.)

The syllogism in Barbara when the minor premiss has an individual subject is
\[
	\pmthm\pmdott x\pmcin\beta\pmand\beta\pmcinc\gamma\pmdot\pmimp\pmdot x\pmcin\gamma,
\]
\textit{e.g.}\ ``if Socrates is a man, and all men are mortals, then Socrates is a mortal.'' This, as was pointed out by Peano, is not a particular case of ``$\alpha \pmcinc \beta \pmand \beta \pmcinc \gamma \pmdot \pmimp \pmdot \alpha \pmcinc \gamma$,'' since ``$x \pmcin \beta$'' is not a particular case of ``$\alpha \pmcinc \beta$.'' This point is important, since traditional logic is here mistaken. The nature and magnitude of its mistake will become clearer at a later stage.

For relations, we have precisely analogous definitions and propositions. We put 
\begin{flalign*}
	&& && &R \pmrcap S \pmiddf \pmrel{x}{y}{xRy \pmand xSy} & &\pmdf, & && \\
	\text{which leads to} && && &\pmthm\pmdott x(R\pmrcap S)y \pmdot \pmiddf \pmdot xRy \pmand xSy & &\pmdf. & &&
\end{flalign*}

\pagefirst{30} \begin{flalign*}
	\text{\indent Similarly} && && & R \pmrcup S \pmiddf \pmrel{x}{y}{xRy \pmdot\pmor\pmdot xSy} &\pmdf, && && \\
	&& && &\pmrcmp{R} \pmiddf \pmrel{x}{y}{\{\pmnot(xRy)\}} &\pmdf, && && \\
	&& && &R \pmrinc S \pmdot \pmiddf \pmdott xRy \pmdot \pmimp_{x,y} \pmdot xSy &\pmdf. && &&
\end{flalign*}

Generally, when we require analogous but different symbols for relations and for classes, we shall choose for relations the symbol obtained by adding a dot, in some convenient position, to the corresponding symbol for classes. (The dot must not be put on the line, since that would cause confusion with the use of dots as brackets.) But such symbols require and receive a special definition in each case.

A class is said to \textit{exist} when it has at least one member: ``$\alpha$ exists'' is denoted by ''$\pmcexists\alpha$.'' Thus we put
\[
	\pmcexists\alpha \pmdot \pmiddf \pmdot \pmsome{x}\pmdot x\pmcin \alpha \pmdf.
\]
The class which has no members is called the ``null-class,'' and is denoted by ``$\pmcnull$.'' Any propositional function which is always false determines the null-class. One such function is known to us already, namely ``$x$ is not identical with $x$,'' which we denote by ``$x \neq x$.'' Thus we may use this function for defining $\pmcnull$, and put
\[ 
	\pmcnull \pmiddf \pmcls{x}{x \neq x} \pmdf. 
\]

The class determined by a function which is always true is called the \textit{universal class}, and is represented by $\pmcuni$; thus
\[ 
	\pmcuni \pmiddf \pmcls{x}{x \neq x} \pmdf. 
\]

Thus $\pmcnull$ is the negation of $\pmcuni$. We have
\[
	\pmthm\pmdot \pmall{x}\pmdot x\pmcin \pmcuni,
\]
\textit{i.e.}\ ```$x$ is a member of $\pmcuni$' is always true''; and
\[
	\pmthm\pmdot \pmall{x}\pmdot x\pmnot \pmcin \pmcnull,
\]
\textit{i.e.}\ ```$x$ is a member of $\pmcnull$' is always false.'' Also
\[
	\pmthm\pmdott \alpha = \pmcnull \pmdot \pmiff \pmdot \pmnot \pmcexists\alpha,
\]
\textit{i.e.}\ ``$\alpha$ is the null-class'' is equivalent to ``$\alpha$ does not exist.''

For relations we use similar notations. We put
\[ 
	\pmrexists{R} \pmdot \pmiddf \pmdot \pmsome{x,y}\pmdot xRy \pmdf,
\]
\textit{i.e.}\ ``$\pmrexists{R}$'' means that there is at least one couple $x, y$ between which the relation $R$ holds. $\pmrnull$ will be the relation which never holds, and $\pmruni$ the relation which always holds. $\pmruni$ is practically never required; $\pmrnull$ will be the relation $\pmrel{x}{y}{x\neq x \pmand y \neq y}$. We have
\begin{flalign*}
	&& &\pmthm\pmdot \pmall{x, y}\pmdot\pmnot(x\pmrnull y),&  \\
	\text{and} && &\pmthm\pmdott R=\pmrnull \pmdot \pmiff \pmdot \pmnot\pmrexists R.& 
\end{flalign*}
\pagefirst{31} There are no classes which contain objects of more than one type. Accordingly there is a universal class and a null-class proper to each type of object. But these symbols need not be distinguished, since it will be found that there is no possibility of confusion. Similar remarks apply to relations.

\textit{Descriptions}. By a ``description'' we mean a phrase of the form ``the so-and-so'' or of some equivalent form. For the present, we confine our attention to \textit{the} in the singular. We shall use this word strictly, so as to imply uniqueness; \textit{e.g.}\ we should not say ``$A$ is \textit{the} son of $B$'' if $B$ had other sons besides $A$. Thus a description of the form ``the so-and-so'' will only have an application in the event of there being one so-and-so and no more. Hence a description requires some propositional function $\pmpf{\phi}{\pmhat{x}}$ which is satisfied by one value of $x$ and by no other values; then ``the $x$ which satisfies $\pmpf{\phi}{\pmhat{x}}$'' is a description which definitely describes a certain object, though we may not know what object it describes. For example, if $y$ is a man, ``$x$ is the father of $y$'' must be true for one, and only one, value of $x$. Hence ``the father of $y$'' is a description of a certain man, though we may not know what man it describes. A phrase containing ``the'' always presupposes some initial propositional function not containing ``the''; thus instead of ``$x$ is the father of $y$'' we ought to take as our initial function ``$x$ begot $y$''; then ``the father of $y$'' means the one value of $x$ which satisfies this propositional function.

If $\pmpf{\phi}{\pmhat{x}}$ is a propositional function, the symbol ``$\pmdsc{x}(\phi x)$'' is used in our symbolism in such a way that it can always be read as ``the $x$ which satisfies $\pmpf{\phi}{\pmhat{x}}$.'' But we do not define ``$\pmdsc{x}(\phi x)$'' as standing for ``the $x$ which satisfies $\pmpf{\phi}{\pmhat{x}}$,'' thus treating this last phrase as embodying a primitive idea. Every use of ``$\pmdsc{x}(\phi x)$,'' where it apparently occurs as a constituent of a proposition in the place of an object, is defined in terms of the primitive ideas already on hand. An example of this definition in use is given by the proposition ``$\pmexists\pmdsc{x}(\phi x)$'' which is considered immediately. The whole subject is treated more fully in Chapter III.

The symbol should be compared and contrasted with ``$\pmcls{x}{\phi x}$'' which in use can always be read as ``the $x$'s which satisfy $\pmpf{\phi}{\pmhat{x}}$.'' Both symbols are incomplete symbols defined only in use, and as such are discussed in Chapter III. The symbol ``$\pmcls{x}{\phi x}$'' always has an application, namely to the class determined by $\pmpf{\phi}{\pmhat{x}}$; but ``$\pmexists\pmdsc{x}(\phi x)$'' only has an application when $\pmpf{\phi}{\pmhat{x}}$ is only satisfied by one value of $x$, neither more nor less. It should also be observed that the meaning given to the symbol by the definition, given immediately below, of $\pmexists\pmdsc{x}(\phi x)$ does not presuppose that we know the meaning of ``one.'' This is also characteristic of the definition of any other use of $\pmdsc{x}(\phi x)$.

\pagefirst{32} We now proceed to define ``$\pmexists\pmdsc{x}(\phi x)$'' so that it can be read ``the $x$ satisfying $\pmpf{\phi}{\pmhat{x}}$ exists.'' (It will be observed that this is a different meaning of existence from that which we express by ``\rotatebox[origin=c]{180}{E}.'') Its definition is
\[
	\pmexists\pmdsc{x}(\phi x) \pmdot \pmiddf \pmdott \pmsome{c}\pmdott \phi x\pmdot\pmiff_x\pmdot x = c \pmdf,
\]
\textit{i.e.}\ ``the $x$ satisfying $\pmpf{\phi}{\pmhat{x}}$ exists'' is to mean ``there is an object $c$ such that $\phi x$ is true when $x$ is $c$ but not otherwise.''

The following are equivalent forms:
\begin{flalign*}
	&& &\pmthm\pmdottt \pmexists\pmdsc{x}(\phi x) \pmdot \pmiff \pmdott \pmsome{c}\pmdott \phi c \pmandd \phi x\pmdot \pmimp_x \pmdot x=c, & \\
	&& &\pmthm\pmdottt \pmexists\pmdsc{x}(\phi x) \pmdot \pmiff \pmdott \pmsome{c}\pmdott \phi c \pmandd \phi x \pmand \phi y \pmdot \pmimp_{x,y} \pmdot x=y, & \\
	&& &\pmthm\pmdottt \pmexists\pmdsc{x}(\phi x) \pmdot \pmiff \pmdott \pmsome{c}\pmdott \phi c \pmandd x \neq c \pmdot \pmimp_x \pmdot \pmnot \phi x. &
\end{flalign*}
The last of these states that ``the $x$ satisfying $\pmpf{\phi}{\pmhat{x}}$ exists'' is equivalent to ``there is an object $c$ satisfying $\pmpf{\phi}{\pmhat{x}}$, and every object other than $c$ does not satisfy $\pmpf{\phi}{\pmhat{x}}$.''

The kind of existence just defined covers a great many cases. Thus for example ``the most perfect Being exists'' will mean:
\[ 
	\pmsome{c}\pmdott x \text{ is most perfect} \pmdot \pmiff_x \pmdot x =c,
\]
which, taking the last of the above equivalences, is equivalent to 
\[ 
	\pmsome{c}\pmdott c \text{ is most perfect} \pmandd x \neq c \pmdot \pmiff_x \pmdot x \text{ is not most perfect}.
\]

A proposition such as ``Apollo exists'' is really of the same logical form, although it does not explicitly contain the word \textit{the}. For ``Apollo'' means really ``the object having such-and-such properties,'' say ``the object having the properties enumerated in the Classical Dictionary\footnote{The same principle applies to many uses of the proper names of existent objects, \textit{e.g.}\ to all uses of proper names for objects known to the speaker only by report, and not by personal acquaintance.}.'' If these properties make up the propositional function $\phi x$, then ``Apollo'' means ``$\pmdsc{x}(\phi x)$,'' and ``Apollo exists'' means ``$\pmexists\pmdsc{x}(\phi x)$.'' To take another illustration, ``the author of Waverley'' means ``the man who (or rather, the object which) wrote Waverley.'' Thus ``Scott is the author of Waverley'' is 
\[
	\text{Scott} = \pmdsc{x}(x \text{ wrote Waverley}). 
\]
Here (as we observed before) the importance of \textit{identity} in connection with descriptions plainly appears.

The notation ``$\pmdsc{x}(\phi x)$,'' which is long and inconvenient, is seldom used, being chiefly required to lead up to another notation, namely ``$\pmdscf{R}{y}$,'' meaning ``the object having the relation $R$ to $y$.'' That is, we put
\[
	\pmdscf{R}{y} \pmiddf \pmdsc{x}(xRy) \pmdf.
\]
The inverted comma may be read ``of.'' Thus ``$\pmdscf{R}{y}$'' is read ``the $R$ of $y$.'' Thus if $R$ is the relation of father to son, ``$\pmdscf{R}{y}$'' means ``the father of $y$''; if $R$ is the relation of son to father, ``$\pmdscf{R}{y}$'' means ``the son of $y$,'' which will \pagefirst{33} only ``exist'' if $y$ has one son and no more. $\pmdscf{R}{y}$ is a function of $y$, but not a propositional function; we shall call it a \textit{descriptive} function. All the ordinary functions of mathematics are of this kind, as will appear more fully in the sequel. Thus in our notation, ``$\sin y$'' would be written ``$\sin`y$,'' and ``$\sin$'' would stand for the relation which $\sin`y$ has to $y$. Instead of a variable descriptive function $fy$, we put $\pmdscf{R}{y}$, where the variable relation $R$ takes the place of the variable function $f$. A descriptive function will in general exist while $y$ belongs to a certain domain, but not outside that domain; thus if we are dealing with positive rationals, $\surd{y}$ will be significant if $y$ is a perfect square, but not otherwise; if we are dealing with real numbers, and agree that ``$\surd{y}$'' is to mean the positive square root (or, is to mean the negative square root), $\surd{y}$ will be significant provided $y$ is positive, but not otherwise; and so on. Thus every descriptive function has what we may call a ``domain of definition'' or a ``domain of existence,'' which may be thus defined: If the function in question is $\pmdscf{R}{y}$, its domain of definition or of existence will be the class of those arguments $y$ for which we have $\pmexists\pmdscf{R}{y}$, \textit{i.e.}\ for which $\pmexists\pmdsc{x}(xRy)$, \textit{i.e.}\ for which there is one $x$, and no more, having the relation $R$ to $y$. 

If $R$ is any relation, we will speak of $\pmdscf{R}{y}$ as the ``associated descriptive function.'' A great many of the constant relations which we shall have occasion to introduce are only or chiefly important on account of their associated descriptive functions. In such cases, it is easier (though less correct) to begin by assigning the meaning of the descriptive function, and to deduce the meaning of the relation from that of the descriptive function. This will be done in the following explanations of notation. 

\textit{Various descriptive functions of relations}. If $R$ is any relation, the converse of $R$ is the relation which holds between $y$ and $x$ whenever $R$ holds between $x$ and $y$. Thus greater is the converse of less, before of after, cause of effect, husband of wife, etc. The converse of $R$ is written\footnote{The second of these notations is taken from Schr{\"o}der's \textit{Algebra und Logik der Relative}.} $\pmcnvr{R}$ or $\pmcrel{R}$. The definition is
\begin{align*}
	\pmcrel{R} \pmiddf \pmrel{x}{y}{(yRx)} \pmdf, \\
	\pmcnvr{R} \pmiddf \pmcrel{R} \pmdf.
\end{align*}
The second of these is not a formally correct definition, since we ought to define ``Cnv'' and deduce the meaning of $\pmcnvr{R}$. But it is not worth while to adopt this plan in our present introductory account, which aims at simplicity rather than formal correctness.

A relation is called \textit{symmetrical} if $R = \pmcrel{R}$, \textit{i.e.}\ if it holds between $y$ and $x$ whenever it holds between $x$ and $y$ (and therefore vice versa). Identity, \pagefirst{34} diversity, agreement or disagreement in any respect, are symmetrical relations. A relation is called \textit{asymmetrical} when it is incompatible with its converse, \textit{i.e.}\ when $R\pmrcap \pmcrel{R} = \pmrnull$, or, what is equivalent,
\[
	xRy \pmdot \pmimp_{x,y} \pmdot \pmnot(yRx).
\]

Before and after, greater and less, ancestor and descendant, are asymmetrical, as are all other relations of the sort that lead to \textit{series}. But there are many asymmetrical relations which do not lead to series, for instance, that of wife's brother\footnote{This relation is not strictly asymmetrical, but is so except when the wife's brother is also the sister's husband. In the Greek Church the relation is strictly asymmetrical.}. A relation may be neither symmetrical nor asymmetrical; for example, this holds of the relation of inclusion between classes: $\alpha \pmcinc \beta$ and $\beta \pmcinc \alpha$ will both be true if $\alpha = \beta$, but otherwise only one of them, at most, will be true. The relation \textit{brother} is neither symmetrical nor asymmetrical, for if $x$ is the brother of $y$, $y$ may be either the brother or the sister of $x$.

In the propositional function $xRy$, we call $x$ the \textit{referent} and $y$ the \textit{relatum}. The class $\pmcls{x}{xRy}$, consisting of all the $x$'s which have the relation $R$ to $y$, is called the class of referents of $y$ with respect to $x$; the class $\pmcls{y}{xRy}$, consisting of all the $y$'s to which $x$ has the relation $R$, is called the class of relata of $x$ with respect to $R$. These two classes are denoted respectively by $\pmrrf{R}{y}$ and $\pmrrl{R}{x}$. Thus
\begin{align*}
	\pmrrf{R}{y} \pmiddf \pmcls{x}{xRy} \pmdf, \\
	\pmrrl{R}{x} \pmiddf \pmcls{y}{xRy} \pmdf.
\end{align*}
The arrow runs towards $y$ in the first case, to show that we are concerned with things having the relation $R$ to $y$; it runs away from $x$ in the second case to show that the relation $R$ goes from $x$ to the members of $\pmrrl{R}{x}$. It runs in fact \textit{from} a referent and \textit{towards} a relatum.

The notations $\pmrrf{R}{y}$, $\pmrrl{R}{x}$ are very important, and are used constantly. If $R$ is the relation of parent to child, $\pmrrl{R}{x} =$ the parents of $y$, $\pmrrl{R}{x} =$ the children of $x$. We have
\begin{flalign*}
	&& &\pmthm\pmdott x\pmcin \pmrrf{R}{y} \pmdot \pmiff \pmdot xRy & \\
	\text{and} && & \pmthm\pmdott y \pmcin \pmrrl{R}{y} \pmdot \pmiff \pmdot xRy. &
\end{flalign*}
These equivalences are often embodied in common language. For example, we say indiscriminately ``$x$ is an inhabitant of London'' or ``$x$ inhabits London.'' If we put ``$R$'' for ``inhabits,'' ``$x$ inhabits London'' is ``$xR$ London,'' while ``$x$ is an inhabitant of London'' is ``$x \pmcin \pmrrf{R}{\text{London}}$.''

\pagefirst{35} Instead of $\overrightarrow{R}$ and $\overleftarrow{R}$ we sometimes use $\pmsg R, \pmgs R$, where ``sg'' stands for ``sagitta,'' and ``gs'' is ''sg'' backwards. Thus we put
\begin{flalign*}
	&& &\pmsg R \pmiddf \overrightarrow{R} \pmdf &\\
	&& &\pmgs R \pmiddf \overleftarrow{R} \pmdf. &
\end{flalign*}
These notations are sometimes more convenient than an arrow when the relation concerned is represented by a combination of letters, instead of a single letter such as $R$. Thus \textit{e.g.}\ we should write $\pmsg(R\pmrcap S)$, rather than put an arrow over the whole length of $(R\pmrcap S)$.

The class of all terms that have the relation $R$ to something or other is called the \textit{domain} of $R$. Thus if $R$ is the relation of parent and child, the domain of $R$ will be the class of parents. We represent the domain of $R$ by ``$\pmdm{R}$.'' Thus we put
\[ 
	\pmdm{R} \pmiddf \pmhat{x}\{\pmsome{y}\pmdot xRy\} \pmdf.
\]
Similarly the class of all terms to which something or other has the relation $R$ is called the \textit{converse domain} of $R$; it is the same as the domain of the converse of $R$. The converse domain of $R$ is represented by ``$\pmcdm{R}$''; thus
\[ 
	\pmcdm{R} \pmiddf \pmhat{y}\{\pmsome{x}\pmdot xRy\} \pmdf.
\]
The sum of the domain and the converse domain is called the \textit{field}, and is represented by $\pmfld R$: thus
\[
	\pmfld R \pmiddf \pmdm{R} \cup \pmcdm{R} \pmdf.
\]

The \textit{field} is chiefly important in connection with series. If $R$ is the ordering relation of a series, $\pmfld R$ will be the class of terms of the series, $\pmdm{R}$ will be all the terms except the last (if any), and $\pmcdm{R}$ will be all the terms except the first (if any). The first term, if it exists, is the only member of $\pmdm{R} \cap \pmccmp{\pmcdm{R}}$, since it is the only term which is a predecessor but not a follower. Similarly the last term (if any) is the only member of $\pmcdm{R} \cap \pmccmp{\pmdm{R}}$. The condition that a series should have no end is $\pmcdm{R} \pmcinc \pmdm R$, \textit{i.e.}\ ``every follower is a predecessor''; the condition for no beginning is $\pmdm{R} \pmcinc \pmcdm{R}$. These conditions are equivalent respectively to $\pmdm{R} = \pmfld R$ and $\pmcdm{R} = \pmfld R$.

The \textit{relative product} of two relations $R$ and $S$ is the relation which holds between $x$ and $z$ when there is an intermediate term $y$ such that $x$ has the relation $R$ to $y$ and $y$ has the relation $S$ to $z$. The relative product of $R$ and $S$ is represented by $\pmrprd{R}{S}$; thus we put
\begin{flalign*}
	&& \pmrprd{R}{S} \pmiddf \pmrel{x}{z}{\{\pmsome{y}\pmdot xRy \pmand ySz\}} \pmdf,&& \\
	\text{whence} && \pmthm\pmdott x(\pmrprd{R}{S})z \pmdot\pmiff \pmdot \pmsome{y}\pmdot xRy \pmand ySz.&&
\end{flalign*}
Thus ``paternal aunt'' is the relative product of \textit{sister} and \textit{father}; ``paternal grandmother'' is the relative product of \textit{mother} and \textit{father}; ``maternal \pagefirst{36} grandfather'' is the relative product of \textit{father} and \textit{mother}. The relative product is not commutative, but it obeys the associative law, \textit{i.e.}\
\[ 
	\pmthm\pmdot \pmrprd{(\pmrprd{P}{Q})}{R} = \pmrprd{P}{(\pmrprd{Q}{R})}.
\]
It also obeys the distributive law with regard to the logical addition of relations, \textit{i.e.}\ we have
\begin{align*}
	\pmthm\pmdot \pmrprd{P}{(Q \pmrcup R)} = (\pmrprd{P}{Q}) \pmrcup (\pmrprd{P}{R}), \\
	\pmthm\pmdot \pmrprd{(Q \pmrcup R)}{P} = (\pmrprd{Q}{P})\pmrcup (\pmrprd{R}{P}). 
\end{align*}
But with regard to the logical product, we have only
\begin{align*}
	\pmthm\pmdot \pmrprd{P}{(Q \pmrcap R)} \pmrinc (\pmrprd{P}{Q}) \pmrcap (\pmrprd{P}{R}), \\
	\pmthm\pmdot \pmrprd{(Q \pmrcap R)}{P} \pmrinc (\pmrprd{Q}{P})\pmrcap (\pmrprd{R}{P}). 
\end{align*}

The relative product does not obey the law of tautology, \textit{i.e.}\ we do not have in general $\pmrprd{R}{R} = R$. We put
\[
	\pmrprdn{R}{2} \pmiddf \pmrprd{R}{R} \pmdf.
\]
Thus paternal grandfather $=$ (father)$^2$, \\
\indent maternal grandmother $=$ (mother)$^2$.

A relation is called \textit{transitive} when $\pmrprdn{R}{2}  \pmrinc R$, \textit{i.e.}\ when, if $xRy$ and $yRz$, we always have $xRz$, \textit{i.e.}\ when
\[
	xRy \pmand yRz \pmdot\pmimp_{x,y,z} \pmdot xRz.
\]
Relations which generate series are always transitive; thus \textit{e.g.}\
\[
	x > y \pmand y > z \pmdot \pmimp_{x,y,z}\pmdot x > z.
\]
If $P$ is a relation which generates a series, $P$ may conveniently be read ``precedes''; thus ``$xPy\pmand yPz\pmdot \pmimp_{x,y,z}\pmdot xPz$'' becomes ``if $x$ precedes $y$ and $y$ precedes $z$, then $x$ always precedes $z$.'' The class of relations which generate series are partially characterized by the fact that they are transitive and asymmetrical, and never relate a term to itself.

If $P$ is a relation which generates a series, and if we have not merely $P^2 \pmcinc P$, but $P^2 = P$, then $P$ generates a series which is \textit{compact} (\textit{{\"u}berall dicht}), \textit{i.e.}\ such that there are terms between any two. For in this case we have
\[ 
	xPz \pmdot \pmimp \pmdot \pmsome{y}\pmdot xPy \pmand yPz,
\]
\textit{i.e.}\ if $x$ precedes $z$, there is a term $y$ such that $x$ precedes $y$ and $y$ precedes $z$, \textit{i.e.}\ there is a term between $x$ and $z$. Thus among relations which generate series, those which generate compact series are those for which $P^2=P$.

Many relations which do not generate series are transitive, for example, identity, or the relation of inclusion between classes. Such cases arise when the relations are not asymmetrical. Relations which are transitive and symmetrical are an important class: they may be regarded as consisting in the possession of some common property.

\pagefirst{37} \textit{Plural descriptive functions}. The class of terms $x$ which have the relation $R$ to some member of a class $\alpha$ is denoted by $\pmdscff{R}{\alpha}$ or $\pmdscfr{R}{\alpha}$. The definition is
\[
	\pmdscff{R}{\alpha} \pmiddf \pmhat{x}\{\pmsome{y}\pmdot y\pmcin \alpha \pmand xRy\} \pmdf.
\]
Thus for example let $R$ be the relation of \textit{inhabiting}, and $\alpha$ the class of towns; then $\pmdscff{R}{\alpha} = $ inhabitants of towns. Let $R$ be the relation ``less than'' among rationals, and $\alpha$ the class of those rationals which are of the form $1-2^{-n}$, for integral values of $n$; then $\pmdscff{R}{\alpha}$ will be all rationals less than some member of $\alpha$, \textit{i.e.}\ all rationals less than 1. If $P$ is the generating relation of a series, and $\alpha$ is any class of members of $P$, $\pmdscff{P}{\alpha}$ will be predecessors of $\alpha$'s, \textit{i.e.}\ the segment defined by $\alpha$. If $P$ is a relation such that $\pmdscf{P}{y}$ always exists when $y \pmcin \alpha$, $\pmdscff{P}{\alpha}$ will be the class of all terms of the form $\pmdscf{P}{y}$ for values of $y$ which are members of $\alpha$; \textit{i.e.}\
\[
	\pmdscff{P}{\alpha} = \pmhat{x}\{\pmsome{y}\pmdot y \pmcin \alpha \pmand x = \pmdscf{P}{y}\}.
\]
Thus a member of the class ``fathers of great men'' will be the father of $y$, where $y$ is some great man. In other cases, this will not hold; for instance, let $P$ be the relation of a number to any number of which it is a factor; then $\pmdscff{P}{(\text{even numbers})} = $ factors of even numbers, but this class is not composed of terms of the form ``\textit{the} factor of $x$,'' where $x$ is an even number, because numbers do not have only one factor apiece.

\textit{Unit classes}. The class whose only member is $x$ might be thought to be identical with $x$, but Peano and Frege have shown that this is not the case. (The reasons why this is not the case will be explained in a preliminary way in Chapter II of the Introduction.) We denote by ``$\pmcunit{x}$'' the class whose only member is $x$: thus
\[
	\pmcunit{x} \pmiddf \pmcls{y}{y=x} \pmdf,
\]
\textit{i.e.}\ ``$\pmcunit{x}$'' means ``the class of objects which are identical with $x$.''

The class consisting of $x$ and $y$ will be $\pmcunit{x} \pmccup \pmcunit{y}$; the class got by adding $x$ to a class $\alpha$ will be $\alpha \pmccup \pmcunit{x}$; the class got by taking away $x$ from a class $\alpha$ will be $\alpha \pmccmp{\pmcunit{x}}$. (We write $\alpha \pmccmp{\beta}$ as an abbreviation for $\alpha \pmccap \pmccmp{\beta}$.)

It will be observed that unit classes have been defined without reference to the number 1; in fact, we use unit classes to define the number 1. This number is defined as the class of unit classes, \textit{i.e.}\
\[ 
	1 \pmiddf \pmhat{\alpha}\{\pmsome{x}\pmdot\alpha=\pmcunit{x}\} \pmdf.
\]
This leads to
\[
	\pmthm\pmdottt \alpha \pmcin 1 \pmdot \pmiff \pmdott \pmsome{x} \pmdott y \pmcin \alpha \pmdot \pmiff_y \pmdot y=x.
\]

From this it appears further that
\begin{flalign*}
	&& &\pmthm \pmdott \alpha \pmcin 1 \pmdot \pmiff \pmdot \pmexists\pmdsc{x}(x\pmcin \alpha), &\\
	\text{whence} && &\pmthm \pmdott \pmcls{z}{\phi z} \pmcin 1 \pmdot \pmiff \pmdot \pmexists\pmdsc{x}(\phi x).&
\end{flalign*}
\textit{i.e.}\ ``$\pmcls{z}{\phi z}$ is a unit class'' is equivalent to ``the $x$ satisfying $\phi$ exists.''

\pagefirst{38} If $\alpha \pmcin 1$, $\pmcunits{\alpha}$ is the only member of $\alpha$, for the only member of $\alpha$ is the only term to which $\alpha$ has the relation $\iota$. Thus ``$\pmcunits{\alpha}$'' takes the place of ``$\pmdsc{x}(\phi x)$,'' if $\alpha$ stands for $\pmcls{z}{\phi z}$. In practice, ``$\pmcunits{\alpha}$'' is a more convenient notation than ``$\pmdsc{x}(\phi x)$,'' and is generally used instead of ``$\pmdsc{x}(\phi x)$.''

The above account, has explained most of the logical notation employed in the present work. In the applications to various parts of mathematics, other definitions are introduced; but the objects defined by these later definitions belong, for the most part, rather to mathematics than to logic. The reader who has mastered the symbols explained above will find that any later formulae can be deciphered by the help of comparatively few additional definitions.

\chapter*{\centering CHAPTER II. \\ THE THEORY OF LOGICAL TYPES} \addcontentsline{toc}{chapter}{CHAPTER II. THE THEORY OF LOGICAL TYPES} \pagefirst{39} 

THE theory of logical types, to be explained in the present Chapter, recommended itself to us in the first instance by its ability to solve certain contradictions, of which the one best known to mathematicians is Burali-Forti's concerning the greatest ordinal. But the theory in question is not wholly dependent upon this indirect recommendation: it has also a certain consonance with common sense which makes it inherently credible. In what follows, we shall therefore first set forth the theory on its own account, and then apply it to the solution of the contradictions.

\section*{\centering I. \textit{The Vicious-Circle Principle}.} 

An analysis of the paradoxes to be avoided shows that they all result from a certain kind of vicious circle\footnote{See the last section of the present Chapter. Cf. also H. Poincar\'e, ``Les math\'ematiques et la logique,'' \textit{Revue de M\'etaphysique et de Morale}, Mai 1906, p. 307.}. The vicious circles in question arise from supposing that a collection of objects may contain members which can only be defined by means of the collection as a whole. Thus, for example, the collection of \textit{propositions} will be supposed to contain a proposition stating that ``all propositions are either true or false.'' It would seem, however, that such a statement could not be legitimate unless ``all propositions'' referred to some already definite collection, which it cannot do if new propositions are created by statements about ``all propositions.'' We shall, therefore, have to say that statements about ``all propositions'' are meaningless. More generally, given any set of objects such that, if we suppose the set to have a total, it will contain members which presuppose this total, then such a set cannot have a total. By saying that a set has ``no total,'' we mean, primarily, that no significant statement can be made about ``all its members.'' Propositions, as the above illustration shows, must be a set having no total. The same is true, as we shall shortly see, of propositional functions, even when these are restricted to such as can significantly have as argument a given object a. In such cases, it is necessary to break up our set into smaller sets, each of which is capable of a total. This is what the theory of types aims at effecting.

\pagefirst{40} The principle which enables us to avoid illegitimate totalities may be stated as follows: ``Whatever involves \textit{all} of a collection must not be one of the collection''; or, conversely: ``If, provided a certain collection had a total, it would have members only definable in terms of that total, then the said collection has no total.'' We shall call this the ``vicious-circle principle,'' because it enables us to avoid the vicious circles involved in the assumption of illegitimate totalities. Arguments which are condemned by the vicious circle principle will be called ``vicious-circle fallacies.'' Such arguments, in certain circumstances, may lead to contradictions, but it often happens that the conclusions to which they lead are in fact true, though the arguments are fallacious. Take, for example, the law of excluded middle, in the form ``all propositions are true or false.'' If from this law we argue that, because the law of excluded middle is a proposition, therefore the law of excluded middle is true or false, we incur a vicious-circle fallacy. ``All propositions'' must be in some way limited before it becomes a legitimate totality, and any limitation which makes it legitimate must make any statement about the totality fall outside the totality. Similarly, the imaginary sceptic, who asserts that he knows nothing, and is refuted by being asked if he knows that he knows nothing, has asserted nonsense, and has been fallaciously refuted by an argument which involves a vicious-circle fallacy. In order that the sceptic's assertion may become significant, it is necessary to place some limitation upon the things of which he is asserting his ignorance, because the things of which it is possible to be ignorant form an illegitimate totality. But as soon as a suitable limitation has been placed by him upon the collection of propositions of which he is asserting his ignorance, the proposition that he is ignorant of every member of this collection must not itself be one of the collection. Hence any significant scepticism is not open to the above form of refutation.

The paradoxes of symbolic logic concern various sorts of objects: propositions, classes, cardinal and ordinal numbers, etc. All these sorts of objects, as we shall show, represent illegitimate totalities, and are therefore capable of giving rise to vicious-circle fallacies. But by means of the theory (to be explained in Chapter III) which reduces statements that are verbally concerned with classes and relations to statements that are concerned with propositional functions, the paradoxes are reduced to such as are concerned with propositions and propositional functions. The paradoxes that concern propositions are only indirectly relevant to mathematics, while those that more nearly concern the mathematician are all concerned with \textit{propositional functions}. We shall therefore proceed at once to the consideration of propositional functions.

\section*{\centering II. \textit{The Nature of Propositional Functions}.} \pagefirst{41} 

By a ``propositional function'' we mean something which contains a variable $x$, and expresses a \textit{proposition} as soon as a value is assigned to $x$. That is to say, it differs from a proposition solely by the fact that it is ambiguous: it contains a variable of which the value is unassigned. It agrees with the ordinary functions of mathematics in the fact of containing an unassigned variable; where it differs is in the fact that the values of the function are propositions. Thus \textit{e.g.}\ ``$x$ is a man'' or ``$\sin x = 1$'' is a propositional function. We shall find that it is possible to incur a vicious-circle fallacy at the very outset, by admitting as possible arguments to a propositional function terms which presuppose the function. This form of the fallacy is very instructive, and its avoidance leads, as we shall see, to the hierarchy of types.

The question as to the nature of a function\footnote{When the word ``function'' is used in the sequel, ``propositional function'' is always meant. Other functions will not be in question in the present Chapter.} is by no means an easy one. It would seem, however, that the essential characteristic of a function is \textit{ambiguity}. Take, for example, the law of identity in the form ``$A$ is $A$,'' which is the form in which it is usually enunciated. It is plain that, regarded psychologically, we have here a single judgment. But what are we to say of the object of the judgment? We are not judging that Socrates is Socrates, nor that Plato is Plato, nor any other of the definite judgments that are instances of the law of identity. Yet each of these judgments is, in a sense, within the scope of our judgment. We are in fact judging an ambiguous instance of the propositional function ``$A$ is $A$.'' We appear to have a single thought which does not have a definite object, but has as its object an undetermined one of the values of the function ``$A$ is $A$.'' It is this kind of ambiguity that constitutes the essence of a function. When we speak of ``$\phi x$,'' where $x$ is not specified, we mean one value of the function, but not a definite one. We may express this by saying that ``$\phi x$'' ambiguously denotes $\phi a$, $\phi b$, $\phi c$, etc., where $\phi a$, $\phi b$, $\phi c$, etc., are the various values of ``$\phi x$.'' 

When we say that ``$\phi x$'' ambiguously denotes $\phi a$, $\phi b$, $\phi c$, etc., we mean that ``$\phi x$'' means one of the objects $\phi a$, $\phi b$, $\phi c$, etc., though not a definite one, but an undetermined one. It follows that ``$\phi x$''  only has a well-defined meaning (well-defined, that is to say, except in so far as it is of its essence to be ambiguous) if the objects $\phi a$, $\phi b$, $\phi c$, etc., are well-defined. That is to say, a function is not a well-defined function unless all its values are already well-defined. It follows from this that no function can have among its values anything which presupposes the function, for if it had, we could not regard the objects ambiguously denoted by the function as definite until the function was definite, while conversely, as we have just seen, the function cannot be \pagefirst{42} definite until its values are definite. This is a particular case, but perhaps the most fundamental case, of the vicious-circle principle. A function is what ambiguously denotes some one of a certain totality, namely the values of the function; hence this totality cannot contain any members which involve the function, since, if it did, it would contain members involving the totality, which, by the vicious-circle principle, no totality can do.

It will be seen that, according to the above account, the values of a function are presupposed by the function, not vice versa. It is sufficiently obvious, in any particular case, that a value of a function does not presuppose the function. Thus for example the proposition ``Socrates is human'' can be perfectly apprehended without regarding it as a value of the function ``$x$ is human.'' It is true that, conversely, a function can be apprehended without its being necessary to apprehend its values severally and individually. If this were not the case, no function could be apprehended at all, since the number of values (true and false) of a function is necessarily infinite and there are necessarily possible arguments with which we are unacquainted. What is necessary is not that the values should be given individually and extensionally, but that the totality of the values should be given intensionally, so that, concerning any assigned object, it is at least theoretically determinate whether or not the said object is a value of the function. 

It is necessary practically to distinguish the function itself from an undetermined value of the function. We may regard the function itself as that which ambiguously denotes, while an undetermined value of the function is that which is ambiguously denoted. If the undetermined value is written ``$\phi x$ we will write the function itself ``$\pmpf{\phi}{\pmhat{x}}$.'' (Any other letter may be used in place of $x$.) Thus we should say ``$\phi x$ is a proposition,'' but ``$\pmpf{\phi}{\pmhat{x}}$ is a propositional function.'' When we say ``$\phi x$ is a proposition,'' we mean to state something which is true for every possible value of $x$, though we do not decide what value $x$ is to have. We are making an ambiguous statement about any value of the function. But when we say ``$\pmpf{\phi}{\pmhat{x}}$ is a function,'' we are not making an ambiguous statement. It would be more correct to say that we are making a statement about an ambiguity, taking the view that a function is an ambiguity. The function itself, $\pmpf{\phi}{\pmhat{x}}$ is the single thing which ambiguously denotes its many values; while $\phi x$, where $x$ is not specified, is one of the denoted objects, with the ambiguity belonging to the manner of denoting.

We have seen that, in accordance with the vicious-circle principle, the values of a function cannot contain terms only definable in terms of the function. Now given a function $\pmpf{\phi}{\pmhat{x}}$, the values for the function\footnote{We shall speak in this Chapter of ``values \textit{for} $\pmpf{\phi}{\pmhat{x}}$,'' meaning in each case the same thing, namely $\phi a$, $\phi b$, $\phi c$, etc. The distinction of phraseology serves to avoid ambiguity where several variables are concerned, especially when one of them is a function.} are all pro\pagefirst{43}positions of the form $\phi x$. It follows that there must be no propositions, of the form $\phi x$, in which $x$ has a value which involves $\pmpf{\phi}{\pmhat{x}}$. (If this were the case, the values of the function would not all be determinate until the function was determinate, whereas we found that the function is not determinate unless its values are previously determinate.) Hence there must be no such thing as the value for $\pmpf{\phi}{\pmhat{x}}$ with the argument $\pmpf{\phi}{\pmhat{x}}$, or with any argument which involves $\pmpf{\phi}{\pmhat{x}}$. That is to say, the symbol ``$\phi(\pmpf{\phi}{\pmhat{x}})$'' must not express a proposition, as ``$\phi a$'' does if $a$ is a value for $\pmpf{\phi}{\pmhat{x}}$. In fact ``$\phi(\pmpf{\phi}{\pmhat{x}})$'' must be a symbol which does not express anything: we may therefore say that it is not significant. Thus given any function $\pmpf{\phi}{\pmhat{x}}$, there are arguments with which the function has no value, as well as arguments with which it has a value. We will call the arguments with which $\pmpf{\phi}{\pmhat{x}}$ has a value ``possible values of $x$.'' We will say that $\pmpf{\phi}{\pmhat{x}}$ is ``significant with the argument $x$'' when $\pmpf{\phi}{\pmhat{x}}$ has a value with the argument $x$.

When it is said that \textit{e.g.}\ ``$\phi(\pmpf{\phi}{\pmhat{z}})$'' is meaningless, and therefore neither true nor false, it is necessary to avoid a misunderstanding. If ``$\phi(\pmpf{\phi}{\pmhat{z}})$'' were interpreted as meaning ``the value for $\pmpf{\phi}{\pmhat{z}}$ with the argument $\pmpf{\phi}{\pmhat{z}}$ is true,'' that would be not meaningless, but false. It is false for the same reason for which ``the King of France is bald'' is false, namely because there is no such thing as ``the value for $\pmpf{\phi}{\pmhat{z}}$ with the argument $\pmpf{\phi}{\pmhat{z}}$.'' But when, with some argument $a$, we assert $\phi a$, we are not meaning to assert ``the value for $\pmpf{\phi}{\pmhat{z}}$ with the argument $a$ is true''; we are meaning to assert the actual proposition which is the value for $\pmpf{\phi}{\pmhat{z}}$ with the argument $a$. Thus for example if $\pmpf{\phi}{\pmhat{x}}$ is ``$\pmpf{\pmhat{x}}{\text{ is a man}}$,'' $\phi$(Socrates) will be ``Socrates is a man,'' \textit{not} ``the value for the function `$\pmpf{\pmhat{x}}{\text{ is a man}}$,' with the argument Socrates, is true.'' Thus in accordance with our principle that ``$\phi(\pmpf{\phi}{\pmhat{z}})$'' is meaningless, we cannot legitimately deny ``the function `$\pmpf{\pmhat{x}}{\text{ is a man}}$' is a man,'' because this is nonsense, but we can legitimately deny ``the value for the function `$\pmpf{\pmhat{x}}{\text{ is a man}}$' with the argument `$\pmpf{\pmhat{x}}{\text{ is a man}}$' is true,'' not on the ground that the value in question is false, but on the ground that there is no such value for the function.

We will denote by the symbol ``$\pmall{x}\pmdot \phi x$'' the proposition ``$\phi x$ always\footnote{We use ``always'' as meaning ``in all cases,'' not ``at all times.'' Similarly ``sometimes'' will mean ``in some cases.''},'' \textit{i.e.}\ the proposition which asserts \textit{all} the values for $\pmpf{\phi}{\pmhat{x}}$. This proposition involves the function $\pmpf{\phi}{\pmhat{x}}$, not merely an ambiguous value of the function. The assertion of $\phi x$, where $x$ is unspecified, is a different assertion from the one which asserts all values for $\pmpf{\phi}{\pmhat{x}}$, for the former is an ambiguous assertion, whereas the latter is in no sense ambiguous. It will be observed that ``$\pmall{x}\pmdot \phi x$'' does not assert ``$\phi x$ with all values of $x$,'' because, as we have seen, there must be values of $x$ with which ``$\phi x$'' is meaningless. What is asserted by ``$\pmall{x}\pmdot \phi x$'' is all propositions which are values for $\pmpf{\phi}{\pmhat{x}}$; hence it is \pagefirst{44} only with such values of m as make ``$\phi x$'' significant, \textit{i.e.}\ with all \textit{possible} arguments, that $\phi x$ is asserted when we assert ``$\pmall{x} \pmdot \phi x$.'' Thus a convenient way to read ``$\pmall{x}\pmdot \phi x$'' is ``$\phi x$ is true with all possible values of $x$.'' This is, however, a less accurate reading than ``$\phi x$ always,'' because the notion of \textit{truth} is not part of the content of what is judged. When we judge ``all men are mortal,'' we judge truly, but the notion of truth is not necessarily in our minds, any more than it need be when we judge ``Socrates is mortal.''

\section*{\centering III. \textit{Definition and Systematic Ambiguity of Truth and Falsehood}.}

Since ``$\pmall{x} \pmdot \phi x$'' involves the function $\pmpf{\phi}{\pmhat{x}}$, it must, according to our principle, be impossible as an argument to $\phi$. That is to say, the symbol ``$\phi\{\pmall{x} \pmdot \phi x\}$'' must be meaningless. This principle would seem, at first sight, to have certain exceptions. Take, for example, the function ``$\pmhat{p}$ is false,'' and consider the proposition ``$\pmall{p}\pmdot p$ is false.'' This should be a proposition asserting all propositions of the form ``$p$ is false.'' Such a proposition, we should be inclined to say, must be false, because ``$p$ is false'' is not always true. Hence we should be led to the proposition
\[
	\text{``}\{\pmall{p}\pmdot p \text{ is false}\}\text{ is false,''}
\]
\textit{i.e.}\ we should be led to a proposition in which ``$\pmall{p}\pmdot p$ is false'' is the argument to the function ``$\pmhat{p}$ is false,'' which we had declared to be impossible. Now it will be seen that ``$\pmall{p}\pmdot p$ is false,'' in the above, purports to be a proposition about \textit{all} propositions, and that, by the general form of the vicious-circle principle, there must be no propositions about all propositions. Nevertheless, it seems plain that, given any function, there is a proposition (true or false) asserting all its values. Hence we are led to the conclusion that ``$p$ is false'' and ``$q$ is false'' must not always be the values, with the arguments $p$ and $q$, for a single function ``$\pmhat{p}$ is false.'' This, however, is only possible if the word ``false'' really has many different meanings, appropriate to propositions of different kinds.

That the words ``true'' and ``false'' have many different meanings, according to the kind of proposition to which they are applied, is not difficult to see. Let us take any function $\pmpf{\phi}{\pmhat{x}}$, and let $\phi a$ be one of its values. Let us call the sort of truth which is applicable to $\phi a$ ``\textit{first} truth.'' (This is not to assume that this would be first truth in another context: it is merely to indicate that it is the first sort of truth in our context.) Consider now the proposition $\pmall{x}\pmdot\phi x$. If this has truth of the sort appropriate to it, that will mean that every value $\phi x$ has ``first truth.'' Thus if we call the sort of truth that is appropriate to $\pmall{x}\pmdot\phi x$ ``\textit{second} truth,'' we may define ``$\{\pmall{x}\pmdot\phi x\}$ has second truth'' as meaning ``every value for $\pmpf{\phi}{\pmhat{x}}$ has first truth,'' \textit{i.e.}\ ``$\pmall{x}\pmdot(\phi x$ has first truth).'' Similarly, if we denote by ``$\pmsome{x}\pmdot\phi x$ the proposition ``$\phi x$ sometimes,'' \textit{i.e.}\ as we may less accurately express it, ``$\phi x$ with some value of $x$,'' we find that $\pmsome{x}\pmdot\phi x$ has second truth if there is an $x$ with \pagefirst{45} which $\phi x$ has first truth; thus we may define ``$\{\pmsome{x}\pmdot\phi x\}$ has second truth'' as meaning ``some value for $\pmpf{\phi}{\pmhat{x}}$ has first truth,'' \textit{i.e.}\ ``$\pmall{x}\pmdot(\phi x$ has first truth).'' Similar remarks apply to falsehood. Thus ``$\{\pmall{x}\pmdot\phi x\}$ has second falsehood'' will mean ``some value for $\pmpf{\phi}{\pmhat{x}}$ has first falsehood,'' \textit{i.e.}\ ``$\pmsome{x}\pmdot(\phi x$ has first falsehood),'' while ``$\{\pmsome{x}\pmdot\phi x\}$ has second falsehood'' will mean ''all values for $\pmpf{\phi}{\pmhat{x}}$ have first falsehood,'' \textit{i.e.}\ ``$\pmall{x}\pmdot(\phi x$ has first falsehood). Thus the sort of falsehood that can belong to a general proposition is different from the sort that can belong to a particular proposition.

Applying these considerations to the proposition ``$\pmall{p}\pmdot p$ is false,'' we see that the kind of falsehood in question must be specified. If, for example, first falsehood is meant, the function ``$\pmpf{\pmhat{p}}{\text{ has first falsehood}}$'' is only significant when $p$ is the sort of proposition which has first falsehood or first truth. Hence ``$\pmall{p}\pmdot p$ is false'' will be replaced by a statement which is equivalent to ``all propositions having either first truth or first falsehood have first falsehood.'' This proposition has \textit{second} falsehood, and is not a possible argument to the function ``$\pmpf{\pmhat{p}}{\text{ has \textit{first} falsehood}}$.'' Thus the apparent exception to the principle that ``$\phi\{\pmall{x}\pmdot\phi x\}$'' must be meaningless disappears.

Similar considerations will enable us to deal with ``not-$p$'' and with ``$p$ or $q$.'' It might seem as if these were functions in which \textit{any} proposition might appear as argument. But this is due to a systematic ambiguity in the meanings of ``not'' and ``or,'' by which they adapt themselves to propositions of any order. To explain fully how this occurs, it will be well to begin with a definition of the simplest kind of \textit{truth} and \textit{falsehood}.

The universe consists of objects having various qualities and standing in various relations. Some of the objects which occur in the universe are complex. When an object is complex, it consists of interrelated parts. Let us consider a complex object composed of two parts $a$ and $b$ standing to each other in the relation $R$. The complex object ``$a$-in-the-relation-$R$-to-$b$'' may be capable of being \textit{perceived}; when perceived, it is perceived as one object. Attention may show that it is complex; we then \textit{judge} that $a$ and $b$ stand in the relation $R$. Such a judgment, being derived from perception by mere attention, may be called a ``judgment of perception.'' This judgment of perception, considered as an actual occurrence, is a relation of four terms, namely $a$ and $b$ and $R$ and the percipient. The perception, on the contrary, is a relation of two terms, namely ``$a$-in-the-relation-$R$-to-$b$,'' and the percipient. Since an object of perception cannot be nothing, we cannot perceive ``$a$-in-the-relation-$R$-to-$b$'' unless $a$ is in the relation $R$ to $b$. Hence a judgment of perception, according to the above definition, must be true. This does not mean that, in a judgment which \textit{appears} to us to be one of perception, we are sure of not being in error, since we may err in thinking that our judgment has really been derived merely by analysis of \pagefirst{46} what was perceived. But if our judgment has been so derived, it must be true. In fact, we may define \textit{truth}, where such judgments are concerned, as consisting in the fact that there is a complex \textit{corresponding} to the discursive thought which is the judgment. That is, when we judge ``$a$ has the relation $R$ to $b$,'' our judgment is said to be \textit{true} when there is a complex ``$a$-in-the-relation-$R$-to-$b$,'' and is said to be \textit{false} when this is not the case. This is a definition of truth and falsehood in relation to judgments of this kind.

It will be seen that, according to the above account, a judgment does not have a single object, namely the proposition, but has several interrelated objects. That is to say, the relation which constitutes judgment is not a relation of two terms, namely the judging mind and the proposition, but is a relation of several terms, namely the mind and what are called the constituents of the proposition. That is, when we judge (say) ``this is red,'' what occurs is a relation of three terms, the mind, and ``this,'' and red. On the other hand, when we \textit{perceive} ``the redness of this,'' there is a relation of two terms, namely the mind and the complex object ``the redness of this.'' When a judgment occurs, there is a certain complex entity, composed of the mind and the various objects of the judgment. When the judgment is \textit{true}, in the case of the kind of judgments we have been considering, there is a corresponding complex of the \textit{objects} of the judgment alone. Falsehood, in regard to our present class of judgments, consists in the absence of a corresponding complex composed of the objects alone. It follows from the above theory that a ``proposition,'' in the sense in which a proposition is supposed to be \textit{the} object of a judgment, is a false abstraction, because a judgment has several objects, not one. It is the severalness of the objects in judgment (as opposed to perception) which has led people to speak of thought as ``discursive,'' though they do not appear to have realized clearly what was meant by this epithet.

Owing to the plurality of the objects of a single judgment, it follows that what we call a ``proposition'' (in the sense in which this is distinguished from the phrase expressing it) is not a single entity at all. That is to say, the phrase which expresses a proposition is what we call an ``incomplete'' symbol\footnote{See Chapter III.}; it does not have meaning in itself, but requires some supplementation in order to acquire a complete meaning. This fact is somewhat concealed by the circumstance that judgment in itself supplies a sufficient supplement, and that judgment in itself makes no \textit{verbal} addition to the proposition. Thus ``the proposition `Socrates is human''' uses ``Socrates is human'' in a way which requires a supplement of some kind before it acquires a complete meaning; but when I judge ``Socrates is· human,'' the meaning is completed by the act of judging, and we no longer have an incomplete symbol. The fact that propositions are ``incomplete symbols'' \pagefirst{47} is important philosophically, and is relevant at certain points in symbolic logic.

The judgments we have been dealing with hitherto are such as are of the same form as judgments of perception, \textit{i.e.}\ their subjects are always particular and definite. But there are many judgments which are not of this form. Such are ``all men are mortal,'' ``I met a man,'' ``some men are Greeks.'' Before dealing with such judgments, we will introduce some technical terms.

We will give the name of ``a \textit{complex}'' to any such object as ``$a$ in the relation $R$ to $b$'' or ``$a$ having the quality $q$,'' or ``$a$ and $b$ and $c$ standing in the relation $S$.'' Broadly speaking, a \textit{complex} is anything which occurs in the universe and is not simple. We will call a judgment \textit{elementary} when it merely asserts such things as ``$a$ has the relation $R$ to $b$,'' ``$a$ has the quality $q$'' or ``$a$ and $b$ and $c$ stand in the relation $S$.'' Then an \textit{elementary} judgment is true when there is a corresponding complex, and false when there is no corresponding complex.

But take now such a proposition as ``all men are mortal.'' Here the judgment does not correspond to \textit{one} complex, but to many, namely ``Socrates is mortal,'' ``Plato is mortal,'' ``Aristotle is mortal,'' etc. (For the moment, it is unnecessary to inquire whether each of these does not require further treatment before we reach the ultimate complexes involved. For purposes of illustration, ``Socrates is mortal'' is here treated as an elementary judgment, though it is in fact not one, as will be explained later. Truly elementary judgments are not very easily found.) We do not mean to deny that there may be some relation of the concept \textit{man} to the concept \textit{mortal} which may be \textit{equivalent} to ``all men are mortal,'' but in any case this relation is not the same thing as what we affirm when we say that all men are mortal. Our judgment that all men are mortal collects together a number of elementary judgments. It is not, however, composed of these, since (\textit{e.g.}) the fact that Socrates is mortal is no part of what we assert, as may be seen by considering the fact that our assertion can be understood by a person who has never heard of Socrates. In order to understand the judgment ``all men are mortal,'' it is not necessary to know what men there are. We must admit, therefore, as a radically new kind of judgment, such general assertions as ``all men are mortal.'' We assert that, given that $x$ is human, $x$ is always mortal. That is, we assert ``$x$ is mortal'' of \textit{every} $x$ which is human. Thus we are able to judge (whether truly or falsely) that \textit{all} the objects which have some assigned property also have some other assigned property. That is, given any propositional functions $\pmpf{\phi}{\pmhat{x}}$ and $\pmpf{\psi}{\pmhat{x}}$, there is a judgment asserting $\psi x$ with every $x$ for which we have $\phi x$. Such judgments we will call \textit{general judgments}.

It is evident (as explained above) that the definition of \textit{truth} is different \pagefirst{48} in the case of general judgments from what it was in the case of elementary judgments. Let us call the meaning of \textit{truth} which we gave for elementary judgments ``elementary truth.'' Then when we assert that it is true that all men are mortal, we shall mean that all judgments of the form ``$x$ is mortal,'' where $x$ is a man, have elementary truth. We may define this as ``truth of the second order'' or ``second-order truth.'' Then if we express the proposition ``all men are mortal'' in the form 
\[
	\text{``} \pmall{x} \pmdot x \text{ is mortal, where } x \text{ is a man,''} 
\]
and call this judgment $p$, then ``$p$ is true'' must be taken to mean ``$p$ has second-order truth,'' which in turn means 
``$\pmall{x} \pmdot x$ is mortal' has elementary truth, where $x$ is a man.''

In order to avoid the necessity for stating explicitly the limitation to which our variable is subject, it is convenient to replace the above interpretation of ``all men are mortal'' by a slightly different interpretation. The proposition ``all men are mortal'' is equivalent to ```$x$ is a man' implies `$x$ is mortal,' with all possible values of $x$.'' Here $x$ is not restricted to such values as are men, but may have any value with which ```$x$ is a man' implies `$x$ is mortal''' is \textit{significant}, \textit{i.e.}\ either true or false. Such a proposition is called a ``formal implication.'' The advantage of this form is that the values which the variable may take are given by the function to which it is the argument: the values which the variable may take are all those with which the function is significant.
 
We use the symbol ``$\pmall{x} \pmdot \phi x$'' to express the general judgment which asserts all judgments of the form ``$\phi x$.'' Then the judgment ``all men are mortal'' is equivalent to 
\[
	\text{``} \pmall{x} \pmdot \text{`}x \text{ is a man' implies `} x \text{ is mortal,''} 
\]
\textit{i.e.}\ (in virtue of the definition of implication) to
\[
	\text{``} \pmall{x} \pmdot x \text{ is a not a man or } x \text{ is mortal.''} 
\]
As we have just seen, the meaning of \textit{truth} which is applicable to this proposition is not the same as the meaning of \textit{truth} which is applicable to ``$x$ is a man'' or to ``$x$ is mortal.'' And generally, in any judgment $\pmall{x} \pmdot \phi x$, the sense in which this judgment is or may be true is not the same as that in which $\phi x$ is or may be true. If $\phi x$ is an elementary judgment, it is true when it \textit{points to} a corresponding complex. But $\pmall{x} \pmdot \phi x$ does not point to a single corresponding complex: the corresponding complexes are as numerous as the possible values of \textit{x}.

It follows from the above that such a proposition as ``all the judgments made by Epimenides are true'' will only be prima facie capable of truth if all his judgments are of the same order. If they are of varying orders, of which the $n$th is the highest, we may make $n$ assertions of the form ``all the judgments of order $m$ made by Epimenides are true,'' where $m$ has all values \pagefirst{49} up to $n$. But no such judgment can include itself in its own scope, since such a judgment is always of higher order than the judgments to which it refers.

Let us consider next what is meant by the negation of a proposition of the form ``$\pmall{x} \pmdot \phi x$.'' We observe, to begin with, that ``$\phi x$ in some cases,'' or ``$\phi x$ sometimes,'' is a judgment which is on a par with '``$\phi x$ in all cases,'' or ``$\phi x$ always.'' The judgment ``$\phi x$ sometimes'' is true if one or more values of $x$ exist for which $\phi x$ is true. We will express the proposition ``$\phi x$ sometimes'' by the notation ``$\pmsome{x} \pmdot \phi x$,'' where ``\rotatebox[origin=c]{180}{E}'' stands for ``there exists,'' and the whole symbol may be read ``there exists an $x$ such that $\phi x$.'' We take the two kinds of judgment expressed by ``$\pmall{x} \pmdot \phi x$'' and ``$\pmsome{x} \pmdot \phi x$'' as primitive ideas. We also take as a primitive idea the negation of an \textit{elementary} proposition. We can then define the negations of $\pmall{x} \pmdot \phi x$ and $\pmsome{x} \pmdot \phi x$. The negation of any proposition $p$ will be denoted by the symbol ``$\pmnot p$.'' Then the negation of $\pmall{x} \pmdot \phi x$ will be \textit{defined} as meaning 
\[
	\text{``}\pmsome{x} \pmdot \pmnot \phi x,\text{''}
\]
and the negation of $\pmsome{x} \pmdot \phi x$ will be \textit{defined} as meaning $\pmall{x} \pmdot \pmnot \phi x$.'' Thus, in the traditional language of formal logic, the negation of a universal affirmative is to be defined as the particular negative, and the negation of the particular affirmative is to be defined as the universal negative. Hence the meaning of negation for such propositions is different from the meaning of negation for elementary propositions.

An analogous explanation will apply to disjunction. Consider the statement ``either $p$, or $\phi x$ always.'' We will denote the disjunction of two propositions $p$, $q$ by ``$p \pmor q$.'' Then our statement is ``$p \pmdot \pmor \pmdot \pmall{x} \pmdot \phi x$.'' We will suppose that $p$ is an elementary proposition, and that $\phi x$ is always an elementary proposition. We take the disjunction of two elementary propositions as a primitive idea, and we wish to \textit{define} the disjunction
\[
	\text{``}p \pmdot \pmor \pmdot \pmall{x} \pmdot \phi x\text{.''}
\]
This may be defined as ``$\pmall{x} \pmdot p \pmor \phi x$'' \textit{i.e.}\ ``either $p$ is true, or $\phi x$ is always true'' is to mean ```$p$ or $\phi x$' is always true.'' Similarly we will define
\[
	\text{``}p \pmdot \pmor \pmdot \pmsome{x} \pmdot \phi x\text{,''}
\]
as meaning ``$\pmsome{x} \pmdot p \pmor \phi x$,'' \textit{i.e.}\ we define ``either $p$ is true or there is an $x$ for which $\phi x$ is true'' as meaning ``there is an $x$ for which either $p$ or $\phi x$ is true.'' Similarly we can define a disjunction of two universal propositions: ``$\pmall{x} \pmdot \phi x \pmdot \pmor \pmdot \pmall{y} \pmdot \psi y$'' will be defined as meaning ``$\pmall{x, y}\pmdot \phi x \pmor \psi y$,'' \textit{i.e.}\ ``either $\phi x$ is always true or $\psi y$ is always true'' is to mean ``$\phi x$ or $\psi y$' is always true.'' By this method we obtain definitions of disjunctions containing propositions of the form $\pmall{x}\pmdot \phi x$ or $\pmsome{x}\pmdot \phi x$ in terms of disjunctions of elementary propositions; but the meaning of ``disjunction'' is not the \pagefirst{50} same for propositions of the forms $\pmall{x}\pmdot \phi x$, $\pmsome{x}\pmdot \phi x$ as it was for elementary propositions.

Similar explanations could be given for implication and conjunction, but this is unnecessary, since these can be defined in terms of negation and disjunction.

\section*{\centering IV. \textit{Why a Given Function requires Arguments of a Certain Type}.}
 
The considerations so far adduced in favour of the view that a function cannot significantly have as argument anything defined in terms of the function itself have been more or less indirect. But a direct consideration of the kinds of functions which have functions as arguments and the kinds of functions which have arguments other than functions will show, if we are not mistaken, that not only is it impossible for a function $\pmpf{\phi}{\pmhat{z}}$ to have itself or anything derived from it as argument, but that, if $\pmpf{\psi}{\pmhat{z}}$ is another function such that there are arguments $a$ with which both ``$\phi a$'' and ``$\psi a$'' are significant, then $\pmpf{\psi}{\pmhat{z}}$ and anything derived from it cannot significantly be argument to $\pmpf{\phi}{\pmhat{z}}$. This arises from the fact that a function is essentially an ambiguity, and that, if it is to occur in a definite proposition, it must occur in such a way that the ambiguity has disappeared, and a wholly unambiguous statement has resulted. A few illustrations will make this clear. Thus ``$\pmall{x}\pmdot\phi x$'' which we have already considered, is a function of $\pmpf{\phi}{\pmhat{x}}$; as soon as $\pmpf{\phi}{\pmhat{x}}$ is assigned, we have a definite proposition, wholly free from ambiguity. But it is obvious that we cannot substitute for the function something which is not a function: ``$\pmall{x}\pmdot\phi x$'' means ``$\phi x$ in all cases,'' and depends for its significance upon the fact that there are ``cases'' of $\phi x$, \textit{i.e.}\ upon the ambiguity which is characteristic of a function. This instance illustrates the fact that, when a function can occur significantly as argument, something which is not a function cannot occur significantly as argument. But conversely, when something which is not a function can occur significantly as argument, a function cannot occur significantly. Take, \textit{e.g.}\ ``$x$ is a man,'' and consider ``$\pmpf{\phi}{\pmhat{x}}$ is a man.'' Here there is nothing to eliminate the ambiguity which constitutes $\pmpf{\phi}{\pmhat{x}}$; there is thus nothing definite which is said to be a man. A function, in fact, is not a definite object, which could be or not be a man; it is a mere ambiguity awaiting determination, and in order that it may occur significantly it must receive the necessary determination, which it obviously does not receive if it is merely substituted for something determinate in a proposition\footnote{Note that statements concerning the significance of a phrase containing ``$\pmpf{\phi}{\pmhat{z}}$'' concern the \textit{symbol} ``$\pmpf{\phi}{\pmhat{x}}$,'' and therefore do not fall under the rule that the elimination of the functional ambiguity is necessary to significance. Significance is a property of signs. Cf. pp. 40, 41.}. This argument does not, however, apply directly as against such a statement as ``$\{\pmall{x}\pmdot\phi x\}$ is a man.'' Common sense would pronounce such a statement to be meaningless, but it cannot be condemned on the ground of ambiguity in its subject. We need \pagefirst{51} here a new objection, namely the following: A proposition is not a single entity, but a relation of several; hence a statement in which a proposition appears as subject will only be significant if it can be reduced to a statement about the terms which appear in the proposition. A proposition, like such phrases as ''the so-and-so,'' where grammatically it appears as subject, must be broken up into its constituents if we are to find the true subject or subjects\footnote{Cf. Chapter III.}. But in such a statement as ``$p$ is a man,'' where $p$ is a proposition, this is not possible. Hence ``$\{\pmall{x}\pmdot \phi x\}$ is a man'' is meaningless.

\section*{\centering V. \textit{The Hierarchy of Functions and Propositions}.}

We are thus led to the conclusion, both from the vicious-circle principle and from direct inspection, that the functions to which a given object a can be an argument are incapable of being arguments to each other, and that they have no term in common with the functions to which they can be arguments. We are thus led to construct a hierarchy. Beginning with $a$ and the other terms which can be arguments to the same functions to which $a$ can be argument, we come next to functions to which $a$ is a possible argument, and then to functions to which such functions are possible arguments, and so on. But the hierarchy which has to be constructed is not so simple as might at first appear. The functions which can take a as argument form an illegitimate totality, and themselves require division into a hierarchy of functions. This is easily seen as follows. Let $\pmpff{f}{\pmpf{\phi}{\pmhat{z}}}{x}$ be a function of the two variables $\pmpf{\phi}{\pmhat{x}}$ and $x$. Then if, keeping $x$ fixed for the moment, we assert this with all possible values of $\phi$, we obtain a proposition:
\[  
	\pmall{x}\pmdot \pmpff{f}{\pmpf{\phi}{\pmhat{z}}}{x}.
\]
Here, if $x$ is variable, we have a function of $x$; but as this function involves a totality of values of $\pmpf{\phi}{\pmhat{z}}$\footnote{When we speak of ``values of $\pmpf{\phi}{\pmhat{z}}$,'' it is $\phi$, not $z$, that is to be assigned. This follows from the explanation in the note on p. 40. When the function itself is variable, it is possible and simpler to write $\phi$ rather than $\pmpf{\phi}{\pmhat{z}}$, except in positions where it is necessary to emphasize that an assignment must be applied to secure significance.}, it cannot itself be one of the values included in the totality, by the vicious-circle principle. It follows that the totality of values of $\pmpf{\phi}{\pmhat{z}}$ concerned in $\pmall{\phi}\pmdot \pmpff{f}{\pmpf{\phi}{\pmhat{z}}}{x}$ is not the totality of all functions in which $x$ can occur as argument, and that there is no such totality as that of all functions in which $x$ can occur as argument. 

It follows from the above that a function in which $\pmpf{\phi}{\pmhat{z}}$ appears as argument requires that ``$\pmpf{\phi}{\pmhat{z}}$'' should not stand for any function which is capable of a given argument, but must be restricted in such a way that none of the functions which are possible values of ``$\pmpf{\phi}{\pmhat{z}}$'' should involve any reference to the totality of such functions. Let us take as an illustration the definition of identity. We might attempt to define ``$x$ is identical with $y$'' as meaning ``whatever is true of $x$ is true of $y$,'' \textit{i.e.}\ ``$\phi x$ always implies $\phi y$.'' But here, \pagefirst{52} since we are concerned to assert all values of ``$\phi x$ implies $\psi y$'' regarded as a function of $\phi$, we shall be compelled to impose upon $\phi$ some limitation which will prevent us from including among values of $\phi$, values in which ``all possible values of $\phi$'' are referred to. Thus for example ``$x$ is identical with $a$'' is a function of $x$; hence, if it is a legitimate value of $\phi$ in ``$\phi x$ always implies $\phi y$,'' we shall be able to infer, by means of the above definition, that if $x$ is identical with $a$, and $x$ is identical with $y$, then $y$ is identical with $a$. Although the conclusion is sound, the reasoning embodies a vicious-circle fallacy, since we have taken ``$\pmall{\phi}\pmdot \phi x$ implies $\phi a$'' as a possible value of $\phi x$, which it cannot be. If, however, we impose any limitation upon $\phi$, it may happen, so far as appears at present, that with other values of $\phi$, we might have $\phi x$ true and $\phi y$ false, so that our proposed definition of identity would plainly be wrong. This difficulty is avoided by the ``axiom of reducibility,'' to be explained later. For the present, it is only mentioned in order to illustrate the necessity and the relevance of the hierarchy of functions of a given argument.

Let us give the name ``$a$-functions'' to functions that are significant for a given argument $a$. Then suppose we take any selection of $a$-functions, and consider the proposition ``$a$ satisfies all the functions belonging to the selection in question.'' If we here replace $a$ by a variable, we obtain an $a$-function; but by the vicious-circle principle this $a$-function cannot be a member of our selection, since it refers to the whole of the selection. Let the selection consist of all those functions which satisfy $f(\pmpf{\phi}{\pmhat{z}})$. Then our new function is
\[
	\pmall{x}\pmdot \{f(\pmpf{\phi}{\pmhat{z}}) \text{ implies } \phi x\},
\]
where $x$ is the argument. It thus appears that, whatever selection of $a$-functions we may make, there will be other $a$-functions that lie outside our selection. Such $a$-functions, as the above instance illustrates, will always arise through taking a function of two arguments, $\pmpf{\phi}{\pmhat{z}}$ and $x$, and asserting all or some of the values resulting from varying $\phi$. What is necessary, therefore, in order to avoid vicious-circle fallacies, is to divide our $a$-functions into ``types,'' each of which contains no functions which refer to the whole of that type.

When something is asserted or denied about all possible values or about some (undetermined) possible values of a variable, that variable is called \textit{apparent}, after Peano. The presence of the words \textit{all} or \textit{some} in a proposition indicates the presence of an apparent variable; but often an apparent variable is really present where language does not at once indicate its presence. Thus for example ``$A$ is mortal'' means ``there is a time at which $A$ will die.'' Thus a variable time occurs as apparent variable.

The clearest instances of propositions not containing apparent variables are such as express immediate judgments of perception, such as ``this is red'' or ``this is painful,'' where ``this'' is something immediately given. In other \pagefirst{53} judgments, even where at first sight no variable appears to be present, it often happens that there really is one. Take (say) ``Socrates is human.'' To Socrates himself, the word ``Socrates'' no doubt stood for an object of which he was immediately aware, and the judgment ``Socrates is human'' contained no apparent variable. But to us, who only know Socrates by description, the word ``Socrates'' cannot mean what it meant to him; it means rather ``the person having such-and-such properties,'' (say) ``the Athenian philosopher who drank the hemlock.'' Now. in all propositions about ``the so-and-so'' there is an apparent variable, as will be shown in Chapter III. Thus in what we have in mind when we say ``Socrates is human'' there is an apparent variable, though there was no apparent variable in the corresponding judgment as made by Socrates, provided we assume that there is such a thing as immediate awareness of oneself.

Whatever may be the instances of propositions not containing apparent variables, it is obvious that propositional functions whose values do not contain apparent variables are the source of propositions containing apparent variables, in the sense in which the function $\pmpf{\phi}{\pmhat{x}}$ is the source of the proposition $\pmall{x}\pmdot\phi x$. For the values for $\pmpf{\phi}{\pmhat{x}}$ do not contain the apparent variable $x$, which appears in $\pmall{x}\pmdot\phi x$; if they contain an apparent variable $y$, this can be similarly eliminated, and so on. This process must come to an end, since no proposition which we can apprehend can contain more than a finite number of apparent variables, on the ground that whatever we can apprehend must be of finite complexity. Thus we must arrive at last at a function of as many variables as there have been stages in reaching it from our original proposition, and this function will be such that its values contain no apparent variables. We may call this function the \textit{matrix} of our original proposition and of any other propositions and functions to be obtained by turning some of the arguments to the function into apparent variables. Thus for example, if we have a matrix-function whose values are $\phi(x,y)$, we shall derive from it

\indent $\pmall{y} \pmdot \phi(x,y)$, which is a function of $x$,

\indent $\pmall{x}\pmdot \phi(x,y)$, which is a function of $y$,

$\pmall{x, y}\pmdot \phi(x, y)$, meaning ``$\phi(x, y)$ is true with all possible values of $x$ and $y$.'' This last is a proposition containing no real variable, \textit{i.e.}\ no variable except apparent variables.

It is thus plain that all possible propositions and functions are obtainable from matrices by the process of turning the arguments to the matrices into apparent variables. In order to divide our propositions and functions into types, we shall, therefore, start from matrices, and consider how they are to be divided with a view to the avoidance of vicious-circle fallacies in the definitions of the functions concerned. For this purpose, we will use such letters as $a, b, c, x, y, z, w,$ to denote objects which are neither propositions nor functions. Such objects we shall call \textit{individuals}. Such objects will be \pagefirst{54} constituents of propositions or functions, and will be \textit{genuine} constituents, in the sense that they do not disappear on analysis, as (for example) classes do, or phrases of the form ``the so-and-so.''

The first matrices that occur are those whose values are of the forms
\[
	\phi x, \psi(x,y), \chi(x, y, z,...),
\]
\textit{i.e.}\ where the arguments, however many there may be, are all individuals. The functions $\phi, \psi, \chi, ...,$ since (by definition) they contain no apparent variables, and have no arguments except individuals, do not presuppose any totality of functions. From the functions $\psi, \chi ...$ we may proceed to form other functions of $x$, such as $(y) \pmdot \psi(x, y)$, $\pmsome{y} \pmdot \psi(x, y)$, $\pmall{y, z}\pmdot \chi(x, y, z)$, $\pmall{y}\pmdott \pmsome{z}\pmdot \chi(x, y, z)$, and so on. All these presuppose no totality except that of individuals. We thus arrive at a certain collection of functions of $x$, characterized by the fact that they involve no variables except individuals. Such functions we will call ``\textit{first-order} functions.''

We may now introduce a notation to express ``any first-order function.'' We will denote any first-order function by ``$\pmpf{\phi\pmshr}{\pmhat{x}}$'' and any value for such a function by ``$\pmpred{\phi}{x}$.'' Thus ``$\pmpred{\phi}{x}$'' stands for any value for any function which involves no variables except individuals. It will be seen that ``$\pmpred{\phi}{x}$'' is itself a function of \textit{two} variables, namely $\pmpf{\phi\pmshr}{\pmhat{z}}$ and $x$. Thus $\pmpred{\phi}{x}$ involves a variable which is not an individual, namely $\pmpf{\phi\pmshr}{\pmhat{z}}$. Similarly ``$\pmall{x}\pmdot \pmpred{\phi}{x}$'' is a function of the variable $\pmpf{\phi\pmshr}{\pmhat{z}}$, and thus involves a variable other than an individual. Again, if $a$ is a given individual,
\[
	\text{``}\pmpred{\phi}{x} \text{ implies } \pmpred{\phi}{a} \text{ with all possible values of } \phi\text{''}
\]
is a function of $x$, but it is not a function of the form $\pmpred{\phi}{x}$, because it involves an (apparent) variable $\phi$, which is not an individual. Let us give the name ``predicate'' to any first-order function $\pmpf{\phi\pmshr}{\pmhat{x}}$. (This use of the word ``predicate'' is only proposed for the purposes of the present discussion.) Then the statement ``$\pmpred{\phi}{x}$ implies $\pmpred{\phi}{a}$ with all possible values of $\phi$'' may be read ``all the predicates of $x$ are predicates of $a$.'' This makes a statement about $x$, but does not attribute to $x$ a \textit{predicate} in the special sense just defined.

Owing to the introduction of the variable first-order function $\pmpf{\phi\pmshr}{\pmhat{z}}$, we now have a new set of matrices. Thus ``$\pmpred{\phi}{x}$'' is a function which contains no apparent variables, but contains the two real variables $\pmpf{\phi\pmshr}{\pmhat{z}}$ and $x$. (It should be observed that when $\phi$, is assigned, we may obtain a function whose values do involve individuals as apparent variables, for example if $\pmpred{\phi}{x}$, is $\pmall{y}\pmdot \psi(x, y)$. But so long as $\phi$, is variable, $\pmpred{\phi}{x}$ contains no apparent variables.) Again, if $a$ is a definite individual, $\pmpred{\phi}{a}$ is a function of the one variable $\pmpf{\phi\pmshr}{\pmhat{z}}$. If $a$ and $b$ are definite individuals, ``$\pmpred{\phi}{a}$ implies $\pmpred{\psi}{b}$'' is a function of the two variables $\pmpf{\phi\pmshr}{\pmhat{z}}, \pmpf{\psi\pmshr}{\pmhat{z}}$, and so on. We are thus led to a whole set of new matrices,
\[
	f(\pmpf{\phi\pmshr}{\pmhat{z}}), g(\pmpf{\phi\pmshr}{\pmhat{z}}, \pmpf{\psi\pmshr}{\pmhat{z}}), F(\pmpf{\phi\pmshr}{\pmhat{z}}, x), \text{ and so on.}
\]
These matrices contain individuals and first-order functions as arguments, but \pagefirst{55} (like all matrices) they contain no apparent variables. Any such matrix, if it contains more than one variable, gives rise to new functions of one variable by turning all its arguments except one into apparent variables. Thus we obtain the functions
\begin{flalign*}
&& &\pmall{\phi}\pmdot g(\pmpf{\phi\pmshr}{\pmhat{z}}, \pmpf{\psi\pmshr}{\pmhat{z}}), \text{ which is a function of } \pmpf{\psi\pmshr}{\pmhat{z}}. & \\
&& &\pmall{x} \pmdot F(\pmpf{\phi\pmshr}{\pmhat{z}}, x), \text{ which is a function of } \pmpf{\phi\pmshr}{\pmhat{z}}. & \\
&& &\pmall{\phi} \pmdot F(\pmpf{\phi\pmshr}{\pmhat{z}}, x), \text{ which is a function of } x. &
\end{flalign*}

We will give the name of \textit{second-order matrices} to such matrices as have first-order functions among their arguments, and have no arguments except first-order functions and individuals. (It is not \textit{necessary} that they should have individuals among their arguments.) We will give the name of \textit{second-order functions} to such as either are second-order matrices or are derived from such matrices by turning some of the arguments into apparent variables. It will be seen that either an individual or a first-order function may appear as argument to a second-order function. Second-order functions are such as contain variables which are first-order functions, but contain no other variables except (possibly) individuals.

We now have various new classes of functions at our command. In the first place, we have second-order functions which have one argument which is a first-order function. We will denote a variable function of this kind by the notation $\pmpred{f}{(\pmpf{\pmhat{\phi}\pmshr}{\pmhat{z}})}$, and any value of such a function by $\pmpred{f}{(\pmpred{\phi}{\pmhat{z}})}$. Like $\pmpred{\phi}{x}$, $\pmpred{f}{(\pmpred{\phi}{\pmhat{z}})}$ is a function of two variables, namely $\pmpred{f}{(\pmpf{\pmhat{\phi}}{\pmhat{z}})}$ and $\pmpred{\phi}{\pmhat{z}}$. Among possible values of $\pmpred{f}{(\pmpred{\phi}{\pmhat{z}})}$ will be $\pmpred{\phi}{a}$ (where $a$ is constant), $\pmall{x}\pmdot \pmpred{\phi}{x}$, $(\pmexists{x})\pmdot \pmpred{\phi}{x}$, and so on. (These result from assigning a value to $f$, leaving $\phi$, to be assigned.) We will call such functions ``predicative functions of first-order functions.''

In the second place, we have second-order functions of two arguments, one of which is a first-order function while the other is an individual. Let us denote undetermined values of such functions by the notation
\[
	\pmpredd{f}{\pmpred{\phi}{\pmhat{z}}}{x}.
\]
As soon as $x$ is assigned, we shall have a predicative function of $\pmpred{\phi}{\pmhat{z}}$. If our function contains no first-order function as apparent variable, we shall obtain a predicative function of $x$ if we assign a value to $\pmpred{\phi}{\pmhat{z}}$. Thus, to take the simplest possible case, if $\pmpredd{f}{\pmpred{\phi}{\pmhat{z}}}{x}$ is $\pmpred{\phi}{x}$, the assignment of a value to $\phi$, gives us a predicative function of $x$, in virtue of the definition of ``$\pmpred{\phi}{x}$.'' But if $\pmpredd{f}{\pmpred{\phi}{\pmhat{z}}}{x}$ contains a first-order function as apparent variable, the assignment of a value to $\pmpred{\phi}{\pmhat{z}}$ gives us a second-order function of $x$.

In the third place, we have second-order functions of individuals. These will all be derived from functions of the form $\pmpredd{f}{\pmpred{\phi}{\pmhat{z}}}{x}$ by turning $\phi$, into an apparent variable. We do not, therefore, need a new notation for them.

We have also second-order functions of two first-order functions, or of two such functions and an individual, and so on.

\pagefirst{56} We may now proceed in exactly the same way to third-order matrices, which will be functions containing second-order functions as arguments, and containing no apparent variables, and no arguments except individuals and first-order functions and second-order functions. Thence we shall proceed, as before, to third-order functions; and so we can proceed indefinitely. If the highest order of variable occurring in a function, whether as argument or as apparent variable, is a function of the $n$th order, then the function in which it occurs is of the $n+1$th order. We do not arrive at functions of an infinite order, because the number of arguments and of apparent variables in a function must be finite, and therefore every function must be of a finite order. Since the orders of functions are only defined step by step, there can be no process of ``proceeding to the limit,'' and functions of an infinite order cannot occur.

We will define a function of one variable as \textit{predicative} when it is of the next order above that of its argument, \textit{i.e.}\ of the lowest order compatible with its having that argument. If a function has several arguments, and the highest order of function occurring among the arguments is the $n$th, we call the function predicative if it is of the $n+1$th order, \textit{i.e.}\ again, if it is of the lowest order compatible with its having the arguments it has. A function of several arguments is predicative if there is one of its arguments such that, when the other arguments have values assigned to them, we obtain a predicative function of the one undetermined argument.

It is important to observe that all possible functions in the above hierarchy can be obtained by means of predicative functions and apparent variables. Thus, as we saw, second-order functions of an individual x are of the form
\[ 
	\pmall{\phi}\pmdot \pmpredd{f}{\pmpred{\phi}{\pmhat{z}}}{x} \text{ or } \pmsome{\phi}\pmdot \pmpredd{f}{\pmpred{\phi}{\pmhat{z}}}{x} \text{ or } \pmall{\phi, \psi}\pmdot \pmpreddd{f}{\pmpred{\phi}{\pmhat{z}}}{\pmpred{\psi}{\pmhat{z}}}{x} \text{ or etc.,} 
\]
where $f$ is a second-order predicative function. And speaking generally, a non-predicative function of the $n$th order is obtained from a predicative function of the $n$th order by turning all the arguments of the $n-1$th order into apparent variables. (Other arguments also may be turned into apparent variables.) Thus we need not introduce as variables any functions except predicative functions. Moreover, to obtain any function of one variable $x$, we need not go beyond predicative functions of two variables. For the function $\pmall{\psi}\pmdot \pmpreddd{f}{\pmpred{\phi}{\pmhat{z}}}{\pmpred{\psi}{\pmhat{z}}}{x}$, where $f$ is given, is a function of $\pmpred{\phi}{\pmhat{z}}$ and $x$, and is predicative. Thus it is of the form $\pmpredd{F}{\pmpred{\phi}{\pmhat{z}}}{x}$, and therefore $\pmall{\phi, \psi}\pmdot \pmpreddd{f}{\pmpred{\phi}{\pmhat{z}}}{\pmpred{\psi}{\pmhat{z}}}{x}$ is of the form $\pmall{\phi}\pmdot \pmpredd{F}{\pmpred{\phi}{\pmhat{z}}}{x}$. Thus speaking generally, by a succession of steps we find that, if $\pmpred{\phi}{\pmhat{u}}$ is a predicative function of a sufficiently high order, any assigned non-predicative function of $x$ will be of one of the two forms
\[
	\pmall{\phi}\pmdot \pmpredd{F}{\pmpf{\phi\pmshr}{\pmhat{u}}}{x}, \pmsome{\phi}\pmdot \pmpredd{F}{\pmpf{\phi\pmshr}{\pmhat{u}}}{x},
\]
where $F$ is a predicative function of $\pmpred{\phi}{\pmhat{u}}$ and $x$.

\pagefirst{57} The nature of the above hierarchy of functions may be restated as follows. A function, as we saw at an earlier stage, presupposes as part of its meaning the totality of its values, or, what comes to the same thing, the totality of its possible arguments. The arguments to a function may be functions or propositions or individuals. (It will be remembered that individuals were defined as whatever is neither a proposition nor a function.) For the present we neglect the case in which the argument to a function is a proposition. Consider a function whose argument is an individual. This function presupposes the totality of individuals; but unless it contains functions as apparent variables, it does not presuppose any totality of functions. If, however, it does contain a function as apparent variable, then it cannot be defined until some totality of functions has been defined. It follows that we must first define the totality of those functions that have individuals as arguments and contain no functions as apparent variables. These are the \textit{predicative} functions of individuals. Generally, a predicative function of a variable argument is one which involves no totality except that of the possible values of the argument, and those that are presupposed by any one of the possible arguments. Thus a predicative function of a variable argument is any function which can be specified without introducing new kinds of variables not necessarily presupposed by the variable which is the argument.

A closely analogous treatment can be developed for propositions. Propositions which contain no functions and no apparent variables may be called \textit{elementary propositions}. Propositions which are not elementary, which contain no functions, and no apparent variables except individuals, may be called \textit{first-order propositions}. (It should be observed that no variables except \textit{apparent} variables can occur in a proposition, since whatever contains a real variable is a function, not a proposition.) Thus elementary and first-order propositions will be values of first-order functions. (It should be remembered that a function is not a constituent in one of its values: thus for example the function ``$\pmpf{\pmhat{x}}{\text{ is a human}}$'' is not a constituent of the proposition ``Socrates is human.'') Elementary and first-order propositions presuppose no totality except (at most) the totality of individuals. They are of one or other of the three forms
\[
	\pmpred{\phi}{x}; \pmall{x}\pmdot \pmpred{\phi}{x}; \pmsome{x}\pmdot \pmpred{\phi}{x},
\]
where $\pmpred{\phi}{x}$ is a predicative function of an individual. It follows that, if $p$ represents a variable elementary proposition or a variable first-order proposition, a function $fp$ is either $f(\pmpred{\phi}{x})$ or $f\{\pmall{x}\pmdot \pmpred{\phi}{x}\}$ or $f\{\pmsome{x}\pmdot \pmpred{\phi}{x}\}$. Thus a function of an elementary or a first-order proposition may always be reduced to a function of a first-order function. It follows that a proposition involving the totality of first-order propositions may be reduced to one involving the totality of first-order functions; and this obviously applies equally to higher \pagefirst{58} orders. The propositional hierarchy can, therefore, be derived from the functional hierarchy, and we may define a proposition of the $n$th order as one which involves an apparent variable of the $n-1$th order in the functional hierarchy. The propositional hierarchy is never required in practice, and is only relevant for the solution of paradoxes ; hence it is unnecessary to go into further detail as to the types of propositions.

\section*{\centering VI. \textit{The Axiom of Reducibility}.}

It remains to consider the ``axiom of reducibility.'' It will be seen that, according to the above hierarchy, no statement can be made significantly about ``all $a$-functions,'' where $a$, is some given object. Thus such a notion as ``all properties of $a$,'' meaning ``all functions which are true with the argument $a$,'' will be illegitimate. We shall have to distinguish the order of function concerned. We can speak of ``all predicative properties of $a$,'' ``all second-order properties of $a$,'' and so on. (If $a$ is not an individual, but an object of order $n$, ``second-order properties of $a$'' will mean ``functions of order $n+2$ satisfied by $a$.'') But we cannot speak of ``all properties of $a$.'' In some cases, we can see that some statement will hold of ``all $n$th-order properties of $a$,'' whatever value $n$ may have. In such cases, no practical harm results from regarding the statement as being about ``all properties of $a$,'' provided we remember that it is really a number of statements, and not a single statement which could be regarded as assigning another property to $a$, over and above all properties. Such cases will always involve some systematic ambiguity, such as that involved in the meaning of the word ``truth,'' as explained above. Owing to this systematic ambiguity, it will be possible, sometimes, to combine into a single verbal statement what are really a number of different statements, corresponding to different orders in the hierarchy. This is illustrated in the case of the liar, where the statement ``all $A$'s statements are false'' should be broken up into different statements referring to his statements of various orders, and attributing to each the appropriate kind of falsehood.

The axiom of reducibility is introduced in order to legitimate a great mass of reasoning, in which, prima facie, we are concerned with such notions as ``all properties of $a$'' or ``all $a$-functions,'' and in which, nevertheless, it seems scarcely possible to suspect any substantial error. In order to state the axiom, we must first define what is meant by ``formal equivalence.'' Two functions $\pmpf{\phi}{\pmhat{x}}$, $\pmpf{\psi}{\pmhat{x}}$ are said to be ``formally equivalent'' when, with every possible argument $x$, $\phi x$ is equivalent to $\psi x$, \textit{i.e.}\ $\phi x$ and $\psi x$ are either both true or both false. Thus two functions are formally equivalent when they are satisfied by the same set of arguments. The axiom of reducibility is the assumption that, given any function $\pmpf{\phi}{x}$, there is a formally equivalent \textit{predicative} function, \pagefirst{59} \textit{i.e.}\ there is a predicative function which is true when $\phi x$ is true and false when $\psi x$ is false. In symbols, the axiom is:
\[
	\pmthm \pmdott \pmsome{\psi}\pmdott \phi x \pmdot \pmiff_x \pmdot \pmpred{\psi}{x}.
\]
For two variables, we require a similar axiom, namely: Given any function $\pmpff{\phi}{\pmhat{x}}{\pmhat{y}}$, there is a formally equivalent \textit{predicative} function, \textit{i.e.}\
\[
	\pmthm \pmdott \pmsome{\psi}\pmdott \phi (x,y) \pmdot \pmiff_{x,y} \pmdot \pmpredd{\psi}{x}{y}.
\]

In order to explain the purposes of the axiom of reducibility, and the nature of the grounds for supposing it true, we shall first illustrate it by applying it to some particular cases.

If we call a \textit{predicate} of an object a predicative function which is true of that object, then the predicates of an object are only some among its properties. Take for example such a proposition as ``Napoleon had all the qualities that make a great general.'' We may interpret this as meaning ``Napoleon had all the predicates that make a great general.'' Here there is a predicate which is an apparent variable. If we put ``$f(\pmpred{\phi}{\pmhat{x}})$'' for ``$\pmpred{\phi}{\pmhat{x}}$'' is a predicate required in a great general,'' our proposition is 
\[
	\pmall{\phi}\pmdott f(\pmpred{\phi}{\pmhat{x}}) \text{ implies } \pmpred{\phi}{\text{Napoleon}}.
\]
Since this refers to a totality of predicates, it is not itself a predicate of Napoleon. It by no means follows, however, that there is not some one predicate common and peculiar to great generals. In fact, it is certain that there is such a predicate. For the number of great generals is finite, and each of them certainly possessed some predicate not possessed by any other human being---for example, the exact instant of his birth. The disjunction of such predicates will constitute a predicate common and peculiar to great generals\footnote{When a (finite) set of predicates is given by actual enumeration, their disjunction is a predicate, because no predicate occurs as apparent variable in the disjunction.}. If we call this predicate $\pmpred{\psi}{\pmhat{z}}$, the statement we made about Napoleon was equivalent to $\pmpred{\psi}{\text{Napoleon}}$. And this equivalence holds equally if we substitute any other individual for Napoleon. Thus we have arrived at a predicate which is always equivalent to the property we ascribed to Napoleon, \textit{i.e.}\ it belongs to those objects which have this property, and to no others. The axiom of reducibility states that such a predicate always exists, \textit{i.e.}\ that any property of an object belongs to the same collection of objects as those that possess some predicate.

We may next illustrate our principle by its application to \textit{identity}. In this connection, it has a certain affinity with Leibniz's identity of indiscernibles. It is plain that, if $x$ and $y$ are identical, and $\phi x$ is true, then $\phi y$ is true. Here it cannot matter what sort of function $\pmpf{\phi}{\pmhat{z}}$ may be: the statement must hold for \textit{any} function. But we cannot say, conversely: ``If, with all values of $\phi$, $\phi x$ implies $\phi y$, then $x$ and $y$ are identical''; because ``all values of $\phi$'' is inadmissible. If we wish to speak of ``all values of $\phi$'' we must confine ourselves to functions of one order. We may confine $\phi$ to predicates, or to \pagefirst{60} second-order functions, or to functions of any order we please. But we must necessarily leave out functions of all but one order. Thus we shall obtain, so to speak, a hierarchy of different degrees of identity. We may say ``all the predicates of $x$ belong to $y$,'' ``all second-order properties of $x$ belong to $y$,'' and so on. Each of these statements implies all its predecessors: for example, if all second-order properties of $x$ belong to $y$, then all predicates of $x$ belong to $y$, for to have all the predicates of $x$ is a second-order property, and this property belongs to $x$. But we cannot, without the help of an axiom, argue conversely that if all the predicates of $x$ belong to $y$, all the second-order properties of $x$ must also belong to $y$. Thus we cannot, without the help of an axiom, be sure that $x$ and $y$ are identical if they have the same predicates. Leibniz's identity of indiscernibles supplied this axiom. It should be observed that by ``indiscernibles'' he cannot have meant two objects which agree as to \textit{all} their properties, for one of the properties of $x$ is to be identical with $x$, and therefore this property would necessarily belong to $y$ if $x$ and $y$ agreed in \textit{all} their properties. Some limitation of the common properties necessary to make things indiscernible is therefore implied by the necessity of an axiom. For purposes of illustration (not of interpreting Leibniz) we may suppose the common properties required for indiscernibility to be limited to predicates. Then the identity of indiscernibles will state that if $x$ and $y$ agree as to all their predicates, they are identical. This can be proved if we assume the axiom of reducibility. For, in that case, every property belongs to the same collection of objects as is defined by some predicate. Hence there is some predicate common and peculiar to the objects which are identical with $x$. This predicate belongs to $x$, since $x$ is identical with itself; hence it belongs to $y$, since $y$ has all the predicates of $x$; hence $y$ is identical with $x$. It follows that we may define $x$ and $y$ as identical when all the predicates of $x$ belong to $y$, \textit{i.e.}\ when $\pmall{\phi} \pmdott \pmpred{\phi}{x} \pmdot \pmimp \pmdot \pmpred{\phi}{y}$. We therefore adopt the following definition of identity\footnote{Note that in this definition the second sign of equality is to be regarded as combining with ``Df'' to form one symbol; what is defined is the sign of equality \textit{not} followed by the letters ``Df.''}:
\[
	x=y \pmdot \pmiddf \pmdott \pmall{\phi} \pmdott \pmpred{\phi}{x} \pmdot \pmimp \pmdot \pmpred{\phi}{y} \pmdf
\]

But apart from the axiom of reducibility, or some axiom equivalent in this connection, we should be compelled to regard identity as indefinable, and to admit (what seems impossible) that two objects may agree in all their predicates without being identical. 

The axiom of reducibility is even more essential in the theory of classes. It should be observed, in the first place, that if we assume the existence of classes, the axiom of reducibility can be proved. For in that case, given any function $\pmpf{\phi}{\pmhat{z}}$ of whatever order, there is a class $\alpha$ consisting of just those objects which satisfy $\pmpf{\phi}{\pmhat{z}}$. Hence ``$\phi x$'' is equivalent to ``$x$ belongs to $\alpha$.'' But ``$x$ belongs to $\alpha$'' is a statement containing no apparent variable, and is therefore a predicative function of $x$. Hence if we assume the existence of \pagefirst{61} classes, the axiom of reducibility becomes unnecessary. The assumption of the axiom of reducibility is therefore a smaller assumption than the assumption that there are classes. This latter assumption has hitherto been made unhesitatingly. However, both on the ground of the contradictions, which require a more complicated treatment if classes are assumed, and on the ground that it is always well to make the smallest assumption required for proving our theorems, we prefer to assume the axiom of reducibility rather than the existence of classes. But in order to explain the use of the axiom in dealing with classes, it is necessary first to explain the theory of classes, which is a topic belonging to Chapter III. We therefore postpone to that Chapter the explanation of the use of our axiom in dealing with classes.

It is worth while to note that all the purposes served by the axiom of reducibility are equally well served if we assume that there is always a function of the $n$th order (where $n$ is fixed) which is formally equivalent to $\pmpf{\phi}{\pmhat{x}}$ whatever may be the order of $\pmpf{\phi}{\pmhat{x}}$. Here we shall mean by ``a function of the $n$th order'' a function of the $n$th order relative to the arguments to $\pmpf{\phi}{\pmhat{x}}$; thus if these arguments are absolutely of the $m$th order, we assume the existence of a function formally equivalent to $\pmpf{\phi}{\pmhat{x}}$, whose absolute order is the $m+n$th. The axiom of reducibility in the form assumed above takes $n = 1$, but this is not necessary to the use of the axiom. It is also unnecessary that $n$ should be the same for different values of $m$; what is necessary is that $n$ should be constant so long as $m$ is constant. What is needed is that, where extensional functions of functions are concerned, we should be able to deal with any $a$-function by means of some formally equivalent function of a given type, so as to be able to obtain results which would otherwise require the illegitimate notion of ``all $a$-functions''; but it does not matter what the given type is. It does not appear, however, that the axiom of reducibility is rendered appreciably more plausible by being put in the above more general but more complicated form.

The axiom of reducibility is equivalent to the assumption that ``any combination or disjunction of predicates\footnote{Here the combination or disjunction is supposed to be given intensionally. If given extensionally (\textit{i.e.}\ by enumeration), no assumption is required; but in this case the number of predicates concerned must be finite.} is equivalent to a single predicate,'' \textit{i.e.}\ to the assumption that, if we assert that $x$ has all the predicates that satisfy a function $\pmpf{f}{\pmpred{\phi}{\pmhat{z}}}$, there is some one predicate which $x$ will have whenever our assertion is true, and will not have whenever it is false, and similarly if we assert that $x$ has some one of the predicates that satisfy a function $\pmpf{f}{\pmpred{\phi}{\pmhat{z}}}$. For by means of this assumption, the order of a non-predicative function can be lowered by one; hence, after some finite number of steps, we shall be able to get from any non-predicative function to a formally equivalent predicative function. It does not seem probable that \pagefirst{62} the above assumption could be substituted for the axiom of reducibility in symbolic deductions, since its use would require the explicit introduction of the further assumption that by a finite number of downward steps we can pass from any function to a predicative function, and this assumption could not well be made without developments that are scarcely possible at an early stage. But on the above grounds it seems plain that in fact, if the above alternative axiom is true, so is the axiom of reducibility. The converse, which completes the proof of equivalence, is of course evident. 

\section*{\centering VII. \textit{Reasons for Accepting the Axiom of Reducibility}.}

That the axiom of reducibility is self-evident is a proposition which can hardly be maintained. But in fact self-evidence is never more than a part of the reason for accepting an axiom, and is never indispensable. The reason for accepting an axiom, as for accepting any other proposition, is always largely inductive, namely that many propositions which are nearly indubitable can be deduced from it, and that no equally plausible way is known by which these propositions could be true if the axiom were false, and nothing which is probably false can be deduced from it. If the axiom is apparently self-evident, that only means, practically, that it is nearly indubitable; for things have been thought to be self-evident and have yet turned out to be false. And if the axiom itself is nearly indubitable, that merely adds to the inductive evidence derived from the fact that its consequences are nearly indubitable: it does not provide new evidence of a radically different kind. Infallibility is never attainable, and therefore some element of doubt should always attach to every axiom and to all its consequences. In formal logic, the element of doubt is less than in most sciences, but it is not absent, as appears from the fact that the paradoxes followed from premisses which were not previously known to require limitations. In the case of the axiom of reducibility, the inductive evidence in its favour is very strong, since the reasonings which it permits and the results to which it leads are all such as appear valid. But although it seems very improbable that the axiom should turn out to be false, it is by no means improbable that it should be found to be deducible from some other more fundamental and more evident axiom. It is possible that the use of the vicious-circle principle, as embodied in the above hierarchy of types, is more drastic than it need be, and that by a less drastic use the necessity for the axiom might be avoided. Such changes, however, would not render anything false which had been asserted on the basis of the principles explained above: they would merely provide easier proofs of the same theorems. There would seem, therefore, to be but the slenderest ground for fearing that the use of the axiom of reducibility may lead us into error.

\section*{\centering VIII. \textit{The Contradictions}.} \pagefirst{63} 

We are now in a position to show how the theory of types affects the solution of the contradictions which have beset mathematical logic. For this purpose, we shall begin by an enumeration of some of the more important and illustrative of these contradictions, and shall then show how they all embody vicious-circle fallacies, and are therefore all avoided by the theory of types. It will be noticed that these paradoxes do not relate exclusively to the ideas of number and quantity. Accordingly no solution can be adequate which seeks to explain them merely as the result of some illegitimate use of these ideas. The solution must be sought in some such scrutiny of fundamental logical ideas as has been attempted in the foregoing pages.

(1) The oldest contradiction of the kind in question is the \textit{Epimenides}. Epimenides the Cretan said that all Cretans were liars, and all other statements made by Cretans were certainly lies. Was this a lie? The simplest form of this contradiction is afforded by the man who says ``I am lying''; if he is lying, he is speaking the truth, and vice versa. 

(2) Let $w$ be the class of all those classes which are not members of themselves. Then, whatever class $x$ may be, ``$x$ is a $w$'' is equivalent to ``$x$ is not an $x$.'' Hence, giving to $x$ the value $w$, ``$w$ is a $w$'' is equivalent to ``$w$ is not a $w$.''

(3) Let $T$ be the relation which subsists between two relations $R$ and $S$ whenever $R$ does not have the relation $R$ to $S$. Then, whatever relations $R$ and $S$ may be, ``$R$ has the relation $T$ to $S$'' is equivalent to ``$R$ does not have the relation $R$ to $S$.'' Hence, giving the value $T$ to both $R$ and $S$, ``$T$ has the relation $T$ to $T$'' is equivalent to ``$T$ does not have the relation $T$ to $T$.''

( 4) Burali-Forti's contradiction\footnote{``Una questione sui numeri transfiniti,'' \textit{Rendiconti del circolo matematico di Palermo}, Vol. XI. (1897). See $\pmast256$.} may be stated as follows: It can be shown that every well-ordered series has an ordinal number, that the series of ordinals up to and including any given ordinal exceeds the given ordinal by one, and (on certain very natural assumptions) that the series of all ordinals (in order of magnitude) is well-ordered. It follows that the series of all ordinals has an ordinal number, $\Omega$ say. But in that case the series of all ordinals including $\Omega$ has the ordinal number $\Omega+1$, which must be greater than $\Omega$. Hence $\Omega$ is not the ordinal number of all ordinals.

(5) The number of syllables in the English names of finite integers tends to increase as the integers grow larger, and must gradually increase indefinitely, since only a finite number of names can be made with a given finite number of syllables. Hence the names of some integers must consist of at least nineteen syllables, and among these there must be a least. Hence ``the least integer not nameable in fewer than nineteen syllables'' \pagefirst{64} must denote a definite integer; in fact, it denotes 111,777. But ``the least integer not nameable in fewer than nineteen syllables'' is itself a name consisting of eighteen syllables; hence the least integer not nameable in fewer than nineteen syllables can be named in eighteen syllables, which is a contradiction\footnote{This contradiction was suggested to us by Mr G. G. Berry of the Bodleian Library.}.

(6) Among transfinite ordinals some can be defined, while others can not; for the total number of possible definitions is $\aleph_0$\footnote{$\aleph_0$ is the number of the finite integers. See $\pmast123$.}, while the number of transfinite ordinals exceeds $\aleph_0$. Hence there must be indefinable ordinals, and among these there must be a least. But this is defined as ``the least indefinable ordinal,'' which is a contradiction\footnote{Cf. K{\"o}nig, ``Ueber die Grundlagen der Mengelehre und das Kontinuumproblem,'' \textit{Math Annalen}, Vol. LXI (1905); A. C. Dixon, ``On `well-ordered' aggregates,'' \textit{Proc. London Math. Soc.}, Series 2, Vol. IV. Part I. (1906); and E. W. Hobson, ``On the Arithmetic Continuum,'' \textit{ibid.} The solution offered in the last of these papers depends upon the variation of the ``apparatus of definition,'' and is thus in outline in agreement with the solution adopted here. But it does not invalidate the statement in the text, if ``definition'' is given a constant meaning.}.

(7) Richard's paradox\footnote{Cf. Poincar\'e, ``Les math\'ematiques et la logique,'' \textit{Revue de M\'etaphysique et de Morale}, Mai 1906, especially sections VII. and IX.; also Peano, \textit{Revista de Mathematica}, Vol. VIII. No. 5 (1906), p. 149 ff.} is akin to that of the least indefinable ordinal. It is as follows: Consider all decimals that can be defined by means of a finite number of words; let $E$ be the class of such decimals. Then $E$ has $\aleph_0$ terms; hence its members can be ordered as the 1st, 2nd, 3rd, $...$. Let $N$ be a number defined as follows: If the $n$th figure in the $n$th decimal is $p$, let the $n$th figure in $N$ be $p+1$ (or $0$, if $p=9$). Then $N$ is different from all the members of $E$, since, whatever finite value $n$ may have, the $n$th figure in $N$ is different from the $n$th figure in the $n$th of the decimals composing $E$, and therefore $N$ is different from the $n$th decimal. Nevertheless we have defined $N$ in a finite number of words, and therefore $N$ ought to be a member of $E$. Thus $N$ both is and is not a member of $E$.

In all the above contradictions (which are merely selections from an indefinite number) there is a common characteristic, which we may describe as self-reference or reflexiveness. The remark of Epimenides must include itself in its own scope. If \textit{all} classes, provided they are not members of themselves, are members of $w$, this must also apply to $w$; and similarly for the analogous relational contradiction. In the cases of names and definitions, the paradoxes result from considering non-nameability and indefinability as elements in names and definitions. In the case of Burali-Forti's paradox, the series whose ordinal number causes the difficulty is the series of all ordinal numbers. In each contradiction something is said about \textit{all} cases of some kind, and from what is said a new case seems to be generated, \pagefirst{65} which both is and is not of the same kind as the cases of which \textit{all} were concerned in what was said. But this is the characteristic of illegitimate totalities, as we defined them in stating the vicious-circle principle. Hence all our contradictions are illustrations of vicious-circle fallacies. It only remains to show, therefore, that the illegitimate totalities involved are excluded by the hierarchy of types which we have constructed.

(1) When a man says ``I am lying,'' we may interpret his statement as: ``There is a proposition which I am affirming and which is false.'' That is to say, he is asserting the truth of some value of the function ``I assert $p$, and $p$ is false.'' But we saw that the word ``false'' is ambiguous, and that, in order to make it unambiguous, we must specify the order of falsehood, or, what comes to the same thing, the order of the proposition to which falsehood is ascribed. We saw also that, if $p$ is a proposition of the $n$th order, a proposition in which $p$ occurs as an apparent variable is not of the $n$th order, but of a higher order. Hence the kind of truth or falsehood which can belong to the statement ``there is a proposition $p$ which I am affirming and which has falsehood of the $n$th order'' is truth or falsehood of a higher order than the $n$th. Hence the statement of Epimenides does not fall within its own scope, and therefore no contradiction emerges. 

If we regard the statement ``I am lying'' as a compact way of simultaneously making all the following statements: ``I am asserting a false proposition of the first order,'' ```I am asserting a false proposition of the second order,'' and so on, we find the following curious state of things: As no proposition of the first order is being asserted, the statement ``I am asserting a false proposition of the first order'' is false. This statement is of the second order, hence the statement ``I am making a false statement of the second order'' is true. This is a statement of the third order, and is the only statement of the third order which is being made. Hence the statement ``I am making a false statement of the third order'' is false. Thus we see that the statement ``I am making a false statement of order $2n+1$'' is false, while the statement ``I am making a false statement of order $2n$'' is true. But in this state of things there is no contradiction.

(2) In order to solve the contradiction about the class of classes which are not members of themselves, we shall assume, what will be explained in the next Chapter, that a proposition about a class is always to be reduced to a statement about a function which defines the class, \textit{i.e.}\ about a function which is satisfied by the members of the class and by no other arguments. Thus a class is an object derived from a function and presupposing the function, just as, for example, $\pmall{\phi}\pmdot \phi x$ presupposes the function $\pmpf{\phi}{\pmhat{x}}$. Hence a class cannot, by the vicious-circle principle, significantly be the argument to its defining function, that is to say, if we denote \pagefirst{66} by ``$\pmcls{z}{\phi(z)}$'' the class defined by $\pmpf{\phi}{\pmhat{z}}$, the symbol ``$\phi\{\pmcls{z}{\phi(z)}\}$'' must be meaningless. Hence a class neither satisfies nor does not satisfy its defining function, and therefore (as will appear more fully in Chapter III) is neither a member of itself nor not a member of itself. This is an immediate consequence of the limitation to the possible arguments to a function which was explained at the beginning of the present Chapter. Thus if $\alpha$ is a class, the statement ``$\alpha$ is not a member of $\alpha$'' is always meaningless, and there is therefore no sense in the phrase ``the class of those classes which are not members of themselves.'' Hence the contradiction which results from supposing that there is such a class disappears.

(3) Exactly similar remarks apply to ``the relation which holds between $R$ and $S$ whenever $R$ does not have the relation $R$ to $S$.'' Suppose the relation $R$ is defined by a function $\phi(x, y)$, \textit{i.e.}\ $R$ holds between $x$ and $y$ whenever $\phi(x, y)$ is true, but not otherwise. Then in order to interpret ``$R$ has the relation $R$ to $S$,'' we shall have to suppose that $R$ and $S$ can significantly be the arguments to $\phi$. But (assuming, as will appear in Chapter III, that $R$ presupposes its defining function) this would require that $\phi$ should be able to take as argument an object which is defined in terms of $\phi$, and this no function can do, as we saw at the beginning of this Chapter. Hence ``$R$ has the relation $R$ to $S$'' is meaningless, and the contradiction ceases.

(4) The solution of Burali-Forti's contradiction requires some further developments for its solution. At this stage, it must suffice to observe that a series is a relation, and an ordinal number is a class of series. (These statements are justified in the body of the work.) Hence a series of ordinal numbers is a relation between classes of relations, and is of higher type than any of the series which are members of the ordinal numbers in question. Burali-Forti's ``ordinal number of all ordinals'' must be the ordinal number of all ordinals of a given type, and must therefore be of higher type than any of these ordinals. Hence it is not one of these ordinals, and there is no contradiction in its being greater than any of them\footnote{The solution of Burali-Forti's paradox by means of the theory of types is given in detail in $\pmast256$.}.

(5) The paradox about ``the least integer not nameable in fewer than nineteen syllables'' embodies, as is at once obvious, a vicious-circle fallacy. For the word ``nameable'' refers to the totality of names, and yet is allowed to occur in what professes to be one among names. Hence there can be no such thing as a totality of names, in the sense in which the paradox speaks of ``names.'' It is easy to see that, in virtue of the hierarchy of functions, the theory of types renders a totality of ``names'' impossible. We may, in fact, distinguish names of different orders as follows: (a) Elementary names will be such as are true ``proper names,'' \textit{i.e.}\ conventional \pagefirst{67} appellations not involving any description. (b) First-order names will be such as involve a description by means of a first-order function; that is to say, if $\pmpred{\phi}{\pmhat{x}}$ is a first-order function, ``the term which satisfies $\pmpred{\phi}{\pmhat{x}}$'' will be a first-order name, though there will not always be an object named by this name. (c) Second-order names will be such as involve a description by means of a second-order function; among such names will be those involving a reference to the totality of first-order names. And so we can proceed through a whole hierarchy. But at no stage can we give a meaning to the word ``nameable'' unless we specify the order of names to be employed; and any name in which the phrase ``nameable by names of order $n$'' occurs is necessarily of a higher order than the $n$th. Thus the paradox disappears. 

The solutions of the paradox about the least indefinable ordinal and of Richard's paradox are closely analogous to the above. The notion of ``definable,'' which occurs in both, is nearly the same as ``nameable,'' which occurs in our fifth paradox: ``definable'' is what ``nameable'' becomes when elementary names are excluded, \textit{i.e.}\ ``definable'' means ``nameable by a name which is not elementary.'' But here there is the same ambiguity as to type as there was before, and the same need for the addition of words which specify the type to which the definition is to belong. And however the type may be specified, ``the least ordinal not definable by definitions of this type'' is a definition of a higher type; and in Richard's paradox, when we confine ourselves, as we must, to decimals that have a definition of a given type, the number $N$, which causes the paradox, is found to have a definition which belongs to a higher type, and thus not to come within the scope of our previous definitions.

An indefinite number of other contradictions, of similar nature to the above seven, can easily be manufactured. In all of them, the solution is of the same kind. In all of them, the appearance of contradiction is produced by the presence of some word which has systematic ambiguity of type, such as \textit{truth}, \textit{falsehood}, \textit{function}, \textit{property}, \textit{class}, \textit{relation}, \textit{cardinal}, \textit{ordinal}, \textit{name}, \textit{definition}. Any such word, if its typical ambiguity is overlooked, will apparently generate a totality containing members defined in terms of itself, and will thus give rise to vicious-circle fallacies. In most cases, the conclusions of arguments which involve vicious-circle fallacies will not be self-contradictory, but wherever we have an illegitimate totality, a little ingenuity will enable us to construct a vicious-circle fallacy leading to a contradiction, which disappears as soon as the typically ambiguous words are rendered typically definite, \textit{i.e.}\ are determined as belonging to this or that type.

Thus the appearance of contradiction is always due to the presence of words embodying a concealed typical ambiguity, and the solution of the apparent contradiction lies in bringing the concealed ambiguity to light.

\pagefirst{68} In spite of the contradictions which result from unnoticed typical ambiguity, it is not desirable to avoid words and symbols which have typical ambiguity. Such words and symbols embrace practically all the ideas with which mathematics and mathematical logic are concerned: the systematic ambiguity is the result of a systematic analogy. That is to say, in almost all the reasonings which constitute mathematics and mathematical logic, we are using ideas which may receive any one of an infinite number of different typical determinations, any one of which leaves the reasoning valid. Thus by employing typically ambiguous words and symbols, we are able to make one chain of reasoning applicable to any one of an infinite number of different cases, which would not be possible if we were to forego the use of typically ambiguous words and symbols.

Among propositions wholly expressed in terms of typically ambiguous notions practically the only ones which may differ, in respect of truth or falsehood, according to the typical determination which they receive, are existence-theorems. If we assume that the total number of individuals is $n$, then the total number of classes of individuals is $2^n$, the total number of classes of classes of individuals is $2^{2^n}$'', and so on. Here $n$ may be either finite or infinite, and in either case $2^n > n$. Thus cardinals greater than $n$ but not greater than $2^n$ exist as applied to classes, but not as applied to classes of individuals, so that whatever may be supposed to be the number of individuals, there will be existence-theorems which hold for higher types but not for lower types. Even here, however, so long as the number of individuals is not asserted, but is merely assumed hypothetically, we may replace the type of individuals by any other type, provided we make a corresponding change in all the other types occurring in the same context. That is, we may give the name ``relative individuals'' to the members of an arbitrarily chosen type $\tau$, and the name ``relative classes of individuals'' to classes of ``relative individuals,'' and so on. Thus so long as only hypotheticals are concerned, in which existence-theorems for one type are shown to be implied by existence-theorems for another, only relative types are relevant even in existence-theorems. This applies also to cases where the hypothesis (and therefore the conclusion) is \textit{asserted}, provided the assertion holds for any type, however chosen. For example, any type has at least one member; hence any type which consists of classes, of whatever order, has at least two members. But the further pursuit of these topics must be left to the body of the work.

\chapter*{\centering CHAPTER III. \\ \begin{small} INCOMPLETE SYMBOLS \end{small}}  \addcontentsline{toc}{chapter}{CHAPTER III. INCOMPLETE SYMBOLS} \pagefirst{69} 

(1) \textit{Descriptions}. By an ``incomplete'' symbol we mean a symbol which is not supposed to have any meaning in isolation, but is only defined in certain contexts. In ordinary mathematics, for example, $\frac{d}{dx}$ and $\int_{a}^{b}$ are incomplete symbols: something has to be supplied before we have anything significant. Such symbols have what may be called a ``definition in use.'' Thus if we put
\[
	\nabla^2 \pmiddf \frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}+\frac{\partial^2}{\partial z^2} \pmdf,
\]
we define the \textit{use} of $\nabla^2$, but $\nabla^2$ by itself remains without meaning. This distinguishes such symbols from what (in a generalized sense) we may call \textit{proper names}: ``Socrates,'' for example, stands for a certain man, and therefore has a meaning by itself, without the need of any context,. If we supply a context, as in ``Socrates is mortal,'' these words express a fact of which Socrates himself is a constituent: there is a certain object, namely Socrates, which does have the property of mortality, and this object is a constituent of the complex fact which we assert when we say ``Socrates is mortal.'' But in other cases, this simple analysis fails us. Suppose we say: ``The round square does not exist.'' It seems plain that this is a true proposition, yet we cannot regard it as denying the existence of a certain object called ``the round square.'' For if there were such an object, it would exist: we cannot first assume that there is a certain object, and then proceed to deny that there is such an object. Whenever the grammatical subject of a proposition can be supposed not to exist without rendering the proposition meaningless, it is plain that the grammatical subject is not a proper name, \textit{i.e.}\ not a name directly representing some object. Thus in all such cases, the proposition must be capable of being so analysed that what was the grammatical subject shall have disappeared. Thus when we say ``the round square does not exist,'' we may, as a first attempt at such analysis, substitute ``it is false that there is an object $x$ which is both round and square.'' Generally, when ``the so-and-so'' is said not to exist, we have a proposition of the form\footnote{Cf. pp. 30, 31.}
\begin{flalign*}
	&& && &\text{``}\pmnot\pmexists\pmdsc{x}(\phi x)\text{,''} & && \\
	\textit{i.e.}\ && && \pmnot\{&\pmsome{c}\pmdott\phi x \pmdot \pmiff_{x} \pmdot x=c\}, & &&
\end{flalign*}
\pagefirst{70} or some equivalent. Here the apparent grammatical subject $\pmdsc{x}(\phi x)$ has completely disappeared; thus in ``$\pmnot\pmexists\pmdsc{x}(\phi x)$,'' $\pmdsc{x}(\phi x)$ is an \textit{incomplete} symbol.

By an extension of the above argument, it can easily be shown that $\pmdsc{x}(\phi x)$ is \textit{always} an incomplete symbol. Take, for example, the following proposition: ``Scott is the author of Waverley.'' [Here ``the author of Waverley'' is $\pmdsc{x}(x$ wrote Waverley).] This proposition expresses an identity; thus if ``the author of Waverley'' could be taken as a proper name, and supposed to stand for some object $c$, the proposition would be ``Scott is $c$.'' But if $c$ is any one except Scott, this proposition is false; while if $c$ \textit{is} Scott, the proposition is ``Scott is Scott,'' which is trivial, and plainly different from ``Scott is the author of Waverley.'' Generalizing, we see that the proposition
\[ 
	a=\pmdsc{x}(\phi x)
 \]
is one which may be true or may be false, but is never merely trivial, like $a=a$; whereas, if $\pmdsc{x}(\phi x)$ were a proper name, $a=\pmdsc{x}(\phi x)$ would necessarily be either false or the same as the trivial proposition $a=a$. We may express this by saying that $a=\pmdsc{x}(\phi x)$ is not a value of the propositional function $a=y$, from which it follows that $\pmdsc{x}(\phi x)$ is not a value of $y$. But since $y$ may be anything, it follows that $\pmdsc{x}(\phi x)$ is nothing. Hence, since in use it has meaning, it must be an incomplete symbol.

It might be suggested that ``Scott is the author of Waverley'' asserts that ``Scott'' and ``the author of Waverley'' are two names for the same object. But a little reflection will show that this would be a mistake. For if that were the meaning of ``Scott is the author of Waverley,'' what would be required for its truth would be that Scott should have been \textit{called} the author of Waverley: if he had been so called, the proposition would be true, even if some one else had written Waverley; while if no one called him so, the proposition would be false, even if he had written Waverley. But in fact he wits the author of Waverley at a time when no one called him so, and he would not have been the author if every one had called him so but some one else had written Waverley. Thus the proposition ``Scott is the author of Waverley'' is not a proposition about names, like ``Napoleon is Bonaparte''; and this illustrates the sense in which ``the author of Waverley'' differs from a true proper name.

Thus all phrases (other than propositions) containing the word \textit{the} (in the singular) are incomplete symbols: they have a meaning in use, but not in isolation. For ``the author of Waverley'' cannot mean the same as ``Scott,'' or ``Scott is the author of Waverley'' would mean the same as ``Scott is Scott,'' which it plainly does not; nor can ``the author of Waverley'' mean anything other than ``Scott,'' or ``Scott is the author of Waverley'' would be false. Hence ``the author of Waverley'' means nothing.

\pagefirst{71} It follows from the above that we must not attempt to define ``$\pmdsc{x}(\phi x)$,'' but must define the \textit{uses} of this symbol, \textit{i.e.}\ the propositions in whose symbolic expression it occurs. Now in seeking to define the uses of this symbol, it is important to observe the import of propositions in which it occurs. Take as an illustration: ``The author of Waverley was a poet.'' This implies (1) that Waverley was written, (2) that it was written by one man, and not in collaboration, (3) that the one man who wrote it was a poet. If any one of these fails, the proposition is false. Thus ``the author of `Slawkenburgius on Noses' was a poet'' is false, because no such book was ever written; ``the author of `The Maid's Tragedy' was a poet'' is false, because this play was written by Beaumont and Fletcher jointly. These two possibilities of falsehood do not arise if we say ``Scott was a poet.'' Thus our interpretation of the uses of $\pmdsc{x}(\phi x)$ must be such as to allow for them. Now taking $\phi x$ to replace ``$x$ wrote Waverley,'' it is plain that any statement apparently about $\pmdsc{x}(\phi x)$ requires (1) $\pmsome{x}\pmdot\phi x$ and (2) $\phi x\pmand \phi y \pmdot \pmimp_{x,y} \pmdot x=y$; here (1) states that \textit{at least} one object satisfies $\phi x$, while (2) states that \textit{at most} one object satisfies $\phi x$. The two together are equivalent to
\begin{flalign*}
	&& \pmsome{c}&\pmdott \phi x \pmdot \pmiff_x \pmdot x=c, & && \\
	\text{which we defined as} && &\pmexists \pmdsc{x}(\phi x). & &&
\end{flalign*}
Thus ``$\pmexists \pmdsc{x}(\phi x)$'' must be part of what is affirmed by any proposition about $\pmdsc{x}(\phi x)$. If our proposition is $f\{\pmdsc{x}(\phi x)\}$, what is further affirmed is $fc$, if $\phi x \pmdot \pmiff_x \pmdot x=c$. Thus we have
\[ 
	f \{\pmdsc{x}(\phi x)\} \pmdot \pmiddf \pmdott \pmsome{c}\pmdott \phi x \pmdot \pmiff_x \pmdot x=c \pmandd fc \pmdf,
\]
\textit{i.e.}\ ``the $x$ satisfying $\phi x$ satisfies $fx$'' is to mean: ``There is an object $c$ such that $\phi x$ is true when, and only when, $x$ is $c$, and $fc$ is true,'' or, more exactly: ``There is a $c$ such that `$\phi x$' is always equivalent to `$x$ is $c$,' and $fc$.'' In this, ``$\pmdsc{x}(\phi x)$'' has completely disappeared; thus ``$\pmdsc{x}(\phi x)$'' is merely symbolic, and does not directly represent an object, as single small Latin letters are assumed to do\footnote{We shall generally write ``$f\pmdsc{x}(\phi x)$'' rather than ``$f\{\pmdsc{x}(\phi x)\}$'' in future.}.

The proposition ``$a=\pmdsc{x}(\phi x)$'' is easily shown to be equivalent to ``$\phi x \pmdot \pmiff_x \pmdot x=a$.'' For, by the definition, it is
\[
	\pmsome{c}\pmdott \phi x \pmdot \pmiff_x \pmdot x=c \pmandd a=c,
\]
\textit{i.e.}\ ``there is a $c$ for which $\phi x \pmdot \pmiff_x \pmdot x = c$, and this $c$ is $a$,'' which is equivalent to ``$\phi x \pmdot \pmiff_x \pmdot x=a$.'' Thus ``Scott is the author of Waverley'' is equivalent to:
\begin{center}
	```$x$ wrote Waverley' is always equivalent to `$x$ is Scott,'''
\end{center}
\textit{i.e.}\ ``$x$ wrote Waverley'' is true when $x$ is Scott and false when $x$ is not Scott.

Thus although ``$\pmdsc{x}(\phi x)$'' has no meaning by itself, it may be substituted for $y$ in any propositional function $fy$, and we get a significant proposition, though not a value of $fy$.

\pagefirst{72} When $f\{\pmdsc{x}(\phi x)\}$, as above defined, forms part of some other proposition, we shall say that $\pmdsc{x}(\phi x)$ has a \textit{secondary} occurrence. When $\pmdsc{x}(\phi x)$ has a secondary occurrence, a proposition in which it occurs may be true even when $\pmdsc{x}(\phi x)$ does not exist. This applies, \textit{e.g.}\ to the proposition: ``There is no such person as the King of France.'' We may interpret this as
\begin{flalign*}
	&& &\pmnot\{\pmexists \pmdsc{x}(\phi x)\}, & \\
	\text{or as} && \pmnot\{&\pmsome{c}\pmdot c=\pmdsc{x}(\phi x)\}, &
\end{flalign*}
if ``$\phi x$'' stands for ``$x$ is King of France.'' In either case, what is asserted is that a proposition $p$ in which ``$\pmdsc{x}(\phi x)$ occurs is false, and this proposition $p$ is thus part of a larger proposition. The same applies to such a proposition as the following: ``If France were a monarchy, the King of France would be of the House of Orleans.''

It should be observed that such a proposition as
\[
	\pmnot f\{\pmdsc{x}(\phi x)\}
\]
is ambiguous; it may deny $f\{\pmdsc{x}(\phi x)\}$, in which case it will be true if $\pmdsc{x}(\phi x)$ does not exist, or it may mean
\[  
	\pmsome{c}\pmdott \phi x \pmdot \pmiff_x \pmdot x=c \pmandd \pmnot fc,
\]
in which case it can only be true if $\pmdsc{x}(\phi x)$ exists. In ordinary language, the latter interpretation would usually be adopted. For example, the proposition ``the King of France is not bald'' would usually be rejected as false, being held to mean ``the King of France exists and is not bald,'' rather than ``it is false that the King of France exists and is bald.'' When $\pmdsc{x}(\phi x)$ exists, the two interpretations of the ambiguity give equivalent results; but when $\pmdsc{x}(\phi x)$ does not exist, one interpretation is true and one is false. It is necessary to be able to distinguish these in our notation; and generally, if we have such propositions as
\begin{flalign*}
	&& &\psi\pmdsc{x}(\phi x)\pmdot \pmimp \pmdot p, & \\
	&& &p \pmdot \pmimp \pmdot \psi\pmdsc{x}(\phi x), & \\
	&& &\psi\pmdsc{x}(\phi x) \pmdot \pmimp \pmdot \chi\pmdsc{x}(\phi x), &
\end{flalign*}
and so on, we must be able by our notation to distinguish whether the whole or only part of the proposition concerned is to be treated as the ``$f \pmdsc{x}(\phi x)$'' of our definition. For this purpose, we will put ``$[\pmdsc{x}(\phi x)]$'' followed by dots at the beginning of the part (or whole) which is to be taken as $\pmdsc{x}(\phi x)$, the dots being sufficiently numerous to bracket off the $\pmdsc{x}(\phi x)$; \textit{i.e.}\ $f\pmdsc{x}(\phi x)$ is to be everything following the dots until we reach an equal number of dots not signifying a logical product, or a greater number signifying a logical product, or the end of the sentence, or the end of a bracket enclosing ``$[\pmdsc{x}(\phi x)]$.'' Thus
\begin{flalign*}
	&& &[\pmdsc{x}(\phi x)]\pmdot \psi\pmdsc{x}(\phi x) \pmdot \pmimp \pmdot p & \\
	\pagefirst{73} &\text{will mean} & &\pmsome{c} \pmdott \phi x \pmdot\pmiff_x\pmdot x = c \pmandd \psi c \pmdott \pmimp \pmdot p, & \\
	&\text{but} & &[\pmdsc{x}(\phi x)]\pmdott \psi\pmdsc{x}(\phi x) \pmdot \pmimp \pmdot p & \\
	&\text{will mean} & &\pmsome{c} \pmdott \phi x \pmdot\pmiff_x\pmdot x = c \pmdott \psi c \pmdot \pmimp \pmdot p. &
\end{flalign*}
It is important to distinguish these two, for if $\pmdsc{x}(\phi x)$ does not exist, the first is true and the second false. Again
\begin{flalign*}
	&& &[\pmdsc{x}(\phi x)]\pmdot \pmnot\psi\pmdsc{x}(\phi x) & \\
	&\text{will mean} & &\pmsome{c} \pmdott \phi x \pmdot\pmiff_x\pmdot x = c \pmandd \pmnot\psi c, & \\
	&\text{while} & &\pmnot\{[\pmdsc{x}(\phi x)]\pmdot \psi\pmdsc{x}(\phi x)\} & \\
	&\text{will mean} & &\pmnot\{\pmsome{c} \pmdott \phi x \pmdot\pmiff_x\pmdot x = c \pmandd \psi c\}. &
\end{flalign*}
Here again, when $\pmdsc{x}(\phi x)$ does not exist, the first is false and the second true.

In order to avoid this ambiguity in propositions containing $\pmdsc{x}(\phi x)$, we amend our definition, or rather our notation, putting
\[
	[\pmdsc{x}(\phi x)]\pmdot f\pmdsc{x}(\phi x) \pmdot \pmiddf \pmdott \pmsome{c} \pmdott \phi x \pmdot\pmiff_x\pmdot x = c \pmandd fc \pmdf.
\]
By means of this definition, we avoid any doubt as to the portion of our whole asserted proposition which is to be treated as the ``$f\pmdsc{x}(\phi x)$'' of the definition. This portion will be called the \textit{scope} of $\pmdsc{x}(\phi x)$. Thus in
\[
	 [\pmdsc{x}(\phi x)]\pmdot f\pmdsc{x}(\phi x) \pmdot \pmimp \pmdot p
\]
the scope of $\pmdsc{x}(\phi x)$ is $f\pmdsc{x}(\phi x)$; but in
\begin{flalign*}
	&& [\pmdsc{x}(&\phi x)]\pmdot f\pmdsc{x}(\phi x) \pmdot \pmimp \pmdot p & \\
	&\text{the scope is} & &f\pmdsc{x}(\phi x)\pmdot \pmimp \pmdot p; & \\
	&\text{in} & \pmnot\{[&\pmdsc{x}(\phi x)]\pmdot f\pmdsc{x}(\phi x)\} &
\end{flalign*}
the scope is $f\pmdsc{x}(\phi x)$; but in
\begin{flalign*}
&& [\pmdsc{x}(&\phi x)]\pmdot f\pmdsc{x}(\phi x) \pmdot \pmimp \pmdot p & \\
&\text{the scope is} & &\pmnot f\pmdsc{x}(\phi x). &
\end{flalign*}

It will be seen that when $\pmdsc{x}(\phi x)$ has the whole of the proposition concerned for its scope, the proposition concerned cannot be true unless $\pmexists\pmdsc{x}(\phi x)$; but when $\pmdsc{x}(\phi x)$ has only part of the proposition concerned for its scope, it may often be true even when $\pmdsc{x}(\phi x)$ does not exist. It will be seen further that when $\pmexists\pmdsc{x}(\phi x)$, we may enlarge or diminish the scope of $\pmdsc{x}(\phi x)$ as much as we please without altering the truth-value of any proposition in which it occurs.

If a proposition contains two descriptions, say $\pmdsc{x}(\phi x)$ and $\pmdsc{x}(\phi x)$, we have to distinguish which of them has the larger scope, \textit{i.e.}\ we have to distinguish
\begin{flalign*}
	\indent (1) && [\pmdsc{x}(\phi x)]\pmdott[\pmdsc{x}(\psi x)]\pmdot f\{\pmdsc{x}(\phi x), \pmdsc{x}(\psi x)\}, && \\
	\indent (2) && [\pmdsc{x}(\psi x)]\pmdott[\pmdsc{x}(\phi x)]\pmdot f\{\pmdsc{x}(\phi x), \pmdsc{x}(\psi x)\}. &&
\end{flalign*}

\pagefirst{74} The first of these, eliminating $\pmdsc{x}(\phi x)$, becomes
\begin{flalign*}
	\indent (3) && \pmsome{c}\pmdott \phi x \pmdot \pmiff_x \pmdot x=c \pmandd[\pmdsc{x}(\psi x)]\pmdot f\{(c, \pmdsc{x}(\psi x)\}, && 
\end{flalign*}
which, eliminating $\pmdsc{x}(\phi x)$, becomes
\begin{flalign*}
	\indent (4) && \pmsome{c}\pmdottt \phi x \pmdot \pmiff_x \pmdot x=c \pmanddd \pmsome{d}\pmdott \psi x \pmdot \pmiff_x \pmdot x=d \pmandd f\{(c, d)\}, && 
\end{flalign*}
and the same proposition results if, in (1), we eliminate first $\pmdsc{x}(\psi x)$ and then $\pmdsc{x}(\phi x)$. Similarly (2) becomes, when $\pmdsc{x}(\phi x)$ and $\pmdsc{x}(\psi x)$ are eliminated,
\begin{flalign*}
	\indent (5) && \pmsome{d}\pmdottt \phi x \pmdot \pmiff_x \pmdot x=d \pmanddd \pmsome{c}\pmdott \psi x \pmdot \pmiff_x \pmdot x=c \pmandd f\{(c, d)\}, && 
\end{flalign*}

(4) and (5) are equivalent, so that the truth-value of a proposition containing two descriptions is independent of the question which has the larger scope. 

It will be found that, in most cases in which descriptions occur, their scope is, in practice, the smallest proposition enclosed in dots or other brackets in which they are contained. Thus for example
\[
	 [\pmdsc{x}(\phi x)]\pmdot \psi\pmdsc{x}(\phi x)\pmdot\pmimp\pmdot[\pmdsc{x}(\phi x)]\pmdot \chi\pmdsc{x}(\phi x)
\]
will occur much more frequently than
\[
[\pmdsc{x}(\phi x)]\pmdott \psi\pmdsc{x}(\phi x)\pmdot\pmimp\pmdot \chi\pmdsc{x}(\phi x).
\]
For this reason it is convenient to decide that, when the scope of an occurrence of $\pmdsc{x}(\phi x)$ is the smallest proposition, enclosed in dots or other brackets, in which the occurrence in question is contained, the scope need not be indicated by ``$[\pmdsc{x}(\phi x)]$.'' Thus \textit{e.g.}\
\begin{flalign*}
	&& p \pmdot \pmimp \pmdot a&=\pmdsc{x}(\phi x) & \\
	&\text{will mean} & p \pmdot \pmimp \pmdot [\pmdsc{x}(\phi x&)]\pmdot a=\pmdsc{x}(\phi x); & \\
	&\text{and} & p \pmdot \pmimp \pmdot \pmsome{a}& \pmdot a=\pmdsc{x}(\phi x) & \\
	&\text{will mean} & p \pmdot \pmimp \pmdot \pmsome{a} \pmdot [\pmdsc{x}&(\phi x)] \pmdot a=\pmdsc{x}(\phi x); & \\
	&\text{and} & p \pmdot \pmimp \pmdot a &\pmnid \pmdsc{x}(\phi x) & \\
	&\text{will mean} & p \pmdot \pmimp \pmdot [\pmdsc{x}(\phi x)&]\pmdot \pmnot\{a=\pmdsc{x}(\phi x)\}; & \\
	&\text{but} & p \pmdot \pmimp \pmdot \pmnot\{&a=\pmdsc{x}(\phi x)\} && \\
	&\text{will mean} & p \pmdot \pmimp \pmdot \pmnot\{[\pmdsc{x}&(\phi x)]\pmdot a=\pmdsc{x}(\phi x)\}. && 
\end{flalign*}

This convention enables us, in the vast majority of cases that actually occur, to dispense with the explicit indication of the scope of a descriptive symbol; and it will be found that the convention agrees very closely with the tacit conventions of ordinary language on this subject. Thus for example, if ``$\pmdsc{x}(\phi x)$'' is ``the so-and-so,'' ``$a \pmnid \pmdsc{x}(\phi x)$'' is to be read ``$a$ is not the so-and-so,'' which would ordinarily be regarded as implying that ``the so-and-so'' exists; but ``$\pmnot\{a=\pmdsc{x}(\phi x)\}$'' is to be read ``it is not true that $a$ is the so-and-so,'' which would generally be allowed to hold if ``the so-and-so'' does not exist. Ordinary language is, of course, rather loose and fluctuating in its implications on this matter; but subject to the requirement of definiteness, our convention seems to keep as near to ordinary language as possible. 

\pagefirst{75} In the case when the smallest proposition enclosed in dots or other brackets contains two or more descriptions, we shall assume, in the absence of any indication to the contrary, that one which typographically occurs earlier has a larger scope than one which typographically occurs later. Thus 
\begin{flalign*}
	&& \pmdsc{x}(\phi x)&=\pmdsc{x}(\psi x) & \\
	&\text{will mean} & \pmsome{c}\pmdott \phi x \pmdot \pmiff_x \pmdot x=c& \pmandd [\pmdsc{x}(\psi x)]\pmdot c=\pmdsc{x}(\psi x), & \\
	&\text{while} & \pmdsc{x}(\psi x)&=\pmdsc{x}(\phi x) & \\
	&\text{will mean} & \pmsome{d}\pmdott \psi x \pmdot \pmiff_x \pmdot x=d& \pmandd [\pmdsc{x}(\phi x)]\pmdot \pmdsc{x}(\phi x)=d. & 
\end{flalign*}

These two propositions are easily shown to be equivalent.

(2) \textit{Classes}. The symbols for classes, like those for descriptions, are, in our system, incomplete symbols: their \textit{uses} are defined, but they themselves are not assumed to mean anything at all. That is to say, the uses of such symbols are so defined that, when the \textit{definiens} is substituted for the \textit{definiendum}, there no longer remains any symbol which could be supposed to represent a class. Thus classes, so far as we introduce them, are merely symbolic or linguistic conveniences, not genuine objects as their members are if they are individuals.

It is an old dispute whether formal logic should concern itself mainly with intensions or with extensions. In general, logicians whose training was mainly philosophical have decided for intensions, while those whose training was mainly mathematical have decided for extensions. The facts seem to be that, while mathematical logic requires extensions, philosophical logic  refuses to supply anything except intensions. Our theory of classes recognizes and reconciles these two apparently opposite facts, by showing that an extension (which is the same as a class) is an incomplete symbol, whose use always acquires its meaning through a reference to intension.

In the case of descriptions, it was possible to \textit{prove} that they are incomplete symbols. In the case of classes, we do not know of any equally definite proof, though arguments of more or less cogency can be elicited from the ancient problem of the One and the Many\footnote{Briefly, these arguments reduce to the following: If there is such an object as a class, it must be in some sense \textit{one} object. Yet it is only of classes that \textit{many} can be predicated. Hence, if we admit classes as objects, we must suppose that the same object can be both one and many, which seems impossible.}. It is not necessary for our purposes, however, to assert dogmatically that there are no such things as classes. It is only necessary for us to show that the incomplete symbols which we introduce as representatives of classes yield all the propositions for the sake of which classes might be thought essential. When this has been shown, the mere principle of economy of primitive ideas leads to the non-introduction of classes except as incomplete symbols.

\pagefirst{76} To explain the theory of classes, it is necessary first to explain the distinction between \textit{extensional} and \textit{intensional} functions. This is effected by the following definitions:

The \textit{truth-value} of a proposition is truth if it is true, and falsehood if it is false. (This expression is due to Frege.)

Two propositions are said to be \textit{equivalent} when they have the same truth-value, \textit{i.e.}\ when they are both true or both false.

Two propositional functions are said to be formally equivalent when they are equivalent with every possible argument, \textit{i.e.}\ when any argument which satisfies the one satisfies the other, and vice versa. Thus ``$\pmpf{\pmhat{x}}{\text{ is a man}}$'' is formally equivalent to ``$\pmpf{\pmhat{x}}{\text{ is a featherless biped}}$''; ````$\pmpf{\pmhat{x}}{\text{ is an even prime}}$'' is formally equivalent to ````$\pmpf{\pmhat{x}}{\text{ is identical with 2}}$.''

A function of a function is called \textit{extensional} when its truth-value with any argument is the same as with any formally equivalent argument. That is to say, $f(\pmpf{\phi}{\pmhat{z}})$ is an extensional function of $\pmpf{\phi}{\pmhat{z}}$ if, provided $\pmpf{\psi}{\pmhat{z}}$ is formally equivalent to $\pmpf{\phi}{\pmhat{z}}$, $f(\pmpf{\phi}{\pmhat{z}})$ is equivalent to $f(\pmpf{\phi}{\pmhat{z}})$. Here the apparent variables $\phi$ and $\psi$ are necessarily of the type from which arguments can significantly be supplied to $f$. We find no need to use as apparent variables any functions of non-predicative types; accordingly in the sequel all extensional functions considered are in fact functions of predicative functions\footnote{Cf. p. 53.}.

A function of a function is called \textit{intensional} when it is not extensional.

The nature and importance of the distinction between intensional and extensional functions will be made clearer by some illustrations. The proposition ```$x$ is a man' always implies `$x$ is a mortal''' is an extensional function of the function ``$\pmpf{\pmhat{x}}{\text{ is a man}}$,'' because we may substitute, for ``$x$ is a man,'' ``$x$ is a featherless biped,'' or any other statement which applies to the same objects to which ``$x$ is a man'' applies, and to no others. But the proposition ``$A$ believes that `$x$ is a man' always implies `$x$ is a mortal''' is an intensional function of ``$\pmpf{\pmhat{x}}{\text{ is a man}}$,'' because $A$ may never have considered the question whether featherless bipeds are mortal, or may believe wrongly that there are featherless bipeds which are not mortal. Thus even if ``$x$ is a featherless biped'' is formally equivalent to ``$x$ is a man,'' it by no means follows that a person who believes that all men are mortal must believe that all featherless bipeds are mortal, since he may have never thought about featherless bipeds, or have supposed that featherless bipeds were not always men. Again the proposition ``the number of arguments that satisfy the function $\pmpred{\phi}{\pmhat{z}}$ in $n$'' is an extensional function of $\pmpred{\phi}{\pmhat{z}}$, because its truth or falsehood is unchanged if we substitute for $\pmpred{\phi}{\pmhat{z}}$ any other function which is true whenever $\pmpred{\phi}{\pmhat{z}}$ is true, and false whenever $\pmpred{\phi}{\pmhat{z}}$ is false. But the proposition ``$A$ asserts that the number of arguments satisfying $\pmpred{\phi}{\pmhat{z}}$ is $n$'' is an intensional function of $\pmpred{\phi}{\pmhat{z}}$, \pagefirst{77} since, if $A$ asserts this concerning $\pmpred{\phi}{\pmhat{z}}$, he certainly cannot assert it concerning all predicative functions that are equivalent to $\pmpred{\phi}{\pmhat{z}}$, because life is too short. Again, consider the proposition ``two white men claim to have reached the North Pole.'' This proposition states ``two arguments satisfy the function `$x$ is a white man who claims to have reached the North Pole.''' The truth or falsehood of this proposition is unaffected if we substitute for ``$\pmpf{\pmhat{x}}{\text{ is a white man who claims to have reached the North Pole}}$'' any other statement which holds of the same arguments, and of no others. Hence it is an extensional function. But the proposition ``it is a strange coincidence that two white men should claim to have reached the North Pole,'' which states ``it is a strange coincidence that two arguments should satisfy the function `$\pmpf{\pmhat{x}}{\text{ is a white man who claims to have reached the North Pole}}$,''' is not equivalent to ``it is a strange coincidence that two arguments should satisfy the function $\pmpf{\pmhat{x}}{\text{ is Dr Cook or Commander Peary}}$.''' Thus ``it is a strange coincidence that $\pmpred{\phi}{\pmhat{x}}$ should be satisfied by two arguments'' is an intensional function of $\pmpred{\phi}{\pmhat{x}}$.

The above instances illustrate the fact that the functions of functions with which mathematics is specially concerned are extensional, and that intensional functions of functions only occur where non-mathematical ideas are introduced, such as what somebody believes or affirms, or the emotions aroused by some fact. Hence it is natural, in a mathematical logic, to lay special stress on extensional functions of functions.

When two functions are formally equivalent, we may say that they \textit{have the same extension}. In this definition, we are in close agreement with usage. We do not assume that there is such a thing as an extension: we merely define the whole phrase ``having the same extension.'' We may now say that an extensional function of a function is one whose truth or falsehood depends only upon the extension of its argument. In such a case, it is convenient to regard the statement concerned as being about the extension. Since extensional functions are many and important, it is natural to regard the extension as an object, called a \textit{class}, which is supposed to be the subject of all the equivalent statements about various formally equivalent functions. Thus \textit{e.g.}\ if we say ``there were twelve Apostles,'' it is natural to regard this statement as attributing the property of being twelve to a certain collection of men, namely those who were Apostles, rather than as attributing the property of being satisfied by twelve arguments to the function ``$\pmpf{\pmhat{x}}{\text{ was an Apostle}}$.'' This view is encouraged by the feeling that there is something which is identical in the case of two functions which ``have the same extension.'' And if we take such simple problems as ``how many combinations can be made of $n$ things?'' it seems at first sight necessary that each ``combination'' should be a single object which can be counted as one. This, however, is certainly not necessary technically, and we see no reason to suppose that it is true \pagefirst{78} philosophically. The technical procedure by which the apparent difficulty is overcome is as follows.

We have seen that an extensional function of a function may be regarded as a function of the class determined by the argument-function, but that an intensional function cannot be so regarded. In order to obviate the necessity of giving different treatment to intensional and extensional functions of functions, we construct an extensional function derived from any function of a predicative function $\pmpred{\psi}{\pmhat{z}}$, and having the property of being equivalent to the function from which it is derived, provided this function is extensional, as well as the property of being significant (by the help of the systematic ambiguity of equivalence) with any argument $\pmpf{\phi}{\pmhat{z}}$ whose arguments are of the same type as those of $\pmpred{\psi}{\pmhat{z}}$. The derived function, written ``$f\{\pmcls{z}{\phi z}\}$,'' is defined as follows: Given a function $f(\pmpred{\psi}{\pmhat{z}})$, our derived function is to be ``there is a predicative function which is formally equivalent to $\pmpf{\phi}{\pmhat{z}}$ and satisfies $f$.'' If $\pmpf{\phi}{\pmhat{z}}$ is a predicative function, our derived function will be true whenever $f(\pmpf{\phi}{\pmhat{z}})$ is true. If $f(\pmpf{\phi}{\pmhat{z}})$ is an extensional function, and $\pmpf{\phi}{\pmhat{z}}$ is a predicative function, our derived function will not be true unless $f(\pmpf{\phi}{\pmhat{z}})$ is true; thus in this case, our derived function is equivalent to $f(\pmpf{\phi}{\pmhat{z}})$. If $f(\pmpf{\phi}{\pmhat{z}})$ is not an extensional function, and if $\pmpf{\phi}{\pmhat{z}}$ is a predicative function, our derived function may sometimes be true when the original function is false. But in any case the derived function is always extensional.

In order that the derived function should be significant for any function $\pmpf{\phi}{\pmhat{z}}$, of whatever order, provided it takes arguments of the right type, it is necessary and sufficient that $f(\pmpred{\psi}{\pmhat{z}})$ should be significant, where $\pmpred{\psi}{\pmhat{z}}$ is any \textit{predicative} function. The reason of this is that we only require, concerning an argument $\pmpf{\phi}{\pmhat{z}}$, the hypothesis that it is formally equivalent to some predicative function $\pmpred{\psi}{\pmhat{z}}$, and formal equivalence has the same kind of systematic ambiguity as to type that belongs to truth and falsehood, and can therefore hold between functions of any two different orders, provided the functions take arguments of the same type. Thus by means of our derived function we have not merely provided extensional functions everywhere in place of intensional functions, but we have \textit{practically} removed the necessity for considering differences of type among functions whose arguments are of the same type. · This effects the same kind of simplification in our hierarchy as would result from never considering any but predicative functions.

If $f(\pmpred{\psi}{\pmhat{z}})$ can be built up by means of the primitive ideas of disjunction, negation, $\pmall{x}\pmdot \phi x$, and $\pmsome{x}\pmdot \phi x$, as is the case with all the functions of functions that explicitly occur in the present work, it will be found that, in virtue of the systematic ambiguity of the above primitive ideas, any function $\pmpf{\phi}{\pmhat{z}}$ whose arguments are of the same type as those of $\pmpred{\psi}{\pmhat{z}}$ can significantly be substituted for $\pmpred{\psi}{\pmhat{z}}$ in $f$ without any other symbolic change. Thus in \pagefirst{79} such a case what is symbolically, though not really, the same function $f$ can receive as arguments functions of various different types. If, with a given argument $\pmpf{\phi}{\pmhat{z}}$, the function $f(\pmpf{\phi}{\pmhat{z}})$, so interpreted, is equivalent to $\pmcls{z}{\phi z}$ whenever $\pmpred{\psi}{\pmhat{z}}$ is formally equivalent to $\pmpf{\phi}{\pmhat{z}}$, then $f\{\pmcls{z}{\phi z}\}$ is equivalent to $f(\pmpf{\phi}{\pmhat{z}})$ provided there is any predicative function formally equivalent to $\pmpf{\phi}{\pmhat{z}}$. At this point, we make use of the axiom of reducibility, according to which there always is a predicative function formally equivalent to $\pmpf{\phi}{\pmhat{z}}$.

As was explained above, it is convenient to regard an extensional function of a function as having for its argument not the function, but the class determined by the function. Now we have seen that our derived function is always extensional. Hence if our original function was $f(\pmpred{\psi}{\pmhat{z}})$, we write the derived function $\{f(\pmcls{z}{\phi z})\}$, where ``$\pmcls{z}{\phi z}$'' may be read ``the class of arguments which satisfy $\pmpf{\phi}{\pmhat{z}}$,'' or more simply ``the class determined by $\pmpf{\phi}{\pmhat{z}}$.'' Thus ``$\{f(\pmcls{z}{\phi z})\}$'' will mean: ``There is a predicative function $\pmpred{\psi}{\pmhat{z}}$ which is formally equivalent to $\pmpf{\phi}{\pmhat{z}}$ and is such that $f(\pmpred{\psi}{\pmhat{z}})$ is true.'' This is in reality a function of $\pmpf{\phi}{\pmhat{z}}$, but we treat it symbolically as if it had an argument $\pmcls{z}{\phi z}$. By the help of the axiom of reducibility, we find that the usual properties of classes result. For example, two formally equivalent functions determine the same class, and conversely, two functions which determine the same class are formally equivalent. Also to say that $x$ is a member of $\pmcls{z}{\phi z}$, \textit{i.e.}\ of the class determined by $\pmpf{\phi}{\pmhat{z}}$, is true when $\phi x$ is true, and false when $\phi x$ is false. Thus all the mathematical purposes for which classes might seem to be required are fulfilled by the purely symbolic objects $\pmcls{z}{\phi z}$, provided we assume the axiom of reducibility.

In virtue of the axiom of reducibility, if $\pmpf{\phi}{\pmhat{z}}$ is any function, there is a formally equivalent predicative function $\pmpred{\psi}{\pmhat{z}}$; then the class $\pmcls{z}{\phi z}$ is identical with the class $\pmcls{z}{\psi z}$, so that every class can be defined by a \textit{predicative} function. Hence the totality of the \textit{classes} to which a given term can be significantly said to belong or not to belong is a legitimate totality, although the totality of \textit{functions} which a given term can be significantly said to satisfy or not to satisfy is not a legitimate totality. The classes to which a given term $a$ belongs or does not belong are the classes defined by $a$-functions; they are also the classes defined by predicative $a$-functions. Let us call them $a$-classes. Then ``$a$-classes'' form a legitimate totality, derived from that of predicative $a$-functions. Hence many kinds of general statements become possible which would otherwise involve vicious-circle paradoxes. These general statements are none of them such as lead to contradictions, and many of them such as it is very hard to suppose illegitimate. The fact that they are rendered possible by the axiom of reducibility, and that they would otherwise be excluded by the vicious-circle principle, is to be regarded as an argument in favour of the axiom of reducibility.

\pagefirst{80} The above definition of ``the class defined by the function $\pmpf{\phi}{\pmhat{z}}$,'' or rather, of any proposition in which this phrase occurs, is, in symbols, as follows: 
\[
	f\{\pmcls{z}{\phi z}\} \pmdot \pmiddf \pmdott \pmsome{\psi}\pmdott \phi x \pmdot \pmiff_x \pmdot \pmpred{\psi}{x}\pmandd f\{\pmpred{\psi}{\pmhat{z}}\} \pmdf.
\]
In order to recommend this definition, we shall enumerate five requisites which a definition of classes must satisfy, and we shall then show that the above definition satisfies these five requisites.

We require of classes, if they are to serve the purposes for which they are commonly employed, that they shall have certain properties, which may be enumerated as follows. (1) Every propositional function must determine a class, which may be regarded as the collection of all the arguments satisfying the function in question. This principle must hold when the function is satisfied by an infinite number of arguments as well as when it is satisfied by a finite number. It must hold also when no arguments satisfy the function; \textit{i.e.}\ the ``null-class'' must be just as good a class as any other. (2) Two propositional functions which are formally equivalent, \textit{i.e.}\ such that any argument which satisfies either satisfies the other, must determine the same class; that is to say, a class must be something wholly determined by its membership, so that \textit{e.g.}\ the class ``featherless bipeds'' is identical with the class ``men,'' and the class ``even primes'' is identical with the class ``numbers identical with 2.'' (3) Conversely, two propositional functions which determine the same class must be formally equivalent; in other words, when the class is given, the membership is determinate: two different sets of objects cannot yield the same class. (4) In the same sense in which there are classes (whatever this sense may be), or in some closely analogous sense, there must also be classes of classes. Thus for example ``the combinations of $n$ things $m$ at a time,'' where the $n$ things form a given class, is a class of classes; each combination of $m$ things is a class, and each such class is a member of the specified set of combinations, which set is therefore a class whose members are classes. Again, the class of unit classes, or of couples, is absolutely indispensable; the former is the number 1, the latter the number 2. Thus without classes of classes, arithmetic becomes impossible. (5) It must under all circumstances be meaningless to suppose a class identical with one of its own members. For if such a supposition had any meaning, ``$\alpha \pmcin \alpha$'' would be a significant propositional function\footnote{As explained in Chapter I (p. 25), ``$x \pmcin \alpha$'' means ``$x$ is a member of the class $\alpha$,'' or, more shortly, ``$x$ is an $\alpha$.'' The definition of this expression in terms of our theory of classes will be given shortly.}, and so would ``$\alpha \pmnot\pmcin \alpha$.'' Hence, by (1) and (4), there would be a class of all classes satisfying the function ``$\alpha \pmnot \pmcin \alpha$.'' If we call this class $\kappa$, we shall have 
\[
	\alpha \pmcin \kappa \pmdot \pmiff_\alpha \pmdot \alpha \pmnot \pmcin \alpha.
\]
Since, by our hypothesis, ``$\kappa \pmcin \kappa$'' is supposed significant, the above equivalence, which holds with all possible values of $\alpha$, holds with the value $\kappa$, \textit{i.e.}\
\[
	\kappa \pmcin \kappa \pmdot \pmiff \pmdot \kappa \pmnot \pmcin \kappa.
\]
\pagefirst{81} But this is a contradiction\footnote{This is the second of the contradictions discussed at the end of Chapter II.}. Hence ``$\alpha \pmcin \alpha$'' and ``$\alpha \pmnot \pmcin \alpha$'' must always be meaningless. In general, there is nothing surprising about this conclusion, but it has two consequences which deserve special notice. In the first place, a class consisting of only one member must not be identical with that one member, \textit{i.e.}\ we must not have $\pmcunit{x} \pmcin x$. For we have $x \pmcin \pmcunit{x}$, and therefore, if $x = \pmcunit{x}$, we have $\pmcunit{x} \pmcin \pmcunit{x}$, which, we saw, must be meaningless. It follows that ``$\pmcunit{x} = x$'' must be absolutely meaningless, not simply false. In the second place, it might appear as if the class of all classes were a class, \textit{i.e.}\ as if (writing ``$\pmCls$'' for ``class'') ``$\pmCls\pmcin\pmCls$'' were a true proposition. But this combination of symbols must be meaningless; unless, indeed, an ambiguity exists in the meaning of ``$\pmCls$,'' so that, in ``$\pmCls \pmcin \pmCls$,'' the first ``$\pmCls$'' can be supposed to have a different meaning from the second.

As regards the above requisites, it is plain, to begin with, that, in accordance with our definition, every propositional function $\pmpf{\phi}{\pmhat{z}}$ determines a class $\pmcls{z}{\phi z}$. Assuming the axiom of reducibility, there must always be true propositions about $\pmcls{z}{\phi z}$, \textit{i.e.}\ true propositions of the form $f\{\pmcls{z}{\phi z}\}$. For suppose $\pmpf{\phi}{\pmhat{z}}$ is formally equivalent to $\pmpred{\psi}{\pmhat{z}}$, and suppose $\pmpred{\psi}{\pmhat{z}}$ satisfies some function $f$. Then $\pmcls{z}{\phi z}$ also satisfies $f$. Hence, given any function $\pmpf{\phi}{\pmhat{z}}$, there are true propositions of the form $f\{\pmcls{z}{\phi z}\}$, \textit{i.e.}\ true propositions in which ``the class determined by $\pmpf{\phi}{\pmhat{z}}$'' is grammatically the subject. This shows that our definition fulfills the first of our five requisites. 

The second and third requisites together demand that the classes $\pmcls{z}{\phi z}$ and $\pmcls{z}{\psi z}$ should be identical when, and only when, their defining functions are formally equivalent, \textit{i.e.}\ that we should have 
\[
	\pmcls{z}{\phi z} = \pmcls{z}{\psi z} \pmdot \pmiff \pmdott \phi x \pmdot \pmiff_x \pmdot \psi x.
\]
Here the meaning of ``$\pmcls{z}{\phi z} = \pmcls{z}{\psi z}$'' is to be derived, by means of a twofold application of the definition of $f\{\pmcls{z}{\phi z}\}$, from the definition of 
\begin{flalign*}
	&& &\text{``}\pmpred{\chi}{\pmhat{z}} = \pmpred{\theta}{\pmhat{z}}\text{''} & \\
	\text{which is} && \pmpred{\chi}{\pmhat{z}} = \pmpred{\theta}{\pmhat{z}} \pmdot \pmiddf& \pmdott \pmall{f}\pmdott \pmpred{f}{\pmpred{\chi}{\pmhat{z}}} \pmdot \pmimp \pmdot \pmpred{f}{\pmpred{\theta}{\pmhat{z}}} \pmdf &
\end{flalign*}
by the general definition of identity.

In interpreting ``$\pmcls{z}{\phi z} = \pmcls{z}{\psi z}$'' we will adopt the convention which we adopted in regard to $\pmdsc{x}(\phi x)$ and $\pmdsc{x}(\psi x)$, namely that the incomplete symbol which occurs first is to have the larger scope. Thus $\pmcls{z}{\phi z} = \pmcls{z}{\psi z}$ becomes, by our definition,
\[
	\pmsome{\chi}\pmdott \phi x \pmdot \pmiff_x \pmdot \pmpred{\chi}{x} \pmandd \pmpred{\chi}{\pmhat{z}}=\pmcls{z}{\psi z},
\]
which, by eliminating $\pmcls{z}{\psi z}$, becomes
\[
	\pmsome{\chi}\pmdottt \phi x \pmdot \pmiff_x \pmdot \pmpred{\chi}{x} \pmanddd \pmsome{\theta} \pmdott \psi x \pmdot \pmiff_x \pmdot \pmpred{\theta}{x} \pmandd \pmpred{\chi}{\pmhat{z}}=\pmpred{\theta}{\pmhat{z}},
\]
which is equivalent to
\[
	\pmsome{\chi, \theta}\pmdott \phi x \pmdot \pmiff_x \pmdot \pmpred{\chi}{x} \pmandd \psi x \pmdot \pmiff_x \pmdot \pmpred{\theta}{x} \pmandd \pmpred{\chi}{\pmhat{z}}=\pmpred{\theta}{\pmhat{z}},
\]
\pagefirst{82} which, again, is equivalent to,
\[
	\pmsome{\chi}\pmdott \phi x \pmdot \pmiff_x \pmdot \pmpred{\chi}{x} \pmandd \psi x \pmdot \pmiff_x \pmdot \pmpred{\chi}{x},
\]
which, in virtue of the axiom of reducibility, is equivalent to
\[ 
	\phi x \pmdot \pmiff_x \pmdot \psi x.
\]
Thus our definition of the use of $\pmcls{z}{\phi z}$ is such as to satisfy the conditions (2) and (3) which we laid down for classes, \textit{i.e.}\ we have
\[
	\pmthm \pmdottt \pmcls{z}{\phi z} = \pmcls{z}{\psi z} \pmdot \pmiff \pmdott \phi x \pmdot \pmiff_x \pmdot \psi x.
\]

Before considering classes of classes, it will be well to define membership of a class, \textit{i.e.}\ to define the symbol ``$x \pmcin \pmcls{z}{\phi z}$,'' which may be read ``$x$ is a member of the class determined by $\pmpf{\phi}{\pmhat{z}}$.'' Since this is a function of the form $f\{\pmcls{z}{\phi z}\}$, it must be derived, by means of our general definition of such functions, from the corresponding function $f\{\pmpred{\psi}{\pmhat{z}}\}$. We therefore put
\[
	x \pmcin \pmcls{z}{\psi z} \pmdot \pmiddf \pmdot \pmpred{\psi}{x} \pmdf.
\]
This definition is only needed in order to give a meaning to ``$x \pmcin \pmcls{z}{\phi z}$''; the meaning it gives is, in virtue of the definition of $f\{\pmcls{z}{\phi z}\}$,
\[
	\pmsome{\psi} \pmdott \phi y \pmdot \pmiff \pmdot \pmpred{\psi}{y} \pmandd \pmpred{\psi}{x}.
\]
It thus appears that ``$x \pmcin \pmcls{z}{\phi z}$'' implies $\phi x$, since it implies $\pmpred{\psi}{x}$, and $\pmpred{\psi}{x}$ is equivalent to $\phi x$; also, in virtue of the axiom of reducibility, $\phi x$ implies ``$x \pmcin \pmcls{z}{\phi z}$,'' since there is a predicative function $\psi$ formally equivalent to $\phi$, and $x$ must satisfy $\psi$, since $x$ (\textit{ex hypothesi}) satisfies $\phi$. Thus in virtue of the axiom of reducibility we have
\[
	\pmthm \pmdott x \pmcin \pmcls{z}{\phi z} \pmdot \pmiff \pmdot \phi x,
\]
\textit{i.e.}\ $x$ is a member of the class $\pmcls{z}{\phi z}$ when, and only when, $x$ satisfies the function $\phi$, which defines the class.

We have next to consider how to interpret a class of classes. As we have defined $f\{\pmcls{z}{\phi z}\}$, we shall naturally regard a class of classes as consisting of those values of $\pmcls{z}{\phi z}$ which satisfy $f\{\pmcls{z}{\phi z}\}$. Let us write $\alpha$ for $\pmcls{z}{\phi z}$; then we may write $\pmcls{\alpha}{f \alpha}$ for the class of values of $\alpha$ which satisfy $f\alpha$\footnote{The use of a single letter, such as $\alpha$ or $\beta$, to represent a variable class, will be further explained shortly.}. We shall apply the same definition, and put
\[
	F\{\pmcls{\alpha}{f \alpha}\} \pmdot \pmiddf \pmdott \pmsome{g}\pmdott f\beta \pmdot \pmiff_\beta \pmdot \pmpred{g}{\beta} \pmandd F\{\pmpred{g}{\pmhat{\alpha}}\} \pmdf,
\]
where ``$\beta$'' stands for any expression of the form $\pmcls{z}{\pmpred{\psi}{z}}$.

Let us take ``$\gamma \pmcin \pmcls{\alpha}{f\alpha}$'' as an instance of $F\{\pmcls{\alpha}{f \alpha}\}$. Then
\begin{flalign*}
	& & \pmthm \pmdottt \gamma \pmcin \pmcls{\alpha}{f\alpha}& \pmdot \pmiff \pmdott \pmsome{g} \pmdott f\beta \pmdot \pmiff_\beta \pmdot \pmpred{g}{\beta} \pmandd \gamma \pmcin \pmcls{\alpha}{f\alpha}. & \\
	&\text{Just as we put} & x \pmcin & \pmpred{\psi}{\pmhat{z}} \pmdot \pmiddf \pmdot \pmpred{\psi}{x} \hspace{1.3em} \pmdf, & \\
	&\text{so we put} & &\gamma \pmcin \pmpred{g}{\pmhat{\alpha}} \pmdot \pmiddf \pmdot \pmpred{g}{\gamma} \pmdf. & 
\end{flalign*}
Thus we find
\[
	\pmthm \pmdottt \gamma \pmcin \pmcls{\alpha}{f\alpha} \pmdot \pmiff \pmdott \pmsome{g} \pmdott f\beta \pmdot \pmiff_\beta \pmdot \pmpred{g}{\beta} \pmandd \pmpred{g}{\gamma}.
\]

\pagefirst{83} If we now extend the axiom of reducibility so as to apply to functions of functions, \textit{i.e.}\ if we assume
\[
	\pmsome{g} \pmdott f(\pmpred{\psi}{\pmhat{z}}) \pmdot \pmiff_\psi \pmdot \pmpred{g}{(\pmpred{\psi}{\pmhat{z}})},
\]
we easily deduce
\begin{flalign*}
	&& \pmthm \pmdott \pmsome{g} \pmdott &f\{\pmcls{z}{\pmpred{\psi}{z}}\} \pmdot \pmiff_\psi \pmdot \pmpred{g}{\{\pmcls{z}{\pmpred{\psi}{z}}\}}, & \\
	&\textit{i.e.}\ & \pmthm & \pmdott \pmsome{g} \pmdott f\beta \pmdot \pmiff_\beta \pmdot \pmpred{g}{\beta}. & \\
	&\text{Thus} && \pmthm  \pmdott \gamma \pmcin \pmcls{\alpha}{f\alpha} \pmdot \pmiff \pmdot f\gamma. & 
\end{flalign*}

Thus every function which can take classes as arguments, \textit{i.e.}\ every function of functions, determines a class of classes, whose members are those classes which satisfy the determining function. Thus the theory of classes of classes offers no difficulty.

We have next to consider our fifth requisite,namely that ``$\pmcls{z}{\phi z} \pmcin \pmcls{z}{\phi z}$'' is to be meaningless. Applying our definition of $f\{\pmcls{z}{\phi z}\}$, we find that if this collection of symbols had a meaning, it would mean
\[
	\pmsome{\psi} \pmdott \phi x \pmdot \pmiff_x \pmdot \pmpred{\psi}{x} \pmandd \pmpred{\psi}{\pmhat{z}} \pmcin \pmpred{\psi}{\pmhat{z}},
\]
\textit{i.e.}\ in virtue of the definition
\begin{flalign*}
	&& &x \pmcin \pmpred{\psi}{\pmhat{z}} \pmdot \pmiddf \pmdot \pmpred{\psi}{x} \pmdf, & \\
	\text{it would mean} && \pmsome{\psi}&\pmdott \phi x \pmdot \pmiff_x \pmdot \pmpred{\psi}{x} \pmandd \pmpred{\psi}{(\pmpred{\psi}{\pmhat{z}})}. &
\end{flalign*}
But here the symbol ``$\pmpred{\psi}{(\pmpred{\psi}{\pmhat{z}})}$'' occurs, which assigns a function as argument to itself. Such a symbol is always meaningless, for the reasons explained at the beginning of Chapter II (pp. 41---3). Hence ``$\pmcls{z}{\phi z} \pmcin \pmcls{z}{\phi z}$'' is meaningless, and our fifth and last requisite is fulfilled.

As in the case of $f\pmdsc{x}(\phi x)$, so in that of $f\{\pmcls{z}{\phi z}\}$, there is an ambiguity as to the scope of $\pmcls{z}{\phi z}$ if it occurs in a proposition which itself is part of a larger proposition. But in the case of classes, since we always have the axiom of reducibility, namely
\[
	\pmsome{\psi} \pmdott \phi x \pmdot \pmiff_x \pmdot \pmpred{\psi}{x},
\]
which takes the place of $\pmexists\pmdsc{x}(\phi x)$, it follows that the truth-value of any proposition in which $\pmcls{z}{\phi z}$ occurs is the same whatever scope we may give to $\pmcls{z}{\phi z}$, provided the proposition is an extensional function of whatever functions it may contain. Hence we may adopt the convention that the scope is to be always the smallest proposition enclosed in dots or brackets in which $\pmcls{z}{\phi z}$ occurs. If at any time a larger scope is required, we may indicate it by ``$[\pmcls{z}{\phi z}]$'' followed by dots, in the same way as we did for $[\pmdsc{x}(\phi x)]$.

Similarly when two class symbols occur, \textit{e.g.}\ in a proposition of the form $f\{\pmcls{z}{\phi z}, \pmcls{z}{\psi z}\}$, we need not remember rules for the scopes of the two symbols, since all choices give equivalent results, as it is easy to prove. For the preliminary propositions a rule is desirable, so we can decide that the class symbol which occurs first in the order of writing is to have the larger scope.

\pagefirst{84} The representation of a class by a single letter $\alpha$ can now be understood. For the denotation of $\alpha$ is ambiguous, in so far as it is undecided as to which of the symbols $\pmcls{z}{\phi z}, \pmcls{z}{\psi z}, \pmcls{z}{\chi z},$ etc. it is to stand for, where $\pmpf{\phi}{\pmhat{z}},\pmpf{\psi}{\pmhat{z}},\pmpf{\chi}{\pmhat{z}},$ etc. are the various determining functions of the class. According to the choice made, different propositions result. But all the resulting propositions are equivalent by virtue of the easily proved proposition:
\[
	\text{``} \pmthm \pmdott \phi x \pmiff_x \psi x \pmdot \pmimp \pmdot f\{\pmcls{z}{\phi z}\} \pmiff f\{\pmcls{z}{\psi z}\}.\text{''}
\]
Hence unless we wish to discuss the determining function itself, so that the notion of a class is really not properly present, the ambiguity in the denotation of $\alpha$ is entirely immaterial, though, as we shall see immediately, we are led to limit ourselves to predicative determining functions. Thus ``$f(\alpha)$'' where $\alpha$ is a variable class, is really ``$f\{\pmcls{z}{\phi z}\}$,'' where $\phi$, is a variable function, that is, it is
\[
	\text{``}\pmsome{\psi} \pmdot \phi x \pmiff_x \pmpred{\psi}{x} \pmand f\{\pmpred{\psi}{\pmhat{z}}\},\text{''}
\]
where $\phi$ is a variable function. But here a difficulty arises which is removed by a limitation to our practice and by the axiom of reducibility. For the determining functions $\pmpf{\phi}{\pmhat{z}},\pmpf{\psi}{\pmhat{z}},$ etc. will be of different types, though the axiom of reducibility secures that some are predicative functions. Then, in interpreting $\alpha$ as a variable in terms of the variation of any determining function, we shall be led into errors unless we confine ourselves to predicative determining functions. These errors especially arise in the transition to total variation (cf. pp. 15, 16). Accordingly
\[
	f\alpha \pmiddf \pmdot \pmsome{\psi} \pmdot \pmpred{\phi}{x} \pmiff_x \pmpred{\psi}{x} \pmand f\{\pmpred{\psi}{\pmhat{z}}\} \pmdf.
\]
It is the peculiarity of a definition of the use of a single letter [viz. $\alpha$] for a variable incomplete symbol that it, though in a sense a real variable, occurs only in the \textit{definiendum}, while ``$\phi$'' though a real variable, occurs only in the \textit{definiens}. 

Thus ``$f\alpha$'' stands for
\[
	\text{``}\pmsome{\psi} \pmdot \pmpred{\pmhat{\phi}}{x} \pmiff_x \pmpred{\psi}{x} \pmand f\{\pmpred{\psi}{\pmhat{z}}\},\text{''}
\]
and ``$\pmall{\alpha} \pmdot f\alpha$'' stands for
\[ 
	\text{``}\pmall{\phi} \pmdott \pmsome{\psi} \pmdot \pmpred{\pmhat{\phi}}{x} \pmiff_x \pmpred{\psi}{x} \pmand f\{\pmpred{\psi}{\pmhat{z}}\}.\text{''}
\]
Accordingly, in mathematical reasoning, we can dismiss the whole apparatus of functions and think only of classes as ``quasi-things,'' capable of immediate representation by a single name. The advantages are two-fold: (1) classes are determined by their membership, so that to one set of members there is one class, (2) the ``type'' of a class is entirely defined by the type of its members. 

Also a predicative function of a class can be defined thus
\[
	\pmpred{f}{\alpha} \pmiddf \pmdot \pmsome{\psi} \pmdot \pmpred{\phi}{x} \pmiff_x \pmpred{\psi}{x} \pmand f\{\pmpred{\psi}{\pmhat{z}}\} \pmdf.
\]
Thus a predicative function of a class is always a predicative function of any 	predicative determining function of the class, though the converse does not hold.

\pagefirst{85} (3) \textit{Relations}. With regard to relations, we have a theory strictly analogous to that which we have just explained as regards classes. Relations in extension, like classes, are incomplete symbols. We require a division of functions of two variables into predicative and non-predicative functions, again for reasons which have been explained in Chapter II. We use the notation ``$\pmpredd{\phi}{x}{y}$'' for a \textit{predicative} function of $x$ and $y$.

We use ``$\pmpredd{\phi}{\pmhat{x}}{\pmhat{y}}$'' for the function as opposed to its values; and we use ``$\pmrel{x}{y}{\pmpredd{\phi}{x}{y}}$'' for the relation (in extension) determined by ``$\phi(x,y)$. We put
\[
	f\{\pmrel{x}{y}{\pmpredd{\phi}{x}{y}}\} \pmdot \pmiddf \pmdott \pmsome{\psi} \pmdott \phi(x,y) \pmdot \pmiff_{x,y} \pmdot \pmpredd{\psi}{x}{y} \pmandd f\{\pmpredd{\psi}{\pmhat{x}}{\pmhat{y}}\} \pmdf.
\]
Thus even when $f\{\pmpredd{\psi}{\pmhat{x}}{\pmhat{y}}\}$ is not an extensional function of $\psi$, $f\{\pmrel{x}{y}{\pmpredd{\phi}{x}{y}}\}$ is an extensional function of $\phi$. Hence, just as in the case of classes, we deduce
\[
	\pmthm \pmdottt \pmrel{x}{y}{\pmpredd{\phi}{x}{y}} = \pmrel{x}{y}{\pmpredd{\psi}{x}{y}} \pmdot \pmiff \pmdott \phi(x,y) \pmdot \pmiff_{x,y} \pmdot \psi(x,y),
\]
\textit{i.e.}\ a relation is determined by its extension, and vice versa.

On the analogy of the definition of ``$x \pmcin \pmpred{\psi}{\pmhat{z}}$,'' we put
\begin{center}
	$\pmrelep{x}{\pmpredd{\psi}{\pmhat{x}}{\pmhat{y}}}{y} \pmdot \pmiddf \pmdot \pmpredd{\psi}{x}{y} \pmdf$\footnote{This definition raises certain questions as to the two senses of a relation, which are dealt with in $\pmast21$.}.
\end{center}
This definition, like that of ``$x \pmcin \pmpred{\psi}{\pmhat{z}}$,'' is not introduced for its own sake, but in order to give a meaning to
\[
	\pmrele{x}{x}{y}{\phi}{y}.
\]
This meaning, in virtue of our definitions, is
\begin{flalign*}
	&& \pmsome{\psi} \pmdott \phi&(x,y) \pmdot \pmiff_{x,y} \pmdot \pmpredd{\psi}{x}{y} \pmandd \pmrelep{x}{\pmpredd{\psi}{\pmhat{x}}{\pmhat{y}}}{y}, & \\
	\textit{i.e.}\ && \pmsome{\psi} &\pmdott \phi(x,y) \pmdot \pmiff_{x,y} \pmdot \pmpredd{\psi}{x}{y} \pmandd \pmpredd{\psi}{x}{y}, &
\end{flalign*}
and this, in virtue of the axiom of reducibility
\begin{flalign*}
	&&\text{``}\pmsome{\psi} \pmdott \phi(x,&y) \pmdot \pmiff_{x,y} \pmdot \pmpredd{\psi}{x}{y},\text{''}&\\
	\text{is equivalent to} && &\phi(x,y). &
\end{flalign*}
Thus we have always
\[
	\pmthm \pmdott \pmrele{x}{x}{y}{\phi}{y} \pmdot \pmiff \pmdot \phi(x,y).
\]

Whenever the determining function of a relation is not relevant, we may replace $\pmrel{x}{y}{\phi(x,y)}$ by a single capital letter. In virtue of the propositions given above,
\begin{flalign*}
	&& &\pmthm \pmdottt R = S \pmdot \pmiff \pmdott xRy \pmdot \pmiff_{x,y} \pmdot xSy, & \\
	&& & \pmthm \pmdottt R = \pmrel{x}{y}{\phi(x,y)} \pmdot \pmiff \pmdott xRy \pmdot \pmiff_{x,y} \pmdot \phi(x,y), & \\
	\text{and} && & \pmthm \pmdottt R = \pmrel{x}{y}{(xRy)}. &
\end{flalign*}

Classes of relations, and relations of relations, can be dealt with as classes of classes were dealt with above.

\pagefirst{86} Just as a class  must not be capable of being or not being a member of itself, so a relation must neither be nor not be referent or relatum with respect to itself. This turns out to be equivalent to the assertion that $\pmpredd{\phi}{\pmhat{x}}{\pmhat{y}}$ cannot significantly be either of the arguments $x$ or $y$ in $\pmpredd{\phi}{x}{y}$. This principle, again, results from the limitation to the possible arguments to a function explained at the beginning of Chapter II.

We may sum up this whole discussion on incomplete symbols as follows.

The use of the symbol ``$\pmdsc{x}(\phi x)$'' as if in ``$f\pmdsc{x}(\phi x)$'' it \textit{directly} represented an argument to the function $\pmpf{f}{\pmhat{z}}$ is rendered possible by the theorems
\begin{flalign*}
	& \hspace{2em} \pmthm \pmdottt \pmexists\pmdsc{x}(\phi x) \pmdot \pmimp \pmdott \pmall{x}\pmdot fx \pmdot \pmimp \pmdot f\pmdsc{x}(\phi x), & \\
	& \hspace{2em} \pmthm \pmdott \pmdsc{x}(\phi x) = \pmdsc{x}(\psi x) \pmdot \pmimp \pmdot f\pmdsc{x}(\phi x) \pmiff f\pmdsc{x}(\psi x), & \\
	& \hspace{2em} \pmthm \pmdott \pmexists\pmdsc{x}(\phi x) \pmdot \pmimp \pmdot \pmdsc{x}(\phi x) = \pmdsc{x}(\phi x), & \\
	& \hspace{2em} \pmthm \pmdott \pmdsc{x}(\phi x) = \pmdsc{x}(\psi x) \pmdot \pmiff \pmdot \pmdsc{x}(\psi x) = \pmdsc{x}(\phi x), & \\
	& \hspace{2em} \pmthm \pmdott \pmdsc{x}(\phi x) = \pmdsc{x}(\psi x) \pmand \pmdsc{x}(\psi x) = \pmdsc{x}(\chi x) \pmdot \pmimp \pmdot \pmdsc{x}(\phi x) = \pmdsc{x}(\chi x). & 
\end{flalign*}

The use of the symbol ``$\pmcls{x}{\phi x}$'' (or of a single letter, such as $\alpha$, to represent such a symbol) as if, in ``$f\{\pmcls{x}{\phi x}\}$'' it \textit{directly} represented an argument $\alpha$ to a function $\pmpf{f}{\pmhat{\alpha}}$, is rendered possible by the theorems
\begin{flalign*}
	&& &\pmthm \pmdott \pmall{\alpha}\pmdot f\alpha \pmdot \pmimp \pmdot f\{\pmcls{x}{\phi x}\}, & \\
	&& &\pmthm \pmdott \pmcls{x}{\phi x} = \pmcls{x}{\psi x} \pmdot \pmimp \pmdot f\{\pmcls{x}{\phi x}\} \pmiff f\{\pmcls{x}{\psi x}\}, & \\
	&& &\pmthm \pmdot \pmcls{x}{\phi x} = \pmcls{x}{\phi x}, & \\
	&& &\pmthm \pmdott \pmcls{x}{\phi x} = \pmcls{x}{\psi x} \pmdot \pmiff \pmdot \pmcls{x}{\psi x} = \pmcls{x}{\phi x}, & \\
	&& &\pmthm \pmdott \pmcls{x}{\phi x} = \pmcls{x}{\psi x} \pmand \pmcls{x}{\psi x} = \pmcls{x}{\chi x} \pmdot \pmimp \pmdot \pmcls{x}{\phi x} = \pmcls{x}{\chi x}. & 
\end{flalign*}

Throughout these propositions the types must be supposed to be properly adjusted, where ambiguity is possible.

The use of the symbol ``$\pmrel{x}{y}{\phi(x,y)}$ (or of a single letter, such as $R$, to represent such a symbol) as if, in $f\{\pmrel{x}{y}{\phi(x,y)}\}$,'' it \textit{directly} represented an argument $R$ to a function $\pmpf{f}{\pmhat{R}}$, is rendered possible by the theorems
\begin{flalign*}
	& \hspace{2em} \pmthm \pmdott \pmall{R}\pmdot fR \pmdot \pmimp \pmdot f\{\pmrel{x}{y}{\phi(x,y)}\}, & \\
	& \hspace{2em} \pmthm \pmdott \pmrel{x}{y}{\phi(x,y)} = \pmrel{x}{y}{\psi(x,y)} \pmdot \pmimp \pmdot f\{\pmrel{x}{y}{\phi(x,y)}\} \pmiff f\{\pmrel{x}{y}{\psi(x,y)}\}, & \\
	& \hspace{2em} \pmthm \pmdot \pmrel{x}{y}{\phi(x,y)} = \pmrel{x}{y}{\phi(x,y)}, & \\
	& \hspace{2em} \pmthm \pmdott \pmrel{x}{y}{\phi(x,y)} = \pmrel{x}{y}{\psi(x,y)} \pmdot \pmiff \pmdot \pmrel{x}{y}{\psi(x,y)} = \pmrel{x}{y}{\phi(x,y)}, & \\
	& \hspace{2em} \pmthm \pmdott \pmrel{x}{y}{\phi(x,y)} = \pmrel{x}{y}{\psi(x,y)} \pmand \pmrel{x}{y}{\psi(x,y)} = \pmrel{x}{y}{\chi(x,y)} \pmdot \pmimp \pmdot \pmrel{x}{y}{\phi(x,y)} = \pmrel{x}{y}{\chi(x,y)}. & 
\end{flalign*}
Throughout these propositions the types must be supposed to be properly adjusted where ambiguity is possible.

\pagefirst{87} It follows from these three groups of theorems that these incomplete symbols are obedient to the same formal rules of identity as symbols which directly represent objects, so long as we only consider the \textit{equivalence} of the resulting variable (or constant) values of propositional functions and not their identity. This consideration of the \textit{identity} of propositions never enters into our formal reasoning.

Similarly the \textit{limitations} to the use of these symbols can be summed up as follows. In the. case of $\pmdsc{x}(\phi x)$, the chief way in which its incompleteness is relevant is that we do not always have
\[
	\pmall{x}\pmdot fx \pmdot \pmimp \pmdot f\pmdsc{x}(\phi x),
\]
\textit{i.e.}\ a function which is always true may nevertheless not be true of $\pmdsc{x}(\phi x)$. This is possible because $\pmdsc{x}(\phi x)$ is not a value of $\pmpf{f}{\pmhat{x}}$, so that even when all values of $\pmpf{f}{\pmhat{x}}$ are true, $f\pmdsc{x}(\phi x)$ may not be true. This happens when $\pmdsc{x}(\phi x)$ does not exist. Thus for example we have $\pmall{x}\pmdot x=x$, but we do not have
\begin{flalign*}
	&& \text{the round square} & = \text{ the round square.} & && \\
	\text{The inference} && \pmall{x}\pmdot fx \pmdot \pmimp & \pmdot f\pmdsc{x}(\phi x) & &&
\end{flalign*}
is only valid when $\pmexists\pmdsc{x}(\phi x)$. As soon as we know $\pmexists\pmdsc{x}(\phi x)$, the fact that $\pmdsc{x}(\phi x)$ is an incomplete symbol becomes irrelevant so long as we confine ourselves to truth-functions\footnote{Cf. p. 8.} of whatever proposition is its scope. But even when $\pmexists\pmdsc{x}(\phi x)$, the incompleteness of $\pmdsc{x}(\phi x)$ may be relevant when we pass outside truth-functions. For example, George IV wished to know whether Scott was the author of Waverley, \textit{i.e.}\ he wished to know whether a proposition of the form ``$c=\pmdsc{x}(\phi x)$'' was true. But there was no proposition of the form ``$c=y$'' concerning which he wished to know if it was true.

In regard to classes, the relevance of their incompleteness is somewhat different. It may be illustrated by the fact that we may have 
\begin{flalign*}
	&&  \pmcls{z}{\phi z} = &\pmpred{\psi}{\pmhat{z}} \pmand \pmcls{z}{\phi z} = \pmpred{\chi}{\pmhat{z}} & &&\\
	\text{without having} && & \pmpred{\psi}{\pmhat{z}} = \pmpred{\chi}{\pmhat{z}}. & &&
\end{flalign*}
For, by a direct application of the definitions, we find that
\[
	\pmthm \pmdott \pmcls{z}{\phi z} = \pmpred{\psi}{\pmhat{z}} \pmdot \pmiff \pmdot \phi x \pmiff_x \pmpred{\psi}{x}.
\]
Thus we shall have
\[
	\pmthm \pmdott \phi x \pmiff_x \pmpred{\psi}{x} \pmand \phi x \pmiff_x \pmpred{\chi}{x} \pmdot \pmimp \pmdot \pmcls{z}{\phi z} = \pmpred{\psi}{\pmhat{z}} \pmand \pmcls{z}{\phi z} = \pmpred{\chi}{\pmhat{z}},
\]
but we shall not necessarily have $\pmpred{\psi}{\pmhat{z}} = \pmpred{\chi}{\pmhat{z}}$ under these circumstances, for two functions may well be formally equivalent without being identical; for example,
\[
	x = \text{Scott} \pmdot \pmiff_x \pmdot x = \text{the author of Waverley,}
\]
\pagefirst{88} but the function ``$\pmpf{\pmhat{z}}{\text{the author of Waverley}}$ has the property that George IV wished to know whether its value with the argument ``Scott'' was true, whereas the function ``$\pmpf{\pmhat{z}}{\text{Scott}}$'' has no such property, and therefore the two functions are not identical. Hence there is a propositional function, namely
\[
	x = y \pmand x = z \pmdot \pmimp \pmdot x = z,
\]
which holds without any exception, and yet does not hold when for $x$ we substitute a class, and for $y$ and $z$ we substitute functions. This is only possible because a class is an incomplete symbol, and therefore ``$\pmcls{z}{\phi z} = \pmpred{\psi}{\pmhat{z}}$'' is not a value of ``$x=y$.''

It will be observed that ``$\pmpred{\theta}{\pmhat{z}} = \pmpred{\psi}{\pmhat{z}}$'' is not an extensional function of $\pmpred{\psi}{\pmhat{z}}$. Thus the scope of $\pmcls{z}{\phi z}$ is relevant in interpreting the product
\[
	\pmcls{z}{\phi z} = \pmpred{\psi}{\pmhat{z}} \pmand \pmcls{z}{\phi z} = \pmpred{\chi}{\pmhat{z}}.
\]
If we take the whole of the product as the scope of $\pmcls{z}{\phi z}$, the product is equivalent to
\begin{flalign*}
	&& \pmsome{\theta} \pmdott \phi x \pmiff_x \pmpred{\theta}{x}& \pmand \pmpred{\theta}{\pmhat{z}} = \pmpred{\psi}{\pmhat{z}} \pmand \pmpred{\theta}{\pmhat{z}} = \pmpred{\chi}{\pmhat{z}} & && && && \\
	\text{and this \textit{does} imply} && &\pmpred{\psi}{\pmhat{z}} = \pmpred{\chi}{\pmhat{z}}. & && && &&
\end{flalign*}

We may say generally that the fact that $\pmcls{z}{\phi z}$ is an incomplete symbol is not relevant so long as we confine ourselves to extensional functions of functions, but is apt to become relevant for other functions of functions.

\part{MATHEMATICAL LOGIC} %\pagefirst{89} %Followed by a blank page \pagefirst{90}
\begin{center} \textbf{SUMMARY OF PART I.} \end{center}\pagefirst{91} 

IN this Part, we shall deal with such topics as belong traditionally to symbolic logic, or deserve to belong to it in virtue of their generality. We shall, that is to say, establish such properties of propositions, propositional functions, classes and relations as are likely to be required in any mathematical reasoning, and not merely in this or that branch of mathematics.

The subjects treated in Part I may be viewed in two aspects: (1) as a deductive chain depending on the primitive propositions, (2) as a formal calculus. Taking the first view first: We begin, in $\pmast1$, with certain axioms as to deduction of one proposition or asserted propositional function from another. From these primitive propositions, in Section A, we deduce various propositions which are all concerned with four ways of obtaining new propositions from given propositions, namely negation, disjunction, joint assertion and implication, of which the last two can be defined in terms of the first two. Throughout this first section, although, as will be shown at the beginning of Section B, our propositions, symbolically unchanged, will apply to any propositions as values of our variables, yet it will be supposed that our variable propositions are all what we shall call \textit{elementary} propositions, \textit{i.e.}\ such as contain no reference, explicit or implicit, to any totality. This restriction is imposed on account of the distinction between different \textit{types} of propositions, explained in Chapter II of the Introduction. Its importance and purpose, however, are purely philosophical, and so long as only mathematical purposes are considered, it is unnecessary to remember this preliminary restriction to elementary propositions, which is symbolically removed at the beginning of the next section. 

Section B deals, to begin with, with the relations of propositions containing apparent variables (\textit{i.e.}\ involving the notions of ``all'' or ``some'') to each other and to propositions not containing apparent variables. We show that, where propositions containing apparent variables are concerned, we can define negation, disjunction, joint assertion and implication in such a way that their properties shall be exactly analogous to the properties of the corresponding ideas as applied to elementary propositions. We show also that formal implication, \textit{i.e.}\ ``$\pmall{x}\pmdot \phi x \pmimp \psi x$'' \pagefirst{92} considered as a relation of $\pmpf{\phi}{x}$ to $\pmpf{\psi}{x}$, has many properties analogous to those of \textit{material implication}, \textit{i.e.}\ ``$p \pmimp q$'' considered as a relation of $p$ and $q$. We then consider \textit{predicative} functions and the \textit{axiom of reducibility}, which are vital in the employment of \textit{functions} as apparent variables. An example of such employment is afforded by identity, which is the next topic considered in Section B. Finally, this section deals with \textit{descriptions}, \textit{i.e.}\ phrases of the form ``the so-and-so'' (in the singular). It is shown that the appearance of a grammatical subject ``the so-and-so'' is deceptive, and that such propositions, fully stated, contain no such subject, but contain instead an apparent variable. 

Section C deals with classes, and with relations in so far as they are analogous to classes. Classes and relations, like descriptions, are shown to be ``incomplete symbols'' (cf. Introduction, Chapter III), and it is shown that a proposition which is grammatically about a class is to be regarded as really concerned with a propositional function and an apparent variable whose values are predicative propositional functions (with a similar result for relations). The remainder of Section C deals with the calculus of classes, and with the calculus of relations in so far as it is analogous to that of classes.

Section D deals with those properties of relations which have no analogues for classes. In this section, a number of ideas and notations are introduced which are constantly needed throughout the rest of the work. Most of the properties of relations which have analogues in the theory of classes are comparatively unimportant, while those that have no such analogues are of the very greatest utility. Tt is partly for this reason that emphasis on the calculus-aspect of symbolic logic has proved a hindrance, hitherto, to the proper development of the theory of relations. 

Section E, finally, extends the notions of the addition and multiplication of classes or relations to cases where the summands or factors are not individually given, but are given as the members of some class. The advantage obtained by this extension is that it enables us to deal with an infinite number of summands or factors.

Considered as a formal calculus, mathematical logic has three analogous branches, namely (1) the calculus of propositions, (2) the calculus of classes, (3) the calculus of relations. Of these, (1) is dealt with in Section A, while (2) and (3), in so far as they are analogous, are dealt with in Section C. We have, for each of the three, the four analogous ideas of negation, addition, multiplication, and implication or inclusion. Of these, negation is analogous to the negative in ordinary algebra, and implication or inclusion is analogous to the relation ``less than or equal to'' in ordinary algebra. But the analogy must not be pressed, as it has important limitations. The sum of two propositions is their disjunction, the sum of two classes is the class of terms belonging to one or other, the sum of two relations is the relation consisting in the fact that one or other of the two relations holds. The sum of a class \pagefirst{93} of classes is the class of all terms belonging to some one or other of the classes, and the sum of a class of relations is the relation consisting in the fact that some one relation of the class holds. The product of two propositions is their joint assertion, the product of two classes is their common part, the product of two relations is the relation consisting in the fact that both the relations hold. The product of a class of classes is the part common to all of them, and the product of a class of relations is the relation consisting in the fact that all relations of the class in question bold. The inclusion of one class in another consists in the fact that all members of the one are members of the other, while the inclusion of one relation in another consists in the fact that every pair of terms which has the one relation also has the other relation. It is then shown that the properties of negation, addition, multiplication and inclusion are exactly analogous for classes and relations, and are, with certain exceptions, analogous to the properties of negation, addition, multiplication and implication for propositions. (The exceptions arise chiefly from the fact that ``$p$ implies $q$'' is itself a proposition, and can therefore imply and be implied, while ``$\alpha$ is contained in $\beta$,'' where $\alpha$ and $\beta$ are classes, is not a class, and can therefore neither contain nor be contained in another class $\gamma$.) But classes have certain properties not possessed by propositions: these arise from the fact that classes have not a \textit{two-fold} division corresponding to the division of propositions into true and false, but a \textit{three-fold} division, namely into (1) the universal class, which contains the whole of a certain type, (2) the null-class, which has no members, (3) all other classes, which neither contain nothing nor contain everything of the appropriate type. The resulting properties of classes, which are not analogous to properties of propositions, are dealt with in $\pmast24$. And just as classes have properties not analogous to any properties of propositions, so relations have properties not analogous to any properties of classes, though all the properties of classes have analogues among relations. The special properties of relations are much more numerous and important than the properties belonging to classes but not to propositions. These special properties of relations therefore occupy a whole section, namely Section D.

\chapter*{\centering SECTION A. \\ THE THEORY OF DEDUCTION.} \pagefirst{94} 

THE purpose of the present section is to set forth the first stage of the deduction of pure mathematics from its logical foundations. This first stage is necessarily concerned with deduction itself, \textit{i.e.}\ with the principles by which conclusions are inferred from premisses. If it is our purpose to make all our assumptions explicit, and to effect the deduction of all our other propositions from these assumptions, it is obvious that the first assumptions we need are those that are required to make deduction possible. Symbolic logic is often regarded as consisting of two coordinate parts, the theory of classes and the theory of propositions. But from our point of view these two parts are not coordinate; for in the theory of classes we deduce one proposition from .another by means of principles belonging to the theory of propositions, whereas in the theory of propositions we nowhere require the theory of classes. Hence, in a deductive system, the theory of propositions necessarily precedes the theory of classes.

But the subject to be treated in what follows is not quite properly described as the theory of \textit{propositions}. It is in fact the theory of how one proposition can be inferred from another. Now in order that one proposition may be inferred from another, it is necessary that the two should have that relation which makes the one a consequence of the other. When a proposition $q$ is a consequence of a proposition $p$, we say that $p$ \textit{implies} $q$. Thus deduction depends upon the relation of \textit{implication}, and every deductive system must contain among its premisses as many of the properties of implication as are necessary to legitimate the ordinary procedure of deduction. In the present section, certain propositions will be stated as premisses, and it will be shown that they are sufficient for all common forms of inference. It will not be shown that they are all \textit{necessary}, and it is possible that the number of them might be diminished. All that is affirmed concerning the premisses is (1) that they are true, (2) that they are sufficient for the theory of deduction, (3) that we do not know how to diminish their number. But with regard to (2), there must always be some element of doubt, since it is hard to be sure that one never uses some principle unconsciously. The habit of being rigidly guided by formal symbolic rules is a safeguard against unconscious assumptions; but even this safeguard is not always adequate.

\chapter*{\centering \pmast1. PRIMITIVE IDEAS AND PROPOSITIONS.} \addcontentsline{toc}{chapter}{❋1. PRIMITIVE IDEAS AND PROPOSITIONS.} \pagefirst{95} 

Since all definitions of terms are effected by means of other terms, every system of definitions which is not circular must start from a certain apparatus of undefined terms. It is to some extent optional what ideas we take as undefined in mathematics; the motives guiding our choice will be (1) to make the number of undefined ideas as small as possible, (2) as between two systems in which the number is equal, to choose the one which seems the simpler and easier. We know no way of proving that such and such a system of undefined ideas contains as few as will give such and such results\footnote{The recognized methods of proving independence are not applicable, without reserve, to fundamentals. Cf. \textit{Principles of Mathematics}, \S17. What is there said concerning primitive propositions applies with even greater force to primitive ideas.}. Hence we can only say that such and such ideas are undefined in such and such a system, not that they are indefinable. Following Peano, we shall call the undefined ideas and the undemonstrated propositions \textit{primitive} ideas and \textit{primitive} propositions respectively. The primitive ideas are \textit{explained} by means of descriptions intended to point out to the reader what is meant; but the explanations do not constitute definitions, because they really involve the ideas they explain.

In the present number, we shall first enumerate the primitive ideas required in this section; then we shall define \textit{implication}; and then we shall enunciate the primitive propositions required in this section. Every definition or proposition in the work has a number, for purposes of reference. Following Peano, we use numbers having a decimal as well as an integral part, in order to be able to insert new propositions between any two. A change in the integral part of the number will be used to correspond to a new chapter. Definitions will generally have numbers whose decimal part is less than 1, and will be usually put at the beginning of chapters. In references, the integral parts of the numbers of propositions will be distinguished by being preceded by a star; thus ``$\pmast1\pmcdot01$'' will mean the definition or proposition so numbered, and ``$\pmast1$'' will mean the chapter in which propositions have numbers whose integral part is 1, \textit{i.e.}\ the present chapter. Chapters will generally be called ``numbers.''

\section*{\centering PRIMITIVE IDEAS.}

(1) \textit{Elementary propositions}. By an ``elementary'' proposition we mean one which does not involve any variables, or, in other language, one which does not involve such words as ``all,'' ``some,'' ``the'' or equivalents for such words. A proposition such as ``this is red,'' where ``this'' is something given \pagefirst{96} in sensation, will be elementary. Any combination of given elementary propositions by means of negation, disjunction or conjunction (see below) will be elementary. In the primitive propositions of the present number, and therefore in the deductions from these primitive propositions in $\pmast2-\pmast5$, the letters $p, q, r, s$ will be used to denote elementary propositions.

(2) \textit{Elementary propositional functions}. By an ``elementary propositional function'' we shall mean an expression containing an undetermined constituent, \textit{i.e.}\ a variable, or several such constituents, and such that, when the undetermined constituent or constituents are determined, \textit{i.e.}\ when values are assigned to the variable or variables, the resulting value of the expression in question is an elementary proposition. Thus if $p$ is an undetermined elementary proposition, ``not-$p$'' is an elementary propositional function.

We shall show in $\pmast9$ how to extend the results of this and the following numbers ($\pmast1$-$\pmast5$) to propositions which are not elementary.

(3) \textit{Assertion}. Any proposition may be either asserted or merely considered. If I say ``Caesar died,'' I assert the proposition ``Caesar died,'' if I say ```Caesar died' is a proposition,'' I make a different assertion, and ``Caesar died'' is no longer asserted, but merely considered. Similarly in a hypothetical proposition, \textit{e.g.}\ ``if $a=b$, then $b=a$,'' we have two unasserted propositions, namely ``$a=b$'' and ``$b=a$,'' while what is asserted is that the first of these implies the second. In language, we indicate when a proposition is merely considered by ``if so-and-so'' or ``that so-and-so'' or merely by inverted commas. In symbols, if $p$ is a proposition, $p$ by itself will stand for the unasserted proposition, while the asserted proposition will be designated by
\[
	\text{``}\pmthm\pmdot p\text{.''}
\]
The sign ``$\pmthm$'' is called the assertion-sign\footnote{We have adopted both the idea and the symbol of assertion from Frege.}; it may be read ``it is true that'' (although philosophically this is not exactly what it means). The dots after the assertion-sign indicate its range; that is to say, everything following is asserted until we reach either an equal number of dots preceding a sign of implication or the end of the sentence. Thus ``$\pmthm \pmdott p \pmdot \pmimp \pmdot q$'' means ``it is true that $p$ implies $q$,'' whereas ``$\pmthm \pmdot p \pmdot \pmimp \pmdot \pmthm \pmdot q$'' means ``$p$ is true; therefore $q$ is true\footnote{Cf. \textit{Principles of Mathematics}, \S38}.'' The first of these does not necessarily involve the truth either of $p$ or of $q$, while the second involves the truth of both.

(4) \textit{Assertion of a propositional function}. Besides the assertion of definite propositions, we need what we shall call ``assertion of a propositional function.'' The general notion of asserting \textit{any} propositional function is not used until $\pmast9$, but we use at once the notion of asserting various special \textit{elementary} propositional functions. Let $\phi x$ be a propositional function whose argument is $x$; then we may assert $\phi x$ without assigning a value to $x$. \pagefirst{97} This is done, for example, when the law of identity is asserted in the form ``$A$ is $A$.'' Here $A$ is left undetermined, because, however $A$ may be determined, the result will be true. Thus when we assert $\phi x$, leaving $x$ undetermined, we are asserting an ambiguous value of our function. This is only legitimate if, however the ambiguity may be determined, the result will be true. Thus take, as an illustration, the primitive proposition $\pmast1\pmcdot2$ below, namely
\[
	\text{``} \pmthm \pmdott p \pmor p \pmdot \pmimp \pmdot p\text{,''}
\]
\textit{i.e.}\ ```$p$ or $p$' implies $p$.'' Here $p$ may be \textit{any} elementary proposition: by leaving $p$ undetermined, we obtain an assertion which can be applied to any particular elementary proposition. Such assertions are like the particular enunciations in Euclid: when it is said ``let $ABC$ be an isosceles triangle; then the angles at the base will be equal,'' what is said applies to any isosceles triangle; it is stated concerning \textit{one} triangle, but not concerning a definite one. All the assertions in the present work, with a very few exceptions, assert propositional functions, not definite propositions.

As a matter of fact, no constant elementary proposition will occur in the present work, or can occur in any work which employs only logical ideas. The ideas and propositions of logic are all \textit{general}: an assertion (for example) which is true of Socrates but not of Plato, will not belong to logic\footnote{When we say that a proposition ``belongs to logic,'' we mean that it can be expressed in terms of the primitive ideas of logic. We do not mean that logic \textit{applies} to it, for that would of course be true of any proposition.}, and if an assertion which is true of both is to occur in logic, it must not be made concerning either, but concerning a variable $x$. In order to obtain, in logic, a definite proposition instead of a propositional function, it is necessary to take some propositional function and assert that it is true always or sometimes, \textit{i.e.}\ with all possible values of the variable or with some possible value. Thus, giving the name ``individual'' to whatever there is that is neither a proposition nor a function, the proposition ``every individual is identical with itself'' or the proposition ``there are individuals'' will be a proposition belonging to logic. But these propositions are not elementary.

(5) \textit{Negation}. If $p$ is any proposition, the proposition ``not-$p$,'' or ``$p$ is false,'' will be represented by ``$\pmnot p$.'' For the present, $p$ must be an \textit{elementary} proposition.

(6) \textit{Disjunction}. If $p$ and $q$ are any propositions, the proposition ``$p$ or $q$,'' \textit{i.e.}\ ``either $p$ is true or $q$ is true,'' where the alternatives are to be not mutually exclusive, will be represented by
\[
	\text{``}p \pmor q\text{.''}
\]
This is called the \textit{disjunction} or the \textit{logical sum} of $p$ and $q$. Thus ``$\pmnot p \pmor q$'' will mean ``$p$ is false or $q$ is true''; $\pmnot(p \pmor q)$ will mean ``it is false that either $p$ or $q$ is true,'' which is equivalent to ``$p$ and $q$ are both false''; \pagefirst{98} $\pmnot(\pmnot p \pmor \pmnot q)$ will mean ``it is false that either $p$ is false or $q$ is false,'' which is equivalent to ``$p$ and $q$ are both true''; and so on. For the present, $p$ and $q$ must be elementary propositions.

The above are all the primitive ideas required in the theory of deduction. Other primitive ideas will be introduced in Section B.

\textit{Definition of Implication}. When a proposition $q$ follows from a proposition $p$, so that if $p$ is true, $q$ must also be true, we say that $p$ \textit{implies} $q$. The idea of implication, in the form in which we require it, can be defined. The meaning to be given to implication in what follows may at first sight appear somewhat artificial; but although there are other legitimate meanings, the one here adopted is very much more convenient for our purposes than any of its rivals. The essential property that we require of implication is this: ``What is implied by a true proposition is true.'' It is in virtue of this property that implication yields proofs. But this property by no means determines whether anything, and if so what, is implied by a false proposition. What it does determine is that, if $p$ implies $q$, then it cannot be the case that $p$ is true and $q$ is false, \textit{i.e.}\ it must be the case that either $p$ is false or $q$ is true. The most convenient interpretation of implication is to say, conversely, that if either $p$ is false or $q$ is true, then ``$p$ implies $q$'' is to be true. Hence ``$p$ implies $q$'' is to be defined to mean: ``Either $p$ is false or $q$ is true.'' Hence we put:
\[
	\pmast1\pmcdot01\text{.} p \pmimp q \pmdot \pmiddf \pmdot \pmnot p \pmor q \pmdf.
\]

Here the letters ``Df'' stand for ``definition.'' They and the sign of equality together are to be regarded as forming one symbol, standing for ``is defined to mean\footnote{The sign of equality not followed by the letters ``Df'' will have a different meaning, to be defined later.}.'' Whatever comes to the left of the sign of equality is defined to mean the same as what comes to the right of it. Definition is not among the primitive ideas, because definitions are concerned solely with the symbolism, not with what is symbolised; they are introduced for practical convenience, and are theoretically unnecessary.

In virtue of the above definition, when ``$p \pmimp q$'' holds, then either $p$ is false or $q$ is true; hence if $p$ is true, $q$ must be true. Thus the above definition preserves the essential characteristic of implication; it gives, in fact, the most general meaning compatible with the preservation of this characteristic.

\section*{\centering PRIMITIVE PROPOSITIONS.}

$\pmast1\pmcdot1$. Anything implied by a true elementary proposition is true. $\pmpp$\footnote{The letters ``$\pmpp$'' stand for ``primitive proposition.''}.

The above principle will be extended in $\pmast9$ to propositions which are not elementary. It is not the same as ``\textit{if} $p$ is true, then \textit{if} $p$ implies $q$, $q$ is \pagefirst{99} true.'' This is a true proposition, but it holds equally when $p$ is not true and when $p$ does not imply $q$. It does not, like the principle we are concerned with, enable us to assert $q$ simply, without any hypothesis. We cannot express the principle symbolically, partly because any symbolism in which $p$ is variable only gives the \textit{hypothesis} that $p$ is true, not the fact that it is true\footnote{For further remarks on this principle, cf. \textit{Principles of Mathematics}, \S38}.

The above principle is used whenever we have to deduce a \textit{proposition} from a \textit{proposition}. But the immense majority of the assertions in the present work are assertions of propositional functions, \textit{i.e.}\ they contain an undetermined variable. Since the assertion of a propositional function is a different primitive idea from the assertion of a proposition, we require a primitive proposition different from $\pmast1\pmcdot1$, though allied to it, to enable us to deduce the assertion of a propositional function ``$\psi x$'' from the assertions of the two propositional functions ``$\phi x$ and ``$\phi x \pmimp \psi x$.'' This primitive proposition is as follows:
\\ $\pmast1\pmcdot11$. When $\phi x$ can be asserted, where $x$ is a real variable, and $\phi x \pmimp \psi x$ can be asserted, where $x$ is a real variable, then $\psi x$ can be asserted, where $x$ is a real variable. $\pmpp$

This principle is also to be assumed for functions of several variables.

Part of the importance of the above primitive proposition is due to the fact that it expresses in the symbolism a result following from the theory of types, which requires symbolic recognition. Suppose we have the two assertions of \textit{propositional functions} ``$\pmthm \pmdot \phi x$'' and ``$\pmthm \pmdot \phi x \pmimp \psi x$''; then the ``$x$'' in $\phi x$ is not absolutely anything, but anything for which as argument the function ``$\phi x$'' is significant; similarly in ``$\phi x \pmimp \psi x$'' the $x$ is anything for which ``$\phi x \pmimp \psi x$'' is significant. Apart from some axiom, we do not know that the $x$'s for which ``$\phi x \pmimp \psi x$'' is significant are the same as those for which ``$\phi x$'' is significant. The \pagefirst{100} primitive proposition $\pmast1\pmcdot11$, by securing that, as the result of the assertions of the \textit{propositional functions} ``$\phi x$'' and ``$\phi x \pmimp \psi x$,'' the propositional function ``$\psi x$ can also be asserted, secures partial symbolic recognition, in the form most useful in actual deductions, of an important principle which follows from the theory of types, namely that, if there is any one argument $a$ for which both ``$\phi a$'' and ``$\psi a$'' are significant, then the range of arguments for which ``$\phi x$'' is significant is the same as the range of arguments for which ``$\psi x$'' is significant. It is obvious that, if the propositional function ``$\phi x \pmimp \psi x$'' can be asserted, there must be arguments $a$ for which ``$\phi a \pmimp \psi a$'' is significant, and for which, therefore, ``$\phi a$'' and ''``$\psi a$'' must be significant. Hence, by our principle, the values of $x$ for which ``$\phi x$'' is significant are the same as those for which ``$\psi x$'' is significant, \textit{i.e.}\ the type of possible arguments for $\pmpf{\phi}{\pmhat{x}}$ (cf. p. 15) is the same as that of possible arguments for $\pmpf{\psi}{\pmhat{x}}$. The primitive proposition $\pmast1\pmcdot11$, since it states a practically important consequence of this fact, is called the ``axiom of identification of type.''

Another consequence of the principle that, if there is an argument $a$ for which both $\phi a$ and $\psi a$ are significant, then $\phi x$ is significant whenever $\psi x$ is significant, and vice versa, will be given in the ``axiom of identification of real variables,'' introduced in $\pmast1\pmcdot72$. These two propositions, $\pmast1\pmcdot11$ and $\pmast1\pmcdot72$, give what is symbolically essential to the conduct of demonstrations in accordance with the theory of types.

The above proposition $\pmast1\pmcdot11$ is used in every inference from one asserted propositional function to another. We will illustrate the use of this proposition by setting forth at length the way in which it is first used, in the proof of $\pmast2\pmcdot06$. That proposition is

\[
	\text{``}\pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r\text{.''}
\]
We have already proved, in $\pmast2\pmcdot05$, the proposition
\[
	\pmthm \pmdottt q \pmimp r \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r\text{.}
\]
It is obvious that $\pmast2\pmcdot06$ results from $\pmast2\pmcdot05$ by means of $\pmast2\pmcdot04$, which is
\[
	\pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott q \pmdot \pmimp \pmdot p \pmimp r\text{.}
\]
For if, in this proposition, we replace $p$ by $q \pmimp r$, $q$ by $p \pmimp q$, and $r$ by $p \pmimp r$, we obtain, as an instance of $\pmast2\pmcdot04$, the proposition
\begin{flalign*}
	& \hspace{2em} \pmthm \pmdotttt q \pmimp r \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r \pmdottt \pmimp \pmdottt p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r && & (1), 
\end{flalign*}
and here the hypothesis is asserted by $\pmast2\pmcdot05$. Thus our primitive proposition $\pmast1\pmcdot11$ enables us to assert the conclusion.
\begin{flalign*}
\pagefirst{101} 	\pmast1\pmcdot2\text{. } \pmthm \pmdott p \pmor p \pmdot \pmimp \pmdot p \pmpp. &&
\end{flalign*}

This proposition states: ``If either $p$ is true or $p$ is true, then $p$ is true.'' It is called the ``principle of tautology,'' and will be quoted by the abbreviated title of  ``Taut.'' It is convenient, for purposes of reference, to give names to a few of the more important propositions; in general, propositions will be referred to by their numbers.
\begin{flalign*}
	\pmast1\pmcdot3\text{. } \pmthm \pmdott q  \pmdot \pmimp \pmdot p \pmor q \pmpp. &&
\end{flalign*}

This principle states: ``If $q$ is true, then `$p$ or $q$' is true.'' Thus \textit{e.g.}\ if $q$ is ``to-day is Wednesday'' and $p$ is ``to-day is Tuesday,'' the principle states: ``If to-day is Wednesday, then to-day is either Tuesday or Wednesday.'' It is called the ``principle of addition,'' because it states that if a proposition is true, any alternative may be added without making it false. The principle will be referred to as ``Add.''
\begin{flalign*}
	\pmast1\pmcdot4\text{. } \pmthm \pmdott p \pmor q  \pmdot \pmimp \pmdot q \pmor p \pmpp. &&
\end{flalign*}

This principle states that ``$p$ or $q$'' implies ``$q$ or $p$.'' It states the permutative law for logical addition of propositions, and will be called the ``principle of permutation.'' It will be referred to as ``Perm.''
\begin{flalign*}
	\pmast1\pmcdot5\text{. } \pmthm \pmdott p \pmor (q \pmor r) \pmdot \pmimp \pmdot q \pmor (p \pmor r) \pmpp. &&
\end{flalign*}

This principle states: ``If either $p$ is true, or `$q$ or $r$' is true, then either $q$ is true, or `$p$ or $r$' is true.'' It is a form of the associative law for logical addition, and will be called the ``associative principle.'' It will be referred to as ``Assoc.'' The proposition
\[ 
	p \pmor (q \pmor r) \pmdot \pmimp \pmdot (p \pmor q) \pmor r,
\]
which would be the natural form for the associative law, has less deductive power, and is therefore not taken as a primitive proposition.
\begin{flalign*}
	\pmast1\pmcdot6\text{. } \pmthm \pmdottt q \pmimp r \pmdot \pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot p \pmor r \pmpp. &&
\end{flalign*}

This principle states: ``If $q$ implies $r$, then `$p$ or $q$' implies `$p$ or $r$.''' In other words, in an implication, an alternative may be added to both premiss and conclusion without, impairing the truth of the implication. The principle will be called the ``principle of summation,'' and will be referred to as ``Sum.'' 
\begin{description}
	\item[$\pmast1\pmcdot7.$] If $p$ is an elementary proposition, $\pmnot p$ is an elementary proposition. $\pmpp$. 
	\item[$\pmast1\pmcdot71.$] If $p$ and $q$ are elementary propositions, $p \pmor q$ is an elementary proposition. $\pmpp$. 
	\item[$\pmast1\pmcdot72.$] If $\phi p$ and $\psi p$ are elementary propositional functions which take elementary propositions as arguments, $\phi p \pmor \psi p$ is an elementary propositional function. $\pmpp$.
\end{description} 

This axiom is to apply also to functions of two or more variables. It is called the ``axiom of identification of real variables.'' It will be observed that if $\phi$ and $\psi$ are functions which take arguments of different types, there is no such function as ``$\phi x \pmor \psi x$,'' because $\phi$ and $\psi$ cannot significantly have the same argument. A more general form of the above axiom will be given in $\pmast9$.

The use of the above axioms $\pmast1\pmcdot7\pmcdot71\pmcdot72$ will generally be tacit. It is only through them and the axioms of $\pmast9$ that the theory of types explained in the Introduction becomes relevant, and any view of logic which justifies these axioms justifies such subsequent reasoning as employs the theory of types.

This completes the list of primitive propositions required for the theory of deduction as applied to elementary propositions.

\chapter*{\centering \pmast2. IMMEDIATE CONSEQUENCES OF THE PRIMITIVE PROPOSITIONS.} \addcontentsline{toc}{chapter}{❋2. IMMEDIATE CONSEQUENCES OF THE PRIMITIVE PROPOSITIONS.} \pagefirst{102} \noindent
\indent \textit{Summary of $\pmast$2.}

The proofs of the earlier of the propositions of this number consist simply in noticing that they are instances of the general rules given in $\pmast$1. In such cases, these rules are not premisses, since they assert any instance of themselves, not something other than their instances. Hence when a general rule is adduced in early proofs, it will be adduced in brackets\footnote{Later on we shall cease to mark the distinction between a premiss and a rule according to which an inference is conducted. It is only in early proofs that this distinction is important.}, with indications, when required, as to the changes of letters from those given in the rule to those in the case considered. Thus ``$\text{Taut}\frac{\pmnot p}{p}$'' will mean what ``Taut'' becomes when $\pmnot p$ is written in place of $p$. If ``$\text{Taut}\frac{\pmnot p}{p}$'' is enclosed in square brackets before an asserted proposition, that means that, in accordance with ``Taut," we are asserting what ``Taut" becomes when $\pmnot p$ is written in place of $p$. The recognition that a certain proposition is an instance of some general proposition previously proved or assumed is essential to the process of deduction from general rules, but cannot itself be erected into a general rule, since the application required is particular, and no general rule can \textit{explicitly} include a particular application.

Again, when two different sets of symbols express the same proposition in virtue of a definition, say $\pmast1\pmcdot01$, and one of these, which we will call (1), has been asserted, the assertion of the other is made by writing ``$[(1)\pmdot(\pmast1\pmcdot01)]$" before it, meaning that, in virtue of $\pmast1\pmcdot01$, the new set of symbols asserts the same proposition as was asserted in $(1)$. A reference to a definition is distinguished from a reference to a previous proposition by being enclosed in round brackets.

The propositions in this number are all, or nearly all, actually needed in deducing mathematics from our primitive propositions. Although certain abbreviating processes will be gradually introduced, proofs will be given very fully, because the importance of the present subject lies, not in the propositions themselves, but (1) in the fact that they follow from the primitive propositions, (2) in the fact that the subject is the easiest, simplest, and most elementary example of the symbolic method of dealing with the principles of mathematics generally. Later portions---the theories of classes, relations, cardinal numbers, series, ordinal numbers, geometry, etc.---all employ the same method, but with an increasing complexity in the entities and functions considered.

\pagefirst{103} The most important propositions proved in the present number are the following:
\begin{flalign*}
	& \mathbf{\pmast2\pmcdot02}. \quad \pmthm \pmdott q \pmdot \pmimp \pmdot p \pmimp q &
\end{flalign*}

\textit{I.e.}\ $q$ implies that $p$ implies $q$, \textit{i.e.}\ a true proposition is implied by any proposition. This proposition is called the ``principle of simplification'' (referred to as ``Simp''), because, as will appear later, it enables us to pass from the joint assertion of $q$ and $p$ to the assertion of q simply. When the special meaning which we have given to implication is remembered, it will be seen that this proposition is obvious.
\begin{flalign*}
	& \mathbf{\pmast2\pmcdot03}. \quad \pmthm \pmdott p \pmimp \pmnot q \pmdot \pmimp \pmdot q \pmimp \pmnot p & \\
	& \mathbf{\pmast2\pmcdot15}. \quad \pmthm \pmdott \pmnot p\pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp p & \\
	& \mathbf{\pmast2\pmcdot16}. \quad \pmthm \pmdott p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot p & \\
	& \mathbf{\pmast2\pmcdot17}. \quad \pmthm \pmdott \pmnot q \pmimp \pmnot p \pmdot \pmimp \pmdot p \pmimp q & 
\end{flalign*}

These four analogous propositions constitute the ``principle of transposition,'' referred to as ``Transp.'' They lead to the rule that in an implication the two sides may be interchanged by turning negative into positive and positive into negative. They are thus analogous to the algebraical rule that the two sides of an equation may be interchanged by changing the signs.
\begin{flalign*}
	& \mathbf{\pmast2\pmcdot04}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott q \pmdot \pmimp \pmdot p \pmimp r &
\end{flalign*}

This is called the ``commutative principle'' and referred to as ``Comm.'' It states that, if $r$ follows from $q$ provided $p$ is true, then $r$ follows from $p$ provided $q$ is true.
\begin{flalign*}
	& \mathbf{\pmast2\pmcdot05}. \quad \pmthm \pmdottt q \pmimp r \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r & \\
	& \mathbf{\pmast2\pmcdot06}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r &
\end{flalign*}

These two propositions are the source of the syllogism in Barbara (as will be shown later) and are therefore called the ``principle of the syllogism'' (referred to as ``Syll''). The first states that, if $r$ follows from $q$, then if $q$ follows from $p$, $r$ follows from $p$. The second states the same thing with the premisses interchanged.
\begin{flalign*}
	& \mathbf{\pmast2\pmcdot08}. \quad \pmthm \pmdot p \pmimp p &
\end{flalign*}

\textit{I.e.}\ any proposition implies itself. This is called the ``principle of identity'' and referred to as ``Id.'' It is not the same as the ``law of identity'' (``$x$ is identical with $x$''), but the law of identity is inferred from it (cf. $\pmast13\pmcdot15$).
\begin{flalign*}
	& \mathbf{\pmast2\pmcdot21}. \quad \pmthm \pmdott \pmnot p \pmdot \pmimp \pmdot p \pmimp q &
\end{flalign*}

\textit{I.e.}\ a false proposition implies any proposition.

The later propositions of the present number are mostly subsumed under propositions in $\pmast3$ or $\pmast4$, which give the same results in more compendious forms. We now proceed to formal deductions. 
\pmfd
\begin{flalign*} \pagefirst{104} %2.01
	& \mathbf{\pmast2\pmcdot01}. \quad \pmthm \pmdott p \pmimp \pmnot p \pmdot \pmimp \pmdot p &
\end{flalign*}

This proposition states that, if $p$ implies its own falsehood, then $p$ is false. It is called the ``principle of the \textit{reductio ad absurdum},'' and will be referred to as ``Abs.''\footnote{There is an interesting historical article on this principle by Vailati, ``A proposito d'un passo del Teeteto e di una dimostrazione di Euclide,'' \textit{Rivista di Filosofia e scienze affine}, 1904.} The proof is as follows (where ``\textit{Dem}.'' is short for ``demonstration''):
\\ \\ 
\pmdemi
\begin{flalign*} %2.01
	&& & \pmSub{\text{Taut}}{\pmnot p}{p}& &\pmthm \pmdott \pmnot p \pmor \pmnot p \pmdot \pmimp \pmdot \pmnot p& && (1)  \\
	&& & [(1)\pmdot(\pmast1\pmcdot01)]& &\pmthm \pmdott p \pmimp \pmnot p \pmdot \pmimp \pmdot \pmnot p& && 
\end{flalign*}
\begin{flalign*} %2.02
	& \mathbf{\pmast2\pmcdot02}. \quad \pmthm \pmdott q \pmdot \pmimp \pmdot p \pmimp q & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.02
	&& & \pmSub{\text{Add}}{\pmnot p}{p} & &\pmthm \pmdott q \pmdot \pmimp \pmdot \pmnot p \pmor q & && (1)  \\
	&& & [(1)\pmdot(\pmast1\pmcdot01)]& &\pmthm \pmdott q \pmdot \pmimp \pmdot p \pmimp q & &&
\end{flalign*}
\begin{flalign*} %2.03
& \mathbf{\pmast2\pmcdot03}. \quad \pmthm \pmdott p \pmimp \pmnot q \pmdot \pmimp \pmdot q \pmimp \pmnot p & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.03
&& & \pmSubb{\text{Perm}}{\pmnot p}{p}{\pmnot q}{q} & &\pmthm \pmdott \pmnot p \pmor \pmnot q \pmdot \pmimp \pmdot \pmnot q \pmor \pmnot p & && (1)  \\
&& & [(1)\pmdot(\pmast1\pmcdot01)]& &\pmthm \pmdott p \pmimp \pmnot q \pmdot \pmimp \pmdot q \pmimp \pmnot p & &&
\end{flalign*}
\begin{flalign*} %2.04
& \mathbf{\pmast2\pmcdot04}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott q \pmdot \pmimp \pmdot p \pmimp r & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.04
&& & \pmSubb{\text{Assoc}}{\pmnot p}{p}{\pmnot q}{q} & &\pmthm \pmdottt \pmnot p \pmor (\pmnot q \pmor r) \pmdot \pmimp \pmdot \pmnot q \pmor (\pmnot p \pmor r) & && (1) \\
&& & [(1)\pmdot(\pmast1\pmcdot01)]& &\pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott q \pmdot \pmimp \pmdot p \pmimp r & &&
\end{flalign*}
\begin{flalign*} %2.05
& \mathbf{\pmast2\pmcdot05}. \quad \pmthm \pmdottt q \pmimp r \pmdott \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.05
&& & \pmSub{\text{Sum}}{\pmnot p}{p} & &\pmthm \pmdottt q \pmimp r \pmdot \pmimp \pmdott \pmnot p \pmor q \pmdot \pmimp \pmdot \pmnot p \pmor r & && (1) \\
&& & [(1)\pmdot(\pmast1\pmcdot01)]& &\pmthm \pmdottt q \pmimp r \pmdott \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r & &&
\end{flalign*}
\begin{flalign*} %2.06
& \mathbf{\pmast2\pmcdot06}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.06
&& & \pmSubbb{\text{Comm}}{q \pmimp r}{p}{p \pmimp q}{q}{p \pmimp r}{r} & &\pmthm \pmdotttt q \pmimp r \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r  \pmdottt & && \\
&& && & \quad \pmimp \pmdottt p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r & && (1) \\
&& & [\pmast2\pmcdot05] & &\pmthm \pmdottt q \pmimp r \pmdott \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r & && (2) \\
&& & [(1)\pmdot(2)\pmdot(\pmast1\pmcdot11)]& &\pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r & &&
\end{flalign*}
In the last line of this proof, ``$(1)\pmdot(2)\pmdot(\pmast1\pmcdot11)$" means that we are inferring in accordance with $\pmast1\pmcdot11$, having before us a proposition, namely $p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r$, which, by one, is implied by $q \pmimp r \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r$, which, by (2), is true. In general, in such cases, we shall omit the reference to $\pmast1\pmcdot11$. 

\pagefirst{105} The above two propositions will both be referred to as the ``principle of the syllogism" (shortened to ``Syll"), because, as will appear later, the syllogism in Barbara is derived from them. 
\begin{flalign*} %2.07
	& \mathbf{\pmast2\pmcdot07}. \quad \pmthm \pmdott p \pmdot \pmimp \pmdot p \pmor p \quad \pmSub{\pmast1\pmcdot3}{p}{q} & 
\end{flalign*}
Here we put nothing beyond ``$\pmast1\pmcdot3\dfrac{p}{q}$," because the proposition to be proved is what $\pmast1\pmcdot3$ becomes when $p$ is written in place of $q$. 

\begin{flalign*} %2.08
	& \mathbf{\pmast2\pmcdot08}. \quad \pmthm \pmdot p \pmimp p & 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.08
	&& & \pmSubb{\pmast2\pmcdot05}{p \pmor p}{q}{p}{r} & &\pmthm \pmdotttt p \pmor p \pmdot \pmimp \pmdot p \pmdott \pmimp \pmdottt p \pmdot \pmimp \pmdot p \pmor p \pmdott \pmimp \pmdot p \pmimp p & && (1) \\
	&& & [\text{Taut}]& &\pmthm \pmdott p \pmor p \pmdot \pmimp \pmdot p  & && (2) \\
	&& & [(1)\pmdot(2)\pmdot\pmast1\pmcdot11]& &\pmthm \pmdottt p \pmdot \pmimp \pmdot p \pmor p \pmdott \pmimp \pmdot p \pmimp p  & && (3) \\
	&& & [\pmdot\pmast2\pmcdot07]& &\pmthm \pmdott p \pmdot \pmimp \pmdot p \pmor p & && (4) \\
	&& & [(3)\pmdot(4)\pmdot\pmast1\pmcdot11]& & \pmthm \pmdot p \pmimp p  & && 
\end{flalign*}
\begin{flalign*} %2.1
	& \mathbf{\pmast2\pmcdot1}. \quad \pmthm \pmdot \pmnot p \pmor p \quad [\pmast2\pmcdot08\pmdot(\pmast1\pmcdot01)] & 
\end{flalign*}
\begin{flalign*} %2.11
& \mathbf{\pmast2\pmcdot11}. \quad \pmthm \pmdot p \pmor \pmnot p & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.11
&& & \pmSubb{\text{Perm}}{\pmnot p}{p}{p}{q} & &\pmthm \pmdott \pmnot p \pmor p \pmdot \pmimp \pmdot p \pmor \pmnot p & && (1) \\ && &[(1)\pmdot\pmast2\pmcdot1\pmdot\pmast1\pmcdot11]& &\pmthm \pmdot p \pmor \pmnot p  & &&
\end{flalign*}
This is the law of excluded middle.
\begin{flalign*} %2.12
	& \mathbf{\pmast2\pmcdot12}. \quad \pmthm \pmdot p \pmimp \pmnot (\pmnot p) & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.12
	&& & \pmSub{\pmast2\pmcdot11}{\pmnot p}{p} & &\pmthm \pmdott \pmnot p \pmor \pmnot (\pmnot p) & && (1) \\ && &[(1)\pmdot(\pmast1\pmcdot01)]& &\pmthm \pmdot p \pmimp \pmnot (\pmnot p)   & &&
\end{flalign*}
\pagefirst{106} \begin{flalign*} %2.13
& \mathbf{\pmast2\pmcdot13}. \quad \pmthm \pmdot p \pmor \pmnot \{\pmnot (\pmnot p)\} & && && && 
\end{flalign*}

This proposition is a lemma for $\pmast2\pmcdot14$, which, with $\pmast2\pmcdot12$, constitutes the principle of double negation.
\\ \\ 
\pmdemi
\begin{flalign*} %2.13
	&& & \pmSubb{\text{Sum}}{\pmnot p}{q}{\pmnot\{\pmnot(\pmnot p)\}}{r} & &\pmthm \pmdottt \pmnot p \pmdot \pmimp \pmdot \pmnot\{\pmnot(\pmnot p)\} \pmdot \pmimp \pmdott & \\
	&& && & \qquad \quad p \pmor \pmnot p \pmdot \pmimp \pmdot p \pmor \pmnot\{\pmnot(\pmnot p)\} & (1) \\
	&& & \pmSub{\pmast2\pmcdot12}{\pmnot p}{p} & &\pmthm \pmdott \pmnot p \pmdot \pmimp \pmdot \pmnot\{\pmnot(\pmnot p)\}  & (2) \\
	&& & [(1)\pmdot(2)\pmdot\pmast1\pmcdot11]& &\pmthm \pmdott p \pmor \pmnot p \pmdot \pmimp \pmdot p \pmor \pmnot\{\pmnot(\pmnot p)\} & (3) \\
	&& & [(3)\pmdot\pmast2\pmcdot11\pmdot\pmdot\pmast1\pmcdot11]& & \pmthm \pmdot p \pmor \pmnot\{\pmnot(\pmnot p)\}  &  
\end{flalign*}

\begin{flalign*} %2.14
	& \mathbf{\pmast2\pmcdot14}. \quad \pmthm \pmdot \pmnot (\pmnot p) \pmimp p &  
\end{flalign*}
\pmdemi
\begin{flalign*} %2.14
	&& & \pmSub{\text{Perm}}{\pmnot\{\pmnot(\pmnot p)\}}{q} & &\pmthm \pmdott p \pmor \pmnot \{\pmnot (\pmnot p)\} \pmdot \pmimp \pmdot \pmnot\{\pmnot(\pmnot p)\} \pmor p & (1) \\ 
	&& &[(1)\pmdot\pmast2\pmcdot13\pmdot\pmast1\pmcdot11]& &\pmthm \pmdot \pmnot\{\pmnot(\pmnot p)\} \pmor p & (2) \\
	&& & [(2)\pmdot(\pmast1\pmcdot01)]& & \pmthm \pmdot \pmnot (\pmnot p) \pmimp p & 
\end{flalign*}
\begin{flalign*} %2.15
& \mathbf{\pmast2\pmcdot15}. \quad \pmthm \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp p &  
\end{flalign*}
\pmdemi
\begin{flalign*} %2.15
&\pmSubb{\pmast2\pmcdot05}{\pmnot p}{p}{\pmnot(\pmnot q)}{r} & &\pmthm \pmdottt q \pmimp \pmnot(\pmnot q) \pmdot \pmimp \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot p \pmimp \pmnot(\pmnot q) & (1) \\ 
&\pmSub{\pmast2\pmcdot12}{q}{p} & &\pmthm \pmdot q \pmimp \pmnot(\pmnot q) & (2) \\ 
&[(1)\pmdot(2)\pmdot\pmast1\pmcdot11] & &\pmthm \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot p \pmimp \pmnot(\pmnot q) & (3) \\
&\pmSubb{\pmast2\pmcdot03}{\pmnot p}{p}{\pmnot q}{q} & &\pmthm \pmdott \pmnot p \pmimp \pmnot(\pmnot q) \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot(\pmnot p) & (4) \\ 
&\pmSubbb{\pmast2\pmcdot05}{\pmnot q}{p}{\pmnot(\pmnot p)}{q}{p}{r} & &\pmthm \pmdottt \pmnot(\pmnot p) \pmimp p \pmdot \pmimp \pmdott \pmnot q \pmimp \pmnot(\pmnot p) \pmdot \pmimp \pmdot \pmnot q \pmimp p & (5) \\ 
&[(5)\pmdot\pmast2\pmcdot14\pmdot\pmast1\pmcdot11] & & \pmthm \pmdott \pmnot q \pmimp \pmnot(\pmnot p) \pmdot \pmimp \pmdot \pmnot q \pmimp p & (6) \\
&\multispan3{$\pmSubbb{\pmast2\pmcdot05}{\pmnot p \pmimp q}{p}{\pmnot p \pmimp \pmnot(\pmnot q)}{q}{\pmnot q \pmimp \pmnot(\pmnot p)}{r} \quad \pmthm \pmdotttt \pmnot p \pmimp \pmnot(\pmnot q) \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot (\pmnot p) \pmdott \pmimp \pmdottt$} &\\ 
&& & \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot p \pmimp \pmnot(\pmnot q) \pmdott \pmimp \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot(\pmnot p) &  (7) \\ 
&[(4)\pmdot(7)\pmdot\pmast1\pmcdot11]& & \pmthm \pmdottt \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot p \pmimp \pmnot(\pmnot q) \pmdott \pmimp \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot(\pmnot p) &  (8) \\ \pagefirst{107} 
&[(3)\pmdot(8)\pmdot\pmast1\pmcdot11]& & \pmthm \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot(\pmnot p) &  (9) \\
&\multispan3{$\pmSubbb{\pmast2\pmcdot05}{\pmnot p \pmimp q}{p}{\pmnot q \pmimp \pmnot(\pmnot p)}{q}{\pmnot q \pmimp p}{r} \quad \pmthm \pmdotttt \pmnot q \pmimp \pmnot(\pmnot p) \pmdot \pmimp \pmdot \pmnot q \pmimp p \pmdott \pmimp \pmdott$ \hfill} &  \\ 
&& & \pmimp \pmdottt \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot(\pmnot p) \pmdott \pmimp \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp p & (10) \\ 
&[(6)\pmdot(10)\pmdot\pmast1\pmcdot11]& & \pmthm \pmdottt \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot(\pmnot p) \pmdott \pmimp \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp p &  (11) \\
&[(9)\pmdot(11)\pmdot\pmast1\pmcdot11]& & \pmthm \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp p & \\
\end{flalign*}

\textit{Note on the proof of $\pmast2\pmcdot15$}. In the above proof, it will be seen that (3), (4), (6) are respectively of the forms $p_1 \pmimp p_2$, $p_2 \pmimp p_3$, $p_3 \pmimp p_4$, where $p_1 \pmimp p_4$ is the proposition to be proved. From $p_1 \pmimp p_2$, $p_2 \pmimp p_3$, $p_3 \pmimp p_4$ the proposition $p_1 \pmimp p_4$ results by repeated applications of $\pmast2\pmcdot05$ or $\pmast2\pmcdot06$ (both of which are called ``Syll"). It is tedious and unnecessary to repeat this process every time it is used; it will therefore be abbreviated into
\[
	\text{``[Syll] } \pmthm \pmdot (a) \pmand (b) \pmand (c) \pmdot \pmimp \pmthm \pmdot (d)\text{,"}
\]
where $(a)$ is of the form $p_1 \pmimp p_2$, $(b)$ of the form $p_2 \pmimp p_3$, $(c)$ of the form $p_3 \pmimp p_4$, and $(d)$ of the form $p_1 \pmimp p_4$. The same abbreviation will be applied to a sorites of any length.

Also where we have ``$\pmthm \pmdot p_1$" and ``$\pmthm \pmdot p_1 \pmimp p_2$," and $p_2$ is the proposition to
be proved, it is convenient to write simply 
\begin{flalign*}
	&& \text{``}\:&\pmthm \pmdot p_1 \pmdot \pmimp & && \\
	&\text{[etc.]} & &\pmthm \pmdot p_2\text{,"}& &&
\end{flalign*}
where ``etc." will be a reference to the previous propositions in virtue of which the implication ``$\pmdot p_1 \pmimp p_2$" holds. This form embodies the use of $\pmast1\pmcdot11$ or $\pmast1\pmcdot1$, and makes many proofs at once shorter and easier to follow. It is used in the first two lines of the following proof.
\begin{flalign*} %2.16
	& \mathbf{\pmast2\pmcdot16}. \quad \pmthm \pmdott p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot p & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.16
	&& & [\pmast2\pmcdot12]& &\pmthm \pmdot q \pmimp \pmnot (\pmnot q) \pmdot \pmimp  & && \\
	&& & [\pmast2\pmcdot05]& &\pmthm \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp \pmnot(\pmnot q)  & && (1) \\
	&& & \pmSub{\pmast2\pmcdot03}{\pmnot q}{q} & &\pmthm \pmdott p \pmimp \pmnot(\pmnot q) \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot p & && (2) \\
	&& & [\text{Syll}]& &\pmthm \pmdot (1) \pmand (2) \pmdot \pmithm \pmdott p \pmimp q \pmdot \pmimp \pmdot \pmnot q \pmimp \pmnot p & && 
\end{flalign*}

\pagefirst{108} \textit{Note}. The proposition to be proved will be called ``\pmprop," and when a proof ends, like that of $\pmast2\pmcdot16$, by an implication between asserted propositions, of which the consequent is the proposition to be proved, we shall write ``$\pmthm \pmdot \text{etc.} \pmithm \pmdot \pmprop$". Thus ``$\pmithm \pmdot \pmprop$" ends a proof, and more or less corresponds to ``\begin{scriptsize}Q.E.D.\end{scriptsize}"
\begin{flalign*} %2.17
	& \mathbf{\pmast2\pmcdot17}. \quad \pmthm \pmdott \pmnot q \pmimp \pmnot p \pmdot \pmimp \pmdot p \pmimp q & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.17
	&& & \pmSubb{\pmast2\pmcdot03}{\pmnot q}{p}{p}{q} & &\pmthm \pmdott \pmnot q \pmimp \pmnot p \pmdot \pmimp \pmdot p \pmimp \pmnot(\pmnot q) & && (1) \\
	&& & [\pmast2\pmcdot14]& &\pmthm \pmdot \pmnot (\pmnot q) \pmimp q \pmdott \pmimp & && \\
	&& & [\pmast2\pmcdot05]& &\pmthm \pmdott p \pmimp \pmnot(\pmnot q) \pmdot \pmimp \pmdot p \pmimp q  & && (2) \\
	&& & [\text{Syll}]& &\pmthm \pmdot (1) \pmand (2) \pmdot \pmithm \pmprop & && 
\end{flalign*}

$\pmast2\pmcdot15$, $\pmast2\pmcdot16$ and $\pmast2\pmcdot17$ are forms of the principle of transposition, and will be all referred to as ``Transp."
\begin{flalign*} %2.18
	& \mathbf{\pmast2\pmcdot18}. \quad \pmthm \pmdott \pmnot p \pmimp p \pmdot \pmimp \pmdot p & && && && 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.18
	&& & [\pmast2\pmcdot12]& &\pmthm \pmdot p \pmimp \pmnot (\pmnot p) \pmdot \pmimp & && \\
	&& & [\pmast2\pmcdot05]& &\pmthm \pmdot \pmnot p \pmimp p \pmdot \pmimp \pmdot \pmnot p \pmimp \pmnot(\pmnot p)  & && (2) \\
	&& & \pmSub{\pmast2\pmcdot01}{\pmnot p}{p}& &\pmthm \pmdott \pmnot p \pmimp \pmnot(\pmnot p) \pmdot \pmimp \pmdot \pmnot(\pmnot p) & && (2) \\
	&& & [\text{Syll}]& &\pmthm \pmdot (1) \pmand (2) \pmdot \pmithm \pmdott \pmnot p \pmimp p \pmdot \pmimp \pmdot \pmnot(\pmnot p)  & && (3) \\
	&& & [\pmast2\pmcdot14]& &\pmthm \pmdot \pmnot (\pmnot p) \pmimp p & && (4) \\
	&& & [\text{Syll}]& &\pmthm \pmdot (3) \pmand (4) \pmdot \pmithm \pmdot \pmprop  & && \\
\end{flalign*}

This is the complement of the principle of the \textit{reductio ad absurdum}. It states that a proposition which follows from the hypothesis of its own falsehood is true.
\begin{flalign*} %2.2
	& \mathbf{\pmast2\pmcdot2}. \quad \pmthm \pmdott p \pmdot \pmimp \pmdot p \pmor q & 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.2
	&& & \pmthm \pmdot \text{Add} \pmdot \pmithm \pmdott p \pmimp q \pmor p & (1) \\
	&& & [\text{Perm}]\; \pmthm \pmdott q \pmor p \pmdot \pmimp \pmdot p \pmor q & (2) \\
	&& & [\text{Syll}]\;  \pmthm \pmdot (1) \pmand (2) \pmdot \pmithm \pmdot \pmprop  & \\
\end{flalign*}
\begin{flalign*} %2.21
& \mathbf{\pmast2\pmcdot21}. \quad \pmthm \pmdott \pmnot p \pmdot \pmimp \pmdot p \pmimp q \quad \pmSub{\pmast2\pmcdot2}{\pmnot p}{p} & 
\end{flalign*}

The above two propositions are very frequently used.
\begin{flalign*} %2.24
	& \mathbf{\pmast2\pmcdot24}. \quad \pmthm \pmdott p \pmdot \pmimp \pmdot \pmnot p \pmimp q \quad [\pmast2\pmcdot21 \pmdot \text{Comm}] & 
\end{flalign*}
\pagefirst{109} \begin{flalign*} %2.25
& \mathbf{\pmast2\pmcdot25}. \quad \pmthm \pmdottt p \pmdott \pmor \pmdott p \pmor q \pmdot \pmimp \pmdot q & 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.25
	&& & \pmthm \pmdot \pmast2\pmcdot1 \pmdot \pmithm \pmdott \pmnot(p \pmor q) \pmdot \pmor \pmdot (p \pmor q) \pmdott & \\
	&& & [\text{Assoc}]\:\: \pmithm \pmdott p \pmdot \pmor \pmdot \{\pmnot(p \pmor q) \pmdot \pmor \pmdot q\} \pmdott \pmithm \pmdot \pmprop  & 
\end{flalign*}
\begin{flalign*} %2.26
& \mathbf{\pmast2\pmcdot26}. \quad \pmthm \pmdottt \pmnot p \pmdott \pmor \pmdott p \pmimp q \pmdot \pmimp \pmdot q \quad \pmSub{\pmast2\pmcdot25}{\pmnot p}{p} & 
\end{flalign*}
\begin{flalign*} %2.27
& \mathbf{\pmast2\pmcdot27}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot q \quad [\pmast2\pmcdot26] & 
\end{flalign*}
\begin{flalign*} %2.3
	& \mathbf{\pmast2\pmcdot3}. \quad \pmthm \pmdott p \pmor (q \pmor r) \pmdot \pmimp \pmdot p \pmor (r \pmor q)  & 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.3
	&& & \pmSubb{\text{Perm}}{q}{p}{r}{q} \;\:\qquad\qquad \pmthm \pmdott (q \pmor r) \pmdot \pmimp \pmdot (r \pmor q) \pmdott & \\
	&& & \pmSubb{\text{Sum}}{q \pmor r}{q}{r \pmor r}{r}\:\: \pmithm \pmdott p \pmor (q \pmor r) \pmdot \pmimp \pmdot p \pmor (r \pmor q) & 
\end{flalign*}
\begin{flalign*} %2.31
& \mathbf{\pmast2\pmcdot31}. \quad \pmthm \pmdott p \pmor (q \pmor r) \pmdot \pmimp \pmdot (p \pmor q) \pmor r & 
\end{flalign*}

This proposition and $\pmast2\pmcdot32$ together constitute the associative law for logical addition of propositions. In the proof, the following abbreviation (constantly used hereafter) will be employed\footnote{This abbreviation applies to the same type of cases as those concerned in the note to $\pmast2\pmcdot15$, but is often more convenient than the abbreviation explained in that note.}: When we have a series of propositions of the form $a \pmimp b$, $b \pmimp c$, $c \pmimp d$, all asserted, and ``$a \pmimp d$" is the proposition to be proved, the proof io full is as follows:
\begin{flalign*} %2.31
	&[\text{Syll}] & &\pmthm \pmdottt a \pmimp b \pmdot \pmimp \pmdott b \pmimp c \pmdot \pmimp \pmdot a \pmimp c & (1) \\ 
	& & &\pmthm \pmdott a \pmdot \pmimp \pmdot b & (2) \\ 
	&[(1)\pmdot(2)\pmdot\pmast1\pmcdot11] & &\pmthm \pmdott b \pmimp c \pmdot \pmimp \pmdot a \pmimp c  & (3) \\
	& & &\pmthm \pmdott b \pmdot \pmimp \pmdot c & (4) \\
	&[(3)\pmdot(4)\pmdot\pmast1\pmcdot11] & &\pmthm \pmdott a \pmdot \pmimp \pmdot c  &  (5) \\ 
	&[\text{Syll}] & &\pmthm \pmdottt a \pmimp c \pmdot \pmimp \pmdott c \pmimp d \pmdot \pmimp \pmdot a \pmimp d & (6) \\ 
	&[(5)\pmdot(6)\pmdot\pmast1\pmcdot11] & &\pmthm \pmdott c \pmimp d \pmdot \pmimp \pmdot a \pmimp d  & (7) \\
	& & &\pmthm \pmdott c \pmdot \pmimp \pmdot d & (8) \\
	&[(7)\pmdot(8)\pmdot\pmast1\pmcdot11] & &\pmthm \pmdott a \pmdot \pmimp \pmdot d  & \\
\end{flalign*}

It is tedious to write out this process in full; we therefore write simply
\begin{flalign*}
	&& &\pmthm\: \pmdott a \pmdot \pmimp \pmdot b \pmdot & \\
	&& &[\text{etc.}]\; \pmimp \pmdot c \pmdot & \\
	&& &[\text{etc.}]\; \pmimp \pmdot d \pmdott \pmithm \pmdot \pmprop, &
\end{flalign*}
where ``$a \pmimp d$" is the proposition to be proved. We indicate on the left by references in square brackets the propositions in virtue of which the successive implications hold. We put one dot (not two) after ``$b$," to show \pagefirst{110} that it is $b$, not ``$a \pmimp b$," that implies $c$. But we put two dots after $d$, to show that now the whole proposition ``$a \pmimp d$" is concerned. If ``$a \pmimp d$" is not the proposition to be proved, but is to be used subsequently in the proof, we put
\begin{flalign*}
	&& &\pmthm\: \pmdott a \pmdot \pmimp \pmdot b \pmdot & \\
	&& &[\text{etc.}]\; \pmimp \pmdot c \pmdot & \\
	&& &[\text{etc.}]\; \pmimp \pmdot d \pmdott \pmithm \pmdot \pmprop & (1),
\end{flalign*}
and then ``(1)" means ``$a \pmimp d$." The proof of $\pmast2\pmcdot31$ is as follows:
\\ \\
\pmdemi
\begin{flalign*} %2.31
	&& && && && & \multispan7{$[\pmast2\pmcdot3]\:\pmthm \pmdott p \pmor (q \pmor r) \pmdot \pmimp \pmdot p \pmor (r \pmor q) \pmdot $ \hfill} & && && && \\
	&& && && && & \pmSubb{\text{Assoc}}{r}{q}{q}{r} & & \pmimp \pmdot r \pmor (p \pmor q) \pmdot & && && \\
	&& && && && & \pmSubb{\text{Perm}}{q}{p}{r}{q} & & \pmimp \pmdott (q \pmor r) \pmdot \pmimp \pmdot (r \pmor q) \pmdott \pmithm \pmdot \pmprop & && &&
\end{flalign*}
\begin{flalign*} %2.32
	& \mathbf{\pmast2\pmcdot32}. \quad \pmthm \pmdott (p \pmor q) \pmor r \pmdot \pmimp \pmdot p \pmor (q \pmor r) & 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.32
	&& &\multispan4{$\pmSubb{\text{Perm}}{p \pmor q}{p}{r}{q}\:\pmthm \pmdott (p \pmor q) \pmor r \pmdot \pmimp \pmdot r \pmor (p \pmor q)$ \hfill} & && && \\
	&& &  \pmSubbb{\text{Assoc}}{r}{p}{p}{q}{q}{r} & & \quad\pmimp \pmdot p \pmor (r \pmor q) \pmdot & && \\
	&& & [\pmast2\pmcdot3] & & \quad\pmimp \pmdot p \pmor (q \pmor r) \pmdott \pmithm \pmdot \pmprop & &&
\end{flalign*}
\begin{flalign*} %2.33
& \mathbf{\pmast2\pmcdot33}. \quad p \pmor q \pmor r \pmdot \pmiddf \pmdot (p \pmor q) \pmor r \pmdf & 
\end{flalign*}

This definition serves only for the avoidance of brackets.

\begin{flalign*} %2.36
	& \mathbf{\pmast2\pmcdot32}. \quad \pmthm \pmdott (p \pmor q) \pmor r \pmdot \pmimp \pmdot p \pmor (q \pmor r) & 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.36
	&& & [\text{Perm}] & \pmthm &\pmdott p \pmor r \pmdot \pmimp \pmdot r \pmor p \pmdott & \\
	&& &  \pmSubbb{\text{Syll}}{p \pmor q}{p}{p \pmor r}{q}{r \pmor p}{r} & \pmithm & \pmdottt p \pmor q \pmdot \pmimp p \pmor r \pmdott \pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot r \pmor p & (1) \\
	&& & [\text{Sum}] & \pmthm & \pmdottt q \pmimp r \pmdot \pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot p \pmor r & (2) \\
	&& & \pmdot(1)\pmdot(2)\pmdot\text{Syll}\pmdot\pmithm\pmdot \pmprop
\end{flalign*}
\begin{flalign*} %2.37
& \mathbf{\pmast2\pmcdot37}. \quad \pmthm \pmdottt q \pmimp r \pmdot \pmimp \pmdott q \pmor p \pmdot \pmimp \pmdot p \pmor r \quad [\text{Syll} \pmdot \text{Perm} \pmdot \text{Sum}] & 
\end{flalign*}
\begin{flalign*} %2.38
& \mathbf{\pmast2\pmcdot38}. \quad \pmthm \pmdottt q \pmimp r \pmdot \pmimp \pmdott q \pmor p \pmdot \pmimp \pmdot r \pmor p \quad [\text{Syll} \pmdot \text{Perm} \pmdot \text{Sum}] & 
\end{flalign*}

The proofs of $\pmast2\pmcdot37\pmcdot38$ are exactly analogous to that of $\pmast2\pmcdot36$. (We use ``$\pmast2\pmcdot37\pmcdot38$" as an abbreviation for ``$\pmast2\pmcdot37$ and $\pmast2\pmcdot38$." Such abbreviations will be used throughout.)

\pagefirst{111} The use of a general principle of deduction, such as either form of ``Syll," in a proof, is different from the use of the particular premisses to which the principle of deduction is applied. The principle of deduction gives the general rule according to which the inference is made, but is not itself a premiss in the inference. If we treated it as a premiss, we should need either it or some other general rule to enable us to infer the desired conclusion, and thus we should gradually acquire an increasing accumulation of premisses without ever being able to make any inference. Thus when a general rule is adduced in drawing an inference, as when we write ``$[\text{Syll}]\: \pmthm \pmdot (1) \pmdot (2) \pmdot \pmithm \:\pmdot \pmprop$," the mention of ``Syll" is only required in order to remind the reader how the inference is drawn. 

The rule of inference may, however, also occur as one of the ordinary premisses, that is to say, in the case of ``Syll" for example, the proposition ``$p \pmimp q \pmdot \pmimp \pmdott q \pmimp r \pmdot \pmimp \pmdot p \pmimp r$" may be one of those to which our rules of deduction are applied, and it is then an ordinary premiss. The distinction between the two uses of principles of deduction is of some philosophical importance, and in the above proofs we have indicated it by putting the rule of inference in square brackets. It is, however, practically inconvenient to continue to distinguish in the manner of the reference. We shall therefore henceforth both adduce ordinary premisses in square brackets where convenient, and adduce rules of inference, along with other propositions, in
asserted premisses, \textit{i.e.}\ we shall write \textit{e.g.}\
\begin{flalign*}
	&& &\text{``} \pmthm \pmdot (1) \pmdot (2) \pmdot \text{Syll} \pmdot \pmithm\: \pmdot \pmprop\text{"} & \\
	&\text{rather than} & &\text{``}[\text{Syll}] \: \pmthm \pmdot (1) \pmdot (2) \pmdot\pmdot \pmithm\: \pmdot \pmprop\text{"} & 
\end{flalign*}
\begin{flalign*} %2.4
& \mathbf{\pmast2\pmcdot4}. \quad \pmthm \pmdottt p \pmdot \pmor \pmdot p \pmor q \pmdott \pmimp \pmdot p \pmor q & 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.4
&& & \pmthm \pmdottt \pmast2\pmcdot31 \pmdot \pmithm \pmdottt & p \pmdot \pmor \pmdot p \pmor q \pmdott\; & \pmimp \pmdot p \pmor p \pmdot \pmor \pmdot q \pmdott & \\
&& & [\text{Sum}\pmdot\pmast2\pmcdot38] & & \pmimp \pmdott p\pmor q \pmdottt \pmithm\pmdot \pmprop & 
\end{flalign*}
\begin{flalign*} %2.41
& \mathbf{\pmast2\pmcdot41}. \quad \pmthm \pmdottt q \pmdot \pmor \pmdot p \pmor q \pmdott \pmimp \pmdot p \pmor q  & 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.41
&& &  \pmSubbb{\text{Assoc}}{q}{p}{p}{q}{q}{r} & \pmthm \pmdottt q \pmdot \pmor \pmdot p \pmor q \pmdott \; &\pmimp \pmdott p \pmdot \pmor \pmdot q \pmor q \pmdott & \\
&& & [\text{Taut}\pmdot\text{Sum}] && \pmimp \pmdott p \pmor q \pmdottt \pmithm\pmdot \pmprop &
\end{flalign*}
\begin{flalign*} %2.42
& \mathbf{\pmast2\pmcdot42}. \quad \pmthm \pmdottt \pmnot p \pmdot \pmor \pmdot p \pmimp q \pmdott \pmimp \pmdot p \pmimp q \quad \pmSub{\pmast2\pmcdot4}{\pmnot p}{p}  & 
\end{flalign*}
\begin{flalign*} %2.43
& \mathbf{\pmast2\pmcdot43}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdot p \pmimp q \pmdott \pmimp \pmdot p \pmimp q \quad [\pmast2\pmcdot42] & 
\end{flalign*}
\begin{flalign*} %2.45
& \mathbf{\pmast2\pmcdot45}. \quad \pmthm \pmdottt \pmnot(p \pmor q) \pmdot \pmimp \pmdot \pmnot p \quad [\pmast2\pmcdot2 \pmdot \text{Transp}] & 
\end{flalign*}
\begin{flalign*} %2.46
& \mathbf{\pmast2\pmcdot46}. \quad \pmthm \pmdott \pmnot(p \pmor q) \pmdot \pmimp \pmdot \pmnot q \quad [\pmast1\pmcdot3 \pmdot \text{Transp}] & 
\end{flalign*}
\pagefirst{112} 
\begin{flalign*} %2.47
	& \mathbf{\pmast2\pmcdot47}. \quad \pmthm \pmdott \pmnot(p \pmor q) \pmdot \pmimp \pmdot \pmnot p \pmor q \quad \pmbr{\pmast2\pmcdot45\pmdot\pmSUb{\pmast2\pmcdot2}{\pmnot p}{p}\pmdot\text{Syll}} & 
\end{flalign*}
\begin{flalign*} %2.48
	& \mathbf{\pmast2\pmcdot48}. \quad \pmthm \pmdott \pmnot(p \pmor q) \pmdot \pmimp \pmdot p \pmor \pmnot q \quad \pmbr{\pmast2\pmcdot46\pmdot\pmSUb{\pmast1\pmcdot3}{\pmnot q}{q}\pmdot\text{Syll}} & 
\end{flalign*}
\begin{flalign*} %2.49
	& \mathbf{\pmast2\pmcdot49}. \quad \pmthm \pmdott \pmnot(p \pmor q) \pmdot \pmimp \pmdot \pmnot p \pmor \pmnot q \quad \pmbr{\pmast2\pmcdot45\pmdot\pmSUbb{\pmast2\pmcdot2}{\pmnot p}{p}{\pmnot q}{q}\pmdot\text{Syll}} & 
\end{flalign*}
\begin{flalign*} %2.5
& \mathbf{\pmast2\pmcdot5}. \quad \pmthm \pmdott \pmnot(p \pmimp q) \pmdot \pmimp \pmdot \pmnot p \pmimp q \quad \pmSub{\pmast2\pmcdot47}{\pmnot p}{p} & 
\end{flalign*}
\begin{flalign*} %2.51
& \mathbf{\pmast2\pmcdot51}. \quad \pmthm \pmdott \pmnot(p \pmimp q) \pmdot \pmimp \pmdot p \pmimp \pmnot q \quad \pmSub{\pmast2\pmcdot48}{\pmnot p}{p} & 
\end{flalign*}
\begin{flalign*} %2.52
& \mathbf{\pmast2\pmcdot52}. \quad \pmthm \pmdott \pmnot(p \pmimp q) \pmdot \pmimp \pmdot \pmnot p \pmimp \pmnot q \quad \pmSub{\pmast2\pmcdot49}{\pmnot p}{p} & 
\end{flalign*}
\begin{flalign*} %2.521
& \mathbf{\pmast2\pmcdot521}. \quad \pmthm \pmdott \pmnot(p \pmimp q) \pmdot \pmimp \pmdot q \pmimp p \quad [\pmast2\pmcdot52\pmcdot17] & 
\end{flalign*}
\begin{flalign*} %2.53
& \mathbf{\pmast2\pmcdot53}. \quad \pmthm \pmdott p \pmor q \pmdot \pmimp \pmdot \pmnot p \pmimp q & 
\end{flalign*}
\pmdemi
\begin{flalign*} %2.53
	\pmthm \pmdot \pmast2\pmcdot12\pmcdot38\pmdot\pmimp\pmdot\pmnot(\pmnot p)\pmor q \pmdott \pmithm \pmdot \pmprop
\end{flalign*}
\begin{flalign*} %2.54
& \mathbf{\pmast2\pmcdot54}. \quad \pmthm \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot p \pmor q \quad [\pmast2\pmcdot14\pmcdot38] & 
\end{flalign*}
\begin{flalign*} %2.55
& \mathbf{\pmast2\pmcdot55}. \quad \pmthm \pmdottt \pmnot p \pmdot \pmimp\pmdott p \pmor q \pmdot \pmimp \pmdot q \quad [\pmast2\pmcdot53\pmdot\text{Comm}] & 
\end{flalign*}
\begin{flalign*} %2.56
& \mathbf{\pmast2\pmcdot56}. \quad \pmthm \pmdottt \pmnot q \pmdot \pmimp\pmdott p \pmor q \pmdot \pmimp \pmdot p \quad \pmbr{\pmSUbb{\pmast2\pmcdot55}{q}{p}{p}{q}\pmdot\text{Perm}} & 
\end{flalign*}
\begin{flalign*} %2.6
& \mathbf{\pmast2\pmcdot6}. \quad \pmthm \pmdottt \pmnot p \pmimp q \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot q & 
\end{flalign*}
\pmdemi
\begin{flalign*}%2.6
	&& & [\pmast2\pmcdot38] & &\pmthm \pmdottt \pmnot p \pmimp q \pmdot \pmimp \pmdott \pmnot p \pmor q \pmdot \pmimp \pmdot q \pmor q & (1) \\
	&& & [\text{Taut}\pmdot\text{Syll}] & &\pmthm \pmdottt \pmnot p \pmor q \pmdot \pmimp \pmdot q \pmor q \pmdott \pmimp \pmdott \pmnot p \pmor q \pmdot \pmimp \pmdot q & (2) \\
	&& & \multispan4{$(1)\pmdot(2)\pmdot\text{Syll}\pmdot \pmithm \pmdottt \pmnot p \pmimp q \pmdot \pmimp \pmdott \pmnot p \pmor q \pmdot \pmimp \pmdot q \pmdottt \pmithm \pmdot \pmprop$\hfill} & &&
\end{flalign*}
\begin{flalign*} %2.61
	& \mathbf{\pmast2\pmcdot61}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot q \quad [\pmast2\pmcdot6\pmdot\text{Comm}] & 
\end{flalign*}
\begin{flalign*} %2.62
	& \mathbf{\pmast2\pmcdot62}. \quad \pmthm \pmdottt p \pmor q \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot q \quad [\pmast2\pmcdot53\pmcdot6] & 
\end{flalign*}
\begin{flalign*} %2.621
	& \mathbf{\pmast2\pmcdot621}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot q \quad [\pmast2\pmcdot62\pmdot\text{Comm}] & 
\end{flalign*}
\begin{flalign*} %2.63
	& \mathbf{\pmast2\pmcdot63}. \quad \pmthm \pmdottt p \pmor q \pmdot \pmimp \pmdott \pmnot p \pmor q \pmdot \pmimp \pmdot q \quad [\pmast2\pmcdot62] & 
\end{flalign*}
\begin{flalign*} %2.64
	& \mathbf{\pmast2\pmcdot64}. \quad \pmthm \pmdottt p \pmor q \pmdot \pmimp \pmdott p \pmor \pmnot q \pmdot \pmimp \pmdot p \quad \pmbr{\pmSUbb{\pmast2\pmcdot63}{q}{p}{p}{q}\pmdot\text{Perm}} & 
\end{flalign*}
\begin{flalign*} %2.65
	& \mathbf{\pmast2\pmcdot65}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott p \pmimp \pmnot q \pmdot \pmimp \pmdot \pmnot p \quad \pmSub{\pmast2\pmcdot64}{\pmnot p}{p} & 
\end{flalign*}
\begin{flalign*} %2.67
	& \mathbf{\pmast2\pmcdot67}. \quad \pmthm \pmdottt p \pmor q \pmdot \pmimp \pmdot q \pmdott \pmimp \pmdot p \pmimp q & 
\end{flalign*}
\pmdemi
\begin{flalign*}%2.67
	&& & [\pmast2\pmcdot54\pmdot\text{Syll}] & &\pmthm \pmdottt p \pmor q \pmdot \pmimp \pmdot q \pmdott \pmimp \pmdott \pmnot p \pmimp q \pmdot \pmimp \pmdot q  & (1) \\
	&& & [\pmast2\pmcdot24\pmdot\text{Syll}] & &\pmthm \pmdottt \pmnot p \pmimp q \pmdot \pmimp \pmdot \pmdot q \pmdott \pmimp \pmdot p \pmimp q  & (2) \\
	&& & \multispan4{$\pmthm \pmdot (1)\pmdot(2)\pmdot\text{Syll}\pmdot \pmithm \pmdot \pmprop$\hfill} & &&
\end{flalign*}
\pagefirst{113} 
\begin{flalign*} %2.68
	& \mathbf{\pmast2\pmcdot68}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdot q \pmdott \pmimp \pmdot p \pmor q & 
\end{flalign*}
\pmdemi
\begin{flalign*}%2.68
	&& & \pmSub{\pmast2\pmcdot54}{\pmnot p}{p} \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdot q \pmdott \pmimp \pmdot \pmnot p \pmimp q  & && (1) \\
	&& & \pmthm \pmdot (1)\pmdot\pmast2\pmcdot54\pmdot \pmithm \pmdot \pmprop & &&
\end{flalign*}
\begin{flalign*} %2.69
& \mathbf{\pmast2\pmcdot69}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdot q \pmdott \pmimp \pmdott q \pmimp p \pmdot \pmimp \pmdot p \quad \pmbr{\pmast2\pmcdot68\pmand\text{Perm}\pmand\pmSUbb{\pmast2\pmcdot62}{q}{p}{p}{q}} & 
\end{flalign*}
\begin{flalign*} %2.73
& \mathbf{\pmast2\pmcdot73}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott p \pmor q \pmor r \pmdot \pmimp \pmdot q \pmor r  \quad [\pmast2\pmcdot621\pmcdot38] & 
\end{flalign*}
\begin{flalign*} %2.74
& \mathbf{\pmast2\pmcdot74}. \quad \pmthm \pmdottt q \pmimp p \pmdot \pmimp \pmdott p \pmor q \pmor r \pmdot \pmimp \pmdot p \pmor r \quad \pmbr{\pmSUbb{\pmast2\pmcdot73}{q}{p}{p}{q}\pmand\text{Assoc}\pmand\text{Syll}} & 
\end{flalign*}
\begin{flalign*} %2.75
& \mathbf{\pmast2\pmcdot75}. \quad \pmthm \pmdotttt p \pmor q  \pmdot \pmimp \pmdottt p \pmdot \pmor \pmdot q \pmimp r \pmdott \pmimp \pmdot p \pmor r \quad \pmbr{\pmSUb{\pmast2\pmcdot74}{\pmnot q}{q}\pmand\pmast2\pmcdot53\pmcdot31} & 
\end{flalign*}
\begin{flalign*} %2.76
& \mathbf{\pmast2\pmcdot76}. \quad \pmthm \pmdottt p \pmdot \pmor \pmdot q \pmimp r \pmdott \pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot p \pmor r \quad [\pmast2\pmcdot75\pmand\text{Comm}] & 
\end{flalign*}
\begin{flalign*} %2.77
& \mathbf{\pmast2\pmcdot77}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott p \pmimp q \pmdot \pmimp \pmdot p \pmimp r \quad \pmSub{\pmast2\pmcdot76}{\pmnot p}{p} & 
\end{flalign*}
\begin{flalign*} %2.8
& \mathbf{\pmast2\pmcdot8}. \quad \pmthm \pmdottt q \pmor r \pmdot \pmimp \pmdott \pmnot r \pmor s \pmdot \pmimp \pmdot q \pmor s & 
\end{flalign*}
\pmdemi
\begin{flalign*}%2.8
&& [\pmast2\pmcdot53]\pmand\text{Perm}\pmdot \pmithm \pmdottt q \pmor r \pmdot\; &\pmimp \pmdott \pmnot r \pmimp q \pmdott  & && \\
&& [\pmast2\pmcdot38] \qquad\qquad\qquad\quad\quad\quad & \pmimp \pmdott \pmnot r \pmor s \pmdot \pmimp \pmdot q \pmor s \pmdottt \pmithm \pmdot \pmprop &&&
\end{flalign*}
\begin{flalign*} %2.81
& \mathbf{\pmast2\pmcdot81}. \quad \pmthm \pmdotttt q \pmdot \pmimp \pmdot r \pmimp s \pmdott \pmimp \pmdottt p \pmor q \pmdot \pmimp \pmdott p \pmor r \pmdot \pmimp \pmdot p \pmor s & 
\end{flalign*}
\pmdemi
\begin{flalign*}%2.81
&& & \pmthm\pmdot\text{Sum}\pmdot \pmithm \pmdotttt q \pmdot \pmimp \pmdot r \pmimp s \pmdott \pmimp \pmdottt p \pmor q \pmdot \pmimp \pmdott p \pmdot \pmor \pmdot r \pmimp s  & && (1) \\
&& & \pmthm \pmdot \pmast2\pmcdot76\pmand\text{Syll} \pmdot \pmithm \pmdotttt p \pmor q \pmdot \pmimp \pmdott p \pmdot \pmor \pmdot r \pmimp s \pmdottt \pmimp \pmdottt p \pmor q \pmdot \pmimp \pmdott p \pmor r \pmdot \pmimp \pmdot p \pmor s& && (2) \\
&& & \pmthm \pmdot (1)\pmand(2) \pmdot \pmithm \pmdot \pmprop & &&
\end{flalign*}
\begin{flalign*} %2.82
& \mathbf{\pmast2\pmcdot82}. \quad \pmthm \pmdottt p \pmor q \pmor r \pmdot \pmimp \pmdott p \pmor \pmnot r \pmor s \pmdot \pmimp \pmdot p \pmor q \pmor s \quad \pmbr{\pmast2\pmcdot8\pmand\pmSUbbb{\pmast2\pmcdot81}{q\pmor r}{q}{\pmnot r \pmor s}{r}{q\pmor s}{s}} & 
\end{flalign*}
\begin{flalign*} %2.83
& \mathbf{\pmast2\pmcdot83}. \quad \pmthm \pmdotttt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdottt p \pmdot \pmimp \pmdot r \pmimp s \pmdott \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmimp s \quad \pmSubb{\pmast2\pmcdot82}{\pmnot p}{p}{\pmnot q}{q} & 
\end{flalign*}
\begin{flalign*} %2.85
& \mathbf{\pmast2\pmcdot85}. \quad \pmthm \pmdottt p \pmor q \pmdot \pmimp \pmdot p \pmor r \pmdot \pmimp \pmdot p \pmdot \pmor \pmdot q \pmimp s  & 
\end{flalign*}
\pmdemi
\begin{flalign*}
	&& & \multispan3{$[\text{Add}\pmand\text{Syll}] \:\; \pmthm \pmdottt p \pmor q \pmdot \pmimp \pmdot r \pmdott \pmimp \pmdot q \pmimp r$ \hfill} & && (1) \\
	&& &\multispan3{$\pmthm\pmdot\pmast2\pmcdot55\pmdot\pmithm\pmdotttt \pmnot p \pmdot \pmimp \pmdottt p \pmor r \pmdot \pmimp \pmdot r \pmdottt$ \hfill} & &&\\
	&& & [\text{Syll}] && \pmimp \pmdottt p \pmor q \pmdot \pmimp \pmdot p \pmor r \pmdott \pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot r \pmdottt & &&\\
	&& & [(1)\pmand\pmast2\pmcdot83] & & \pmimp \pmdottt p \pmor q \pmdot \pmimp \pmdot p \pmor r \pmdott \pmimp \pmdott q \pmimp r  & && (2) \\
	&& & \multispan3{$\pmthm\pmdot(2)\pmand\text{Comm} \pmdot \pmithm \pmdottt \hspace{1.1em} p \pmor q \pmdot \pmimp \pmdot p \pmor r \pmdott \pmimp \pmdott q \pmimp r \pmdott \pmimp \pmdott$ \hfill} & && \\
	&& & [\pmast2\pmcdot54] & & \qquad \qquad \qquad \qquad \quad \; \pmimp \pmdott p \pmdot \pmor \pmdot q \pmimp r \pmdottt \pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} %2.86
& \mathbf{\pmast2\pmcdot86}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdot p \pmimp r \pmdott \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmimp r \quad \pmSub{\pmast2\pmcdot85}{\pmnot p}{p} & 
\end{flalign*}

\chapter*{\centering \pmast3. THE LOGICAL PRODUCT OF TWO PROPOSITIONS.} \addcontentsline{toc}{chapter}{❋3. THE LOGICAL PRODUCT OF TWO PROPOSITIONS.} \pagefirst{114} \noindent
\indent \textit{Summary of $\pmast$3.}

The logical product of two propositions $p$ and $q$ is practically the proposition ``$p$ and $q$ are both true." But this as it stands would have to be a new primitive idea. We therefore take as the logical product the proposition
$\pmnot(\pmnot p \pmor \pmnot q)$, \textit{i.e.}\ ``it is false that either $p$ is false or $q$ is false," which is obviously true when and only when p and q are both true. Thus we put
\begin{flalign*}
	& \mathbf{\pmast3\pmcdot01}. \quad p \pmand q \pmdot\pmiddf \pmdot  \pmnot(\pmnot p \pmor \pmnot q) \pmdf & 
\end{flalign*}

where ``$p \pmand q$" is the logical product of $p$ and $q$.
\begin{flalign*}
	& \mathbf{\pmast3\pmcdot02}. \quad p \pmimp q \pmimp r \pmdot\pmiddf \pmdot p \pmimp q \pmand q \pmimp r \pmdf & 
\end{flalign*}

This definition serves merely to abbreviate proofs.

When we are given two asserted propositional functions ``$\pmthm \pmdot \phi x$" and ``$\pmthm \pmdot \psi x$," we shall have ``$\pmthm \pmdot \phi x \pmand \psi x$" whenever $\phi$ and $\psi$ take arguments of the same type. This will be proved for any functions in $\pmast9$; for the present, we are confined to \textit{elementary} propositional functions of elementary propositions. In this case, the result is proved as follows:

By $\pmast1\pmcdot7$, $\pmnot \phi p$ and $\pmnot \psi p$ are elementary propositional functions, and therefore, by $\pmast1\pmcdot72$, $\pmnot \phi p \pmor \pmnot \psi p$ is an elementary propositional function. Hence by $\pmast2\pmcdot11$,
\[
	\pmthm \pmdott \pmnot \phi p \pmor \pmnot \psi p \pmdot \pmor \pmdot \pmnot(\pmnot \phi p \pmor \pmnot \psi p).
\]

Hence by $\pmast 2\pmcdot32$ and $\pmast1\pmcdot01$,
\[
	\pmthm \pmdottt \phi p \pmdot \pmimp \pmdott \psi p \pmdot \pmimp \pmdot \pmnot(\pmnot \phi p \pmor \pmnot \psi p).
\]
\textit{i.e.}\ by $\pmast3\pmcdot01$,
\[
\pmthm \pmdottt \phi p \pmdot \pmimp \pmdott \psi p \pmdot \pmimp \pmdot \phi p \pmand \psi p.
\]

Hence by $\pmast1\pmcdot11$, when we have ``$\pmthm \pmdot \phi p$" and ``$\pmthm \pmdot \psi p$" we have ``$\pmthm \pmdot \phi x \pmand \psi x$." This proposition is $\pmast3\pmcdot03$. It is to be understood, like $\pmast1\pmcdot72$, as applying also to functions of two or more variables.

The above is the practically most useful form of the axiom of identification of real variables (cf. $\pmast1\pmcdot72$). In practice, when the restriction to elementary propositions and propositional functions has been removed, a convenient means by which two functions can often be recognized as taking arguments of the same type is the following:

If $\phi x$ contains, in any way, a constituent $\chi(x, y, z, ...)$ and $\psi x$ contains, in any way, a constituent $\chi(x, u, v, ...)$, then both $\phi x$ and $\psi x$ take arguments \pagefirst{115} of the type of the argument $x$ in $\chi(x, y, z, ...)$, and therefore both $\phi x$ and $\psi x$ take arguments of the same type. Hence, in such a case, if both $\phi x$ and $\psi x$ can be asserted, so can $\phi x \pmand \psi x$.

As an example of the use of this proposition, take the proof of $\pmast3\pmcdot47$. We there prove
\begin{flalign*}
	&& &\pmthm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot q \pmand r & && (1) \\
	&\text{and}&  &\pmthm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \pmimp \pmdott q \pmand r \pmdot \pmimp \pmdot r \pmand s & && (2)
\end{flalign*}
and what we wish to prove is
\[
	p \pmimp r \pmand q \pmimp s \pmdot \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r \pmand s,
\]
which is which is $\pmast3\pmcdot47$. Now in (1) and (2), $p$, $q$, $r$, $s$ are elementary propositions (as everywhere in Section A); hence by $\pmast1\pmcdot7\pmcdot71$, applied repeatedly, ``$p \pmimp r \pmand  q \pmimp r \pmdot \pmimp \pmdott p \pmand q  \pmdot \pmimp \pmdot q \pmand r$" and ``$p \pmimp r \pmand q \pmimp s \pmdot \pmimp \pmdott q \pmand r \pmdot \pmimp \pmdot r \pmand s$" are elementary propositional functions. Hence by $\pmast3\pmcdot03$, we have
\[
	\pmthm \pmdotttt p \pmimp r \pmand q \pmimp s \pmdot \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot q \pmand r \pmanddd p \pmimp r \pmand q \pmimp s \pmdot \pmimp \pmdott q \pmand r \pmdot \pmimp \pmdot r \pmand s,
\]
whence the result follows by $\pmast3\pmcdot43$ and $\pmast3\pmcdot33$.

The principal propositions of the present number are the following:
\begin{flalign*}
	& \mathbf{\pmast3\pmcdot2}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdott q \pmdot \pmimp \pmdot p \pmand q & 
\end{flalign*}

\textit{I.e.}\ ``$p$ implies that $q$ implies $p \pmand q$," \textit{i.e.}\ if each of two propositions is true, so is their logical product.
\begin{flalign*}
	& \mathbf{\pmast3\pmcdot26}. \quad \pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot p & 
\end{flalign*}
\begin{flalign*}
& \mathbf{\pmast3\pmcdot27}. \quad \pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot q & 
\end{flalign*}

\textit{I.e.}\ if the logical product of two propositions is true, then each of the two propositions severally is true.
\begin{flalign*}
	& \mathbf{\pmast3\pmcdot3}. \quad \pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmimp r & 
\end{flalign*}

\textit{I.e.}\ if $p$ and $q$ jointly imply $r$, then $p$ implies that $q$ implies $r$. This principle (following Peano) will be called ``exportation," because $q$ is ``exported" from the hypothesis. It will be referred to as ``Exp."
\begin{flalign*}
	& \mathbf{\pmast3\pmcdot31}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r & 
\end{flalign*}

This is the correlative of the above, and will be called (following Peano) ``importation" (referred to as ``Imp").
\begin{flalign*}
	& \mathbf{\pmast3\pmcdot35}. \quad \pmthm \pmdott p \pmand p \pmimp q \pmdot \pmimp \pmdot q & 
\end{flalign*}

\textit{I.e.}\ ``if $p$ is true, and $q$ follows from it, then $q$ is true." This will be called the ``principle of assertion" (referred to as ``Ass"). It differs from $\pmast1\pmcdot1$ by the fact that it does not apply only when $p$ really is true, but requires merely the hypothesis that $p$ is true.
\begin{flalign*}
	& \mathbf{\pmast3\pmcdot43}. \quad \pmthm \pmdottt p \pmimp q \pmand p \pmimp r \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmand r & 
\end{flalign*}

\textit{I.e.}\ if a proposition implies each of two propositions, then it implies their logical product. This is called by Peano the ``principle of composition." It will be referred to as ``Comp."
\begin{flalign*}\pagefirst{116}
	& \mathbf{\pmast3\pmcdot45}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott p \pmand r \pmdot \pmimp \pmdot q \pmand r & 
\end{flalign*}

\textit{I.e.}\ both sides of an implication may be multiplied by a common factor. This is called by Peano the ``principle of the factor." It will be referred to
as ``Fact."
\begin{flalign*}
	& \mathbf{\pmast3\pmcdot47}. \quad \pmthm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r \pmand s & 
\end{flalign*}

\textit{I.e.}\ if $p$ implies $q$ and $r$ implies $s$, then $p$ and $q$ jointly imply $r$ and $s$ jointly. The law of contradiction, ``$\pmthm \pmdot \pmnot(p \pmand \pmnot p)$," is proved in this number ($\pmast3\pmcdot24$); but in spite of its fame we have found few occasions for its use.
\pmfd

\begin{flalign*} %3.01
	& \mathbf{\pmast3\pmcdot01}. \quad p \pmand q \pmdot\pmiddf \pmdot \pmnot(\pmnot p \pmor \pmnot q) \pmdf & 
\end{flalign*}
\begin{flalign*} %3.02
	& \mathbf{\pmast3\pmcdot02}. \quad p \pmimp q \pmimp r \pmdot\pmiddf \pmdot p \pmimp q \pmand q \pmimp r \pmdf & 
\end{flalign*}
\begin{description} %3.03
	\item[$\mathbf{\pmast3\pmcdot03}$.] Given two asserted elementary propositional functions ``$\pmthm \pmdot \phi p$ and ``$\pmthm \pmdot \psi p$" whose arguments are elementary propositions, we have ``$\pmthm \pmdot \phi p \pmand \psi p$.
\end{description}
\pmdemi
\begin{flalign*} %3.03
	&& &\pmthm \pmdot \pmast1\pmcdot7\pmcdot72 \pmand \pmast2\pmcdot11 \pmdot \pmithm \pmdott \pmnot \phi p \pmor \pmnot \psi p \pmdot \pmor \pmdot \pmnot(\pmnot \phi p \pmor \pmnot \psi p) & && (1) \\
	&& &\pmthm \pmdot (1) \pmand \pmast2\pmcdot32 \pmand (\pmast1\pmcdot01) \pmdot \pmithm \pmdottt \phi p \pmdot \pmimp \pmdott \psi p \pmdot \pmimp \pmdot \pmnot(\pmnot \phi p \pmor \pmnot \psi p) & && (2) \\
	&& &\pmthm \pmdot (2) \pmand (\pmast3\pmcdot03) \pmdot \pmithm \pmdottt \phi p \pmdot \pmimp \pmdott \psi p \pmdot \pmimp \pmdot \phi p \pmand \psi p & && (3) \\
	&& &\pmthm \pmdot (3) \pmand \pmast1\pmcdot11 \pmand (\pmast1\pmcdot01) \pmdot \pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} %3.1 %3.11 %3.12 %3.13 %3.14 %3.2 %3.21 %3.22
& \mathbf{\pmast3\pmcdot1}. \quad \pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot \pmnot(\pmnot p \pmor \pmnot q) & &[\text{Id} \pmand (\pmast3\pmcdot01)]& && \\
& \mathbf{\pmast3\pmcdot11}. \quad \pmthm \pmdott \pmnot(\pmnot p \pmor \pmnot q) \pmdot \pmimp \pmdot p \pmand q & &[\text{Id} \pmand (\pmast3\pmcdot01)]& && \\
& \mathbf{\pmast3\pmcdot12}. \quad \pmthm \pmdott \pmnot p \pmdot \pmor \pmdot \pmnot q \pmdot \pmor \pmdot p \pmand q & &\pmSub{\pmast2\pmcdot11}{\pmnot p \pmor \pmnot q}{p}& && \\
& \mathbf{\pmast3\pmcdot13}. \quad \pmthm \pmdott \pmnot(p \pmand q) \pmdot \pmimp \pmdot \pmnot p \pmor \pmnot q & &[\pmast3\pmcdot11 \pmand \text{Transp}]& && \\
& \mathbf{\pmast3\pmcdot14}. \quad \pmthm \pmdott \pmnot p \pmor \pmnot q \pmdot \pmimp \pmdot \pmnot(p \pmand q) & &[\pmast3\pmcdot1 \pmand \text{Transp}]& && \\
& \mathbf{\pmast3\pmcdot2}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdott q \pmdot \pmimp \pmdot p \pmand q & &[\pmast3\pmcdot12] && \\
& \mathbf{\pmast3\pmcdot21}. \quad \pmthm \pmdottt q \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot p \pmand q & &[\pmast3\pmcdot2 \pmand \text{Comm}]& && \\
& \mathbf{\pmast3\pmcdot22}. \quad \pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot q \pmand p & && && 
\end{flalign*}

This is one form of the commutative law for logical multiplication. A more complete form is given in $\pmast4\pmcdot3$.
\pmdemi
\begin{flalign*} %3.22
	&& &\pmSubb{\pmast3\pmcdot13}{q}{p}{p}{q} & \pmthm \pmdott \pmnot(q \pmand p) \pmdot \; &\pmimp \pmdot \pmnot q \pmor \pmnot p \pmdot & && \\
	&& &[\text{Perm}] & & \pmimp \pmdot \pmnot p \pmor \pmnot q \pmdot & && \\
	&& &[\pmast3\pmcdot14] & &\pmimp \pmdot \pmnot(p \pmand q) & && (1) \\
	&& &\pmthm \pmdot (1) \pmand \text{Transp} \pmdot \pmithm \pmdot \pmprop & && &&
\end{flalign*}

\pagefirst{117} Note that, in the above proof, ``(1)" stands for the proposition
\[
	\text{``}\pmnot(q \pmand p) \pmdot \pmimp \pmdot \pmnot(p \pmand q)\text{,"}
\]
as was explained in the proof of $\pmast2\pmcdot31$.
\begin{flalign*} %3.24
	&\mathbf{\pmast3\pmcdot24}. \quad \pmthm \pmdot \pmnot(p \pmand \pmnot p)&
\end{flalign*}
\pmdemi
\begin{flalign*} %3.24
	&& &\pmSub{\pmast2\pmcdot11}{\pmnot p}{p} & &\pmthm \pmdot \pmnot p \pmor \pmnot(\pmnot p) \pmdot \pmimp & && \\
	&& &\pmSub{\pmast3\pmcdot14}{\pmnot p}{q} & &\pmthm \pmdot \pmnot(p \pmand \pmnot p) & && 
\end{flalign*}

The above is the law of contradiction.
\begin{flalign*}
& \mathbf{\pmast3\pmcdot26}. \quad \pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot p & 
\end{flalign*}
\pmdemi
\begin{flalign*} %3.26
&& &\pmSubb{\pmast2\pmcdot02}{q}{p}{p}{q} & &\pmthm \pmdott p \pmdot \pmimp \pmdot q \pmimp p & && (1) \\
&& &[(1)\pmand(\pmast1\pmcdot01)] & & \pmthm \pmdott \pmnot p \pmdot \pmor \pmdot \pmnot q \pmor p \pmdott & && \\
&& &[\pmast2\pmcdot31] & \pmimp \; &\pmthm \pmdott  \pmnot p \pmor \pmnot q \pmdot \pmor \pmdot p \pmdott & && \\
&& &\pmSubb{\pmast2\pmcdot53}{\pmnot p \pmor \pmnot q}{p}{p}{q} & \pmimp \; &\pmthm \pmdott \pmnot(\pmnot p \pmor \pmnot q) \pmdot \pmimp \pmdot p & && (2) \\
&& &[(2)\pmand\pmast3\pmcdot01]  & &\pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot p& &&
\end{flalign*}
\begin{flalign*} %3.27
& \mathbf{\pmast3\pmcdot27}. \quad \pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot q & 
\end{flalign*}
\pmdemi
\begin{flalign*} %3.27
&& &[\pmast3\pmcdot22] & \pmthm \pmdott p \pmand q \pmdot \; &\pmimp \pmdot q \pmimp p & && \\
&& &\pmSubb{\pmast3\pmcdot26}{q}{p}{p}{q} & &\pmimp \pmdot q \pmdott \pmithm \pmdot \pmprop & && 
\end{flalign*}

$\pmast3\pmcdot26\pmcdot27$ will both be called the ``principle of simplification," like $\pmast2\pmcdot02$, from which they are deduced. They will be referred to as ``Simp."
\begin{flalign*} %3.3
& \mathbf{\pmast3\pmcdot3}. \quad \pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmimp r & 
\end{flalign*}
\pmdemi
\begin{flalign*} %3.3
&& &[\text{Id}\pmand(\pmast3\pmcdot01)] & \pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \; &\pmimp \pmdott \pmnot(\pmnot p \pmor \pmnot q) \pmdot \pmimp \pmdot r \pmdott & && \\
&& &[\text{Transp}] & &\pmimp \pmdott \pmnot r \pmdot \pmimp \pmdot \pmnot p \pmor \pmnot q \pmdott & && \\
&& &[\text{Id}\pmand(\pmast1\pmcdot01)] & &\pmimp \pmdott  \pmnot r \pmdot \pmimp \pmdot p \pmimp \pmnot q \pmdott & && \\
&& &[\text{Comm}]  & &\pmimp \pmdott p \pmdot \pmimp \pmdot \pmnot r \pmimp \pmnot q \pmdott & && \\
&& &[\text{Transp}\pmand\text{Syll}] & &\pmimp \pmdott p \pmdot \pmimp \pmdot q \pmimp r \pmdottt \pmithm \pmdot \pmprop & &&
\end{flalign*}
\begin{flalign*} %3.31
& \mathbf{\pmast3\pmcdot31}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r & 
\end{flalign*}
\pmdemi
\begin{flalign*} %3.31
&& &[\text{Id}\pmand(\pmast1\pmcdot01)] & \pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \; &\pmimp \pmdott \pmnot p \pmdot \pmor \pmdot \pmnot q \pmor r \pmdott & && \\
&& &[\pmast2\pmcdot31] & &\pmimp \pmdott \pmnot p \pmor \pmnot q \pmdot \pmor \pmdot r \pmdott & && \\
&& &\pmSubb{\pmast2\pmcdot53}{\pmnot p \pmor \pmnot q}{p}{r}{q}  & &\pmimp \pmdott \pmnot(\pmnot p \pmor \pmnot q) \pmdot \pmimp \pmdot r \pmdott & && \\
&& &[\text{Id}\pmand(\pmast3\pmcdot01)] & &\pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r \pmdottt \pmithm \pmdot \pmprop & &&
\end{flalign*}
\begin{flalign*} \pagefirst{118} %3.33
& \mathbf{\pmast3\pmcdot33}. \quad \pmthm \pmdott p \pmimp q \pmand q \pmimp r \pmdot \pmimp \pmdot p \pmimp r \quad [\text{Syll} \pmand \text{Imp}]& 
\end{flalign*}
\begin{flalign*} %3.34
& \mathbf{\pmast3\pmcdot34}. \quad \pmthm \pmdott q \pmimp r \pmand p \pmimp q \pmdot \pmimp \pmdot p \pmimp r \quad [\text{Syll} \pmand \text{Imp}]& 
\end{flalign*}

These two propositions will hereafter be referred to as ``Syll"; they are usually more convenient than either $\pmast2\pmcdot05$ or $\pmast2\pmcdot06$.
\begin{flalign*} %3.35
& \mathbf{\pmast3\pmcdot35}. \quad \pmthm \pmdott p \pmand p \pmimp q \pmdot \pmimp \pmdot q \quad [\pmast2\pmcdot27 \pmand \text{Imp}]& 
\end{flalign*}
\begin{flalign*} %3.37
& \mathbf{\pmast3\pmcdot37}. \quad \pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmimp \pmdott p \pmand \pmnot r \pmdot \pmimp \pmdot \pmnot q & 
\end{flalign*}
\pmdemi
\begin{flalign*} %3.37
&& &\pmthm \pmdot \text{Transp} \pmdot & &\pmithm \pmdott q \pmimp r \pmdot \pmimp \pmdot \pmnot r \pmimp \pmnot q \pmdott & && \\
&& &[\text{Syll}] & &\pmithm \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmimp \pmdott p \pmdot \pmimp \pmdot \pmnot r \pmnot q & && (1) \\
&& &\pmthm \pmdot \text{Exp} \pmdot & &\pmithm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmimp r & && (2) \\
&& &\pmthm \pmdot \text{Imp} \pmdot& &\pmithm \pmdottt p \pmdot \pmimp \pmdot \pmnot r \pmimp \pmnot q \pmdott \pmimp \pmdott p \pmand \pmnot r \pmdot \pmimp \pmdot \pmnot q & && (3) \\
&& &\pmthm \pmdot (2)\pmand(1)\pmand(3)\pmand\text{Syll} \pmdot & &\pmithm \pmdot \pmprop & && 
\end{flalign*}

This is another form of transposition.
\begin{flalign*} %3.4 %3.41 %3.42
	& \mathbf{\pmast3\pmcdot4}. \quad \pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot p \pmimp q & &[\pmast2\pmcdot51 \pmand \text{Transp} \pmand (\pmast1\pmcdot01) \pmand (\pmast3\pmcdot01)]&  \\
	& \mathbf{\pmast3\pmcdot41}. \quad \pmthm \pmdottt p \pmimp r \pmdot \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r & &[\pmast3\pmcdot26 \pmand \text{Syll}]&  \\
	& \mathbf{\pmast3\pmcdot42}. \quad \pmthm \pmdottt q \pmimp r \pmdot \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r & &[\pmast3\pmcdot267 \pmand \text{Syll}]& 
\end{flalign*}
\begin{flalign*} %3.43
& \mathbf{\pmast3\pmcdot43}. \quad \pmthm \pmdottt p \pmimp q \pmand p \pmimp r \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmand r & 
\end{flalign*}
\pmdemi
\begin{flalign*} %3.43
&& &\pmthm \pmdot \pmast3\pmcdot2 \pmdot & &\pmithm \pmdottt q \pmdot \pmimp \pmdott r \pmdot \pmimp \pmdot q \pmand r & && (1) \\
&& &\pmthm \pmdot (1) \pmand \text{Syll} \pmdot & &\pmithm \pmdotttt p \pmimp q \pmdot \pmimp \pmdottt p \pmdot \pmimp \pmdott r \pmdot \pmimp \pmdot q \pmand r \pmdottt & && \\
&& &[\pmast2\pmcdot77] & &\hspace{2.25cm} \pmimp \pmdottt p \pmimp r \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmand r  & && (2) \\
&& &\pmthm \pmdot (2) \pmand \text{Imp} \pmdot & &\pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} %3.44
	& \mathbf{\pmast3\pmcdot44}. \quad \pmthm \pmdottt p \pmimp q \pmand p \pmimp r \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmand r & 
\end{flalign*}

This principle is analogous to $\pmast3\pmcdot43$. The analogy between $\pmast3\pmcdot43$ and $\pmast3\pmcdot44$ is of a sort which generally subsists between formulae concerning products and formulae concerning sums.

\pmdemi
\begin{flalign*} %3.44
	&& &\pmthm \pmdot \text{Syll} \pmdot & &\pmithm \pmdottt \pmnot q \pmimp r \pmand r \pmimp p \pmdot \pmimp \pmdott \pmnot q \pmimp p \pmdott & && \\
	&& & [\pmast2\pmcdot6] & & \hspace{3.825cm} \pmimp \pmdott q \pmimp p \pmdot \pmimp \pmdot p & && (1) \\
	&& &\pmthm \pmdot (1) \pmand \text{Exp} \pmdot & &\pmithm \pmdotttt \pmnot q \pmimp r \pmdot \pmimp \pmdottt r \pmimp p \pmdot \pmimp \pmdott q \pmimp p \pmdot \pmimp \pmdot p \pmdottt & && \\
	&& & [\text{Comm} \pmand \text{Imp}] & & \hspace{2.575cm} \pmimp \pmdottt q \pmimp p \pmand r \pmimp p \pmdot \pmimp \pmdot p & && (2) \\
	&& &\pmthm \pmdot (2) \pmand \text{Comm} \pmdot & & \pmithm \pmdottt q \pmimp p \pmand r \pmimp p \pmdot \pmimp \pmdott \pmnot q \pmimp r \pmdot \pmimp \pmdot p \pmdottt  & && \\
	&& &[\pmast2\pmcdot53\pmand\text{Syll}] & &\pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} \pagefirst{119} %3.45
& \mathbf{\pmast3\pmcdot45}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdott p \pmand r \pmdot \pmimp \pmdot q \pmand r & 
\end{flalign*}

This principle shows that we may multiply both sides of an implication by a common factor; hence it is called by Peano the ``principle of the factor." We shall refer to it as ``Fact." It is the analogue, for multiplication, of the primitive proposition $\pmast1\pmcdot6$.

\pmdemi
\begin{flalign*} %3.45
	&& &\pmthm \pmdot \pmSUb{\text{Syll}}{\pmnot r}{r} \pmdot & &\pmithm \pmdottt p \pmimp q \pmdot \pmimp \pmdott q \pmimp \pmnot r \pmdot \pmimp \pmdot p \pmimp \pmnot r \pmdott & && \\
	&& & [\text{Transp}] & & \hspace{2.25cm} \pmimp \pmdott \pmnot(p \pmimp \pmnot r) \pmdot \pmimp \pmdot \pmnot(p \pmimp \pmnot r) \pmdottt & && \\
	&& &[\text{Id}\pmand(\pmast1\pmcdot01\pmand\pmast3\pmcdot01)] & &\pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} %3.47
& \mathbf{\pmast3\pmcdot47}. \quad \pmthm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r \pmand s & 
\end{flalign*}

This proposition, or rather its analogue for classes, was proved by Leibniz, and evidently pleased him, since he calls it ``pr{\ae}clarum theorema\footnote{\textit{Philosophical works}, Gerhardt's edition, Vol. VII. p. 223.}."

\pmdemi
\begin{flalign*} %3.47
	&& &\pmthm \pmdot \pmast3\pmcdot26 \pmdot & \pmithm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \; &\pmimp \pmdott p \pmimp r \pmdott & && \\
	&& & [\text{Fact}] & & \pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r \pmand q \pmdott & && \\
	&& &[\pmast3\pmcdot22] & &\pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot q \pmand r  & && (1) \\
	&& &\pmthm \pmdot \pmast3\pmcdot27 \pmdot & \pmithm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \; &\pmimp \pmdott q \pmimp s \pmdott & && \\
	&& & [\text{Fact}] & & \pmimp \pmdott q \pmand r \pmdot \pmimp \pmdot s \pmand r \pmdott & && \\
	&& &[\pmast3\pmcdot22] & &\pmimp \pmdott q \pmand r \pmdot \pmimp \pmdot r \pmand s  & && (2) \\
	&& &\pmthm\pmdot (1) \pmand (2) \pmand \pmast3\pmcdot03 \pmand \pmast2\pmcdot83 \pmdot & \pmithm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \; &\pmimp \pmdott p \pmand q \pmdot \pmimp \pmdot r \pmand s \pmdottt \pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} %3.48
& \mathbf{\pmast3\pmcdot48}. \quad \pmthm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot r \pmor s & 
\end{flalign*}

This theorem is the analogue of $\pmast3\pmcdot47$.

\pmdemi
\begin{flalign*} %3.48
&& &\pmthm \pmdot \pmast3\pmcdot26 \pmdot & \pmithm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \; &\pmimp \pmdott p \pmimp r \pmdott & && \\
&& & [\text{Sum}] & & \pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot r \pmor q \pmdott & && \\
&& &[\text{Perm}] & &\pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot q \pmor r  & && (1) \\
&& &\pmthm \pmdot \pmast3\pmcdot27 \pmdot & \pmithm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \; &\pmimp \pmdott q \pmimp s \pmdott & && \\
&& & [\text{Sum}] & & \pmimp \pmdott q \pmor r \pmdot \pmimp \pmdot s \pmor r \pmdott & && \\
&& &[\text{Perm}] & &\pmimp \pmdott q \pmor r \pmdot \pmimp \pmdot r \pmor s  & && (2) \\
&& &\pmthm\pmdot (1) \pmand (2) \pmand \pmast2\pmcdot83 \pmdot & \pmithm \pmdottt p \pmimp r \pmand q \pmimp s \pmdot \; &\pmimp \pmdott p \pmor q \pmdot \pmimp \pmdot r \pmor s \pmdottt \pmithm \pmdot \pmprop & && 
\end{flalign*}


\chapter*{\centering \pmast4. EQUIVALENCE AND FORMAL RULES.} \addcontentsline{toc}{chapter}{❋4. EQUIVALENCE AND FORMAL RULES.} \pagefirst{120} \noindent
\indent \textit{Summary of $\pmast$4.}

In this number, we shall be concerned with rules analogous, more or less, to those of ordinary algebra. It is from these rules that the usual ``calculus of formal logic" starts. Treated as a ``calculus," the rules of deduction are capable of many other interpretations. But all other interpretations depend upon the one here considered, since in all of them we deduce consequences from our rules, and thus presuppose the theory of deduction. One very simple interpretation of the ``calculus" is as follows: The entities considered are to be numbers which are all either 0 or 1; ``$p \pmimp q$" is to have the value 0 if $p$ is 1 and $q$ is 0; otherwise it is to have the value 1; ````$p$ is to be 1 if p is 0, and 0 if $p$ is 1; $p \pmand q$ is to be 1 if $p$ and $q$ are both 1, and is to be 0 in any other case; $p \pmor q$ is to be 0 if $p$ and $q$ are both 0, and is to be 1 in any other case; and the assertion-sign is to mean that what follows has the value 1. Symbolic logic considered as a calculus has undoubtedly much interest on its own account; but in our opinion this aspect has hitherto been too much emphasized, at the expense of the aspect in which symbolic logic is merely the most elementary part of mathematics, and the logical prerequisite of all the rest. For this reason, we shall only deal briefly with what is required for the algebra of symbolic logic.

When each of two propositions implies the other, we say that the two are equivalent, which we write ``$p \pmiff q$." We put
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot01}. \quad p \pmiff q \pmdot \pmiddf \pmdot p \pmimp q \pmand q \pmimp p \pmdf &
\end{flalign*}

It is obvious that two propositions are equivalent when, and only when, both are true or both are false. Following Frege, we shall call the \textit{truth-value of a proposition} truth if it is true, and falsehood if it is false. Thus two propositions are equivalent when they have the same truth-value.

It should be observed that, if $p \pmiff q$, $q$ may be substituted for $p$ without altering the truth-value of any function of $p$ which involves no primitive ideas except those enumerated in $\pmast1$. This can be proved in each separate case, but not generally, because we have no means of specifying (with our apparatus of primitive ideas) that a function is one which can be built up out \pagefirst{121} of these ideas alone. We shall give the name of a \textit{truth-function} to a function $f(p)$ whose argument is a proposition, and whose truth-value depends only upon the truth-value of its argument. All the functions of propositions with which we shall be specially concerned will be truth-functions, \textit{i.e.}\ we shall have
\[
	p \pmiff q \pmdot \pmimp \pmdot f(p) \pmiff f(q).
\]
The reason of this is, that the functions of propositions with which we deal are all built up by means of the primitive ideas of $\pmast1$. But it is not a universal characteristic of functions of propositions to be truth-functions. For example, ``$A$ believes $p$" may be true for one true value of $p$ and false for another.

The principal propositions of this number are the following:
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot1}.\;\; \quad \pmthm \pmdott p \pmimp q \pmdot \pmiff \pmdot \pmnot q \pmimp \pmnot p & \\
	& \mathbf{\pmast4\pmcdot11}. \quad \pmthm \pmdott p \pmiff q \pmdot \pmiff \pmdot \pmnot p \pmiff \pmnot q & 
\end{flalign*}

These are both forms of the ``principle of transposition."
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot13}. \quad \pmthm \pmdot p \pmiff \pmnot(\pmnot p) & 
\end{flalign*}

This is the principle of double negation, \textit{i.e.}\ a proposition is equivalent to the falsehood of its negation.
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot2}.\;\; \quad \pmthm \pmdot p \pmiff p & \\
	& \mathbf{\pmast4\pmcdot21}. \quad \pmthm \pmdott p \pmiff q \pmdot \pmiff \pmdot q \pmiff p & \\
	& \mathbf{\pmast4\pmcdot22}. \quad \pmthm \pmdott p \pmiff q \pmand q \pmiff r \pmdot \pmimp \pmdot p \pmiff r & 
\end{flalign*}

These propositions assert that equivalence is \textit{reflexive}, \textit{symmetrical} and \textit{transitive}.
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot24}. \quad \pmthm \pmdott p \pmdot \pmiff \pmdot p \pmand p & \\
	& \mathbf{\pmast4\pmcdot25}. \quad \pmthm \pmdott p  \pmdot \pmiff \pmdot p \pmor p & 
\end{flalign*}

\textit{I.e.}\ $p$ is equivalent to ``$p$ and $p$" and to ``$p$ or $p$," which are two forms of the \textit{law of tautology}, and are the source of the principal differences between the algebra of symbolic logic and ordinary algebra.
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot3}. \;\; \quad \pmthm \pmdott p \pmand q \pmdot \pmiff \pmdot q \pmand p & 
\end{flalign*}

This is the commutative law for the product of propositions.
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot31}. \quad \pmthm \pmdott p \pmor q \pmdot \pmiff \pmdot q \pmor p & 
\end{flalign*}

This is the commutative law for the sum of propositions.

The associative laws for multiplication and addition of propositions, namely
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot32}. \quad \pmthm \pmdott (p \pmand q) \pmand r \pmdot \pmiff \pmdot p \pmand (q \pmand r)  & \\
	& \mathbf{\pmast4\pmcdot33}. \quad \pmthm \pmdott (p \pmor q) \pmor r \pmdot \pmiff \pmdot p \pmor (q \pmor r)  & 
\end{flalign*}

The distributive law in the two forms
\begin{flalign*} \pagefirst{122}
	& \mathbf{\pmast4\pmcdot4}.\;\; \quad \pmthm \pmdottt p \pmand q \pmor r \pmdot \pmiff \pmdott p \pmand q \pmdot \pmor \pmdot p \pmand r  & \\
	& \mathbf{\pmast4\pmcdot41}. \quad \pmthm \pmdottt p \pmdot \pmor \pmdot q \pmand r \pmdott \pmiff \pmdot p \pmor q \pmand p \pmor r & 
\end{flalign*}

The second of these forms has no analogue in ordinary algebra.
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot71}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmiff \pmdott p \pmdot \pmiff \pmdot p \pmand q
\end{flalign*}

\textit{I.e.}\ $p$ implies $q$ when, and only when, $p$ is equivalent to $p \pmand q$. This proposition is used constantly; it enables us to replace any implication by an equivalence.
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot73}. \quad \pmthm \pmdottt q \pmdot \pmiff \pmdott p \pmdot \pmiff \pmdot p \pmand q
\end{flalign*}

\textit{I.e.}\ a true factor may be dropped from or added to a proposition without altering the truth-value of the proposition.
\pmfd
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot01}. \quad p \pmiff q \pmdot \pmiddf \pmdot p \pmimp q \pmand q \pmimp p \pmdf & \\
	& \mathbf{\pmast4\pmcdot02}. \quad p \pmiff q \pmiff r \pmdot \pmiddf \pmdot p \pmiff q \pmand q \pmiff r \pmdf & 
\end{flalign*}
This definition serves merely to provide a convenient abbreviation.

\begin{flalign*}
	& \mathbf{\pmast4\pmcdot1}.\;\; \quad \pmthm \pmdott p \pmimp q \pmdot \pmiff \pmdot \pmnot q \pmimp \pmnot p & &[\pmast2\pmcdot16\pmcdot17] &\\
	& \mathbf{\pmast4\pmcdot11}. \quad \pmthm \pmdott p \pmiff q \pmdot \pmiff \pmdot \pmnot p \pmiff \pmnot q & &[\pmast2\pmcdot16\pmcdot17 \pmand \pmast3\pmcdot47\pmcdot22] &\\
	& \mathbf{\pmast4\pmcdot12}. \quad \pmthm \pmdott p \pmiff \pmnot q \pmdot \pmiff \pmdot q \pmiff \pmnot p & &[\pmast2\pmcdot03\pmcdot15] &\\
	& \mathbf{\pmast4\pmcdot13}. \quad \pmthm \pmdot p \pmiff \pmnot(\pmnot p) & &[\pmast2\pmcdot12\pmcdot14] &\\
	& \mathbf{\pmast4\pmcdot14}. \quad \pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmiff \pmdott p \pmand \pmnot r \pmdot \pmimp \pmdot \pmnot q & &[\pmast3\pmcdot37 \pmand \pmast4\pmcdot13] &\\
	& \mathbf{\pmast4\pmcdot15}. \quad \pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot \pmnot r \pmdott \pmiff \pmdott q \pmand r \pmdot \pmimp \pmdot \pmnot p & &[\pmast3\pmcdot22 \pmand \pmast4\pmcdot13\pmcdot14] &\\
	& \mathbf{\pmast4\pmcdot2}.\;\; \quad \pmthm \pmdot p \pmiff p & &[\text{Id} \pmand \pmast3\pmcdot2] &\\
	& \mathbf{\pmast4\pmcdot21}. \quad \pmthm \pmdott p \pmiff q \pmdot \pmiff \pmdot q \pmiff p & &[\pmast3\pmcdot22] &\\
	& \mathbf{\pmast4\pmcdot22}. \quad \pmthm \pmdott p \pmiff q \pmand q \pmiff r \pmdot \pmimp \pmdot p \pmiff r & & &
\end{flalign*}
\pmdemi
\begin{flalign*}
	&& &\pmthm \pmdot \pmast3\pmcdot26 \pmdot & \pmithm \pmdott p \pmiff q \pmand q \pmiff r \pmdot\; &\pmimp \pmdot p \pmiff q \pmdot & && \\
	&& &[\pmast3\pmcdot26] & &\pmimp \pmdot p \pmimp q & && (1) \\
	&& &\pmthm \pmdot \pmast3\pmcdot27 \pmdot & \pmithm \pmdott p \pmiff q \pmand q \pmiff r \pmdot\; &\pmimp \pmdot q \pmiff r \pmdot & && \\
	&& &[\pmast3\pmcdot26] & &\pmimp \pmdot q \pmimp r & && (2) \\
	&& &\pmthm \pmdot (1) \pmand (2) \pmand \pmast2\pmcdot83 \pmdot & \pmithm \pmdott p \pmiff q \pmand q \pmiff r \pmdot\; &\pmimp \pmdot p \pmimp r & && (3) \\
	&& &\pmthm \pmdot \pmast3\pmcdot27 \pmdot & \pmithm \pmdott p \pmiff q \pmand q \pmiff r \pmdot\; &\pmimp \pmdot q \pmiff r \pmdot & && \\
	&& &[\pmast3\pmcdot27] & &\pmimp \pmdot r \pmimp q & && (4) \\
	&& &\pmthm \pmdot \pmast3\pmcdot26 \pmdot & \pmithm \pmdott p \pmiff q \pmand q \pmiff r \pmdot\; &\pmimp \pmdot p \pmiff q \pmdot & && \\
	&& &[\pmast3\pmcdot27] & &\pmimp \pmdot q \pmimp p & && (5) \\
	&& &\pmthm \pmdot (4) \pmand (5) \pmand \pmast2\pmcdot83 \pmdot & \pmithm \pmdott p \pmiff q \pmand q \pmiff r \pmdot\; &\pmimp \pmdot r \pmimp p & && (6) \\
	&& & \pmthm \pmdot (3) \pmand (6) \pmand \text{Comp} \pmdot & \pmithm \pmdot \pmprop \hspace{1.525cm} && &&
\end{flalign*}

\pagefirst{123} \textit{Note}. The above three propositions show that the relation of equivalence is reflexive ($\pmast4\pmcdot2$), symmetrical ($\pmast4\pmcdot21$), and transitive ($\pmast4\pmcdot22$). Implication is reflexive and transitive, but not symmetrical. The properties of being symmetrical, transitive, and (at least within a certain field) reflexive are essential to any relation which is to have the formal characters of equality.
\begin{flalign*} %4.24
	& \mathbf{\pmast4\pmcdot24}. \quad \pmthm \pmdott p \pmdot \pmiff \pmdot p \pmand p & 
\end{flalign*}
\pmdemi
\begin{flalign*}
	&& &\pmthm \pmdot \pmast3\pmcdot26 \pmdot & &\pmithm \pmdott p \pmand p \pmdot \pmimp \pmdot p& && (1) \\
	&& &\pmthm \pmdot \pmast3\pmcdot2 \pmdot & &\pmithm \pmdottt p \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot p \pmand p \pmdot {\pmdott} & && \\
	&& &[\pmast2\pmcdot43] \pmdot & &\pmithm \pmdott p \pmdot \pmimp \pmdot p \pmand p & && (2) \\
	&& &\pmthm \pmdot (1) \pmand (2) \pmand \pmast3\pmcdot2 \pmdot & &\pmithm \pmdot \pmprop& && \\
\end{flalign*}
\begin{flalign*} %4.25
	& \mathbf{\pmast4\pmcdot25}. \quad \pmthm \pmdott p  \pmdot \pmiff \pmdot p \pmor p \quad \pmbr{\text{Taut} \pmand \pmSUb{\text{Add}}{p}{q}} & 
\end{flalign*}

\textit{Note}. $\pmast4\pmcdot24\pmcdot25$ are two forms of the \textit{law of tautology}, which is what chiefly distinguishes the algebra of symbolic logic from ordinary algebra.
\begin{flalign*} %4.3
	& \mathbf{\pmast4\pmcdot3}. \;\; \quad \pmthm \pmdott p \pmand q \pmdot \pmiff \pmdot q \pmand p \quad [\pmast3\pmcdot22] & 
\end{flalign*}

\textit{Note}. Whenever we have, whatever values $p$ and $q$ may have,
\[
	\phi(p, q) \pmdot \pmimp \pmdot \phi(q, p), 
\]
we have also
\[
\phi(p, q) \pmdot \pmiff \pmdot \phi(q, p).
\]
\begin{flalign*}
	&\text{For}& && &\{\phi(p,q) \pmdot \pmimp \pmdot \phi(q, p)\}\pmsUbb{q}{p}{p}{q} \pmdot \pmimp \pmdott \phi(q, p) \pmdot \pmimp \pmdot \phi(p,q).& &&
\end{flalign*}
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot31}. \quad \pmthm \pmdott p \pmor q \pmdot \pmiff \pmdot q \pmor p \quad [\text{Perm}] & \\
	& \mathbf{\pmast4\pmcdot32}. \quad \pmthm \pmdott (p \pmand q) \pmand r \pmdot \pmiff \pmdot p \pmand (q \pmand r)  & 
\end{flalign*}
\pmdemi
\begin{flalign*}
	&& &\pmthm \pmdot \pmast4\pmcdot15 \pmdot & \pmithm \pmdottt p \pmand q \pmdot \pmimp \pmdot \pmnot r \pmdott\; &\pmiff \pmdott q \pmand r \pmdot \pmimp \pmdot \pmnot p \pmdott & && \\
	&& &[\pmast4\pmcdot12] & &\pmiff \pmdott p \pmdot \pmimp \pmdot \pmnot(q \pmand r) & && (1) \\
	&& &\pmthm \pmdot (1) \pmand \pmast4\pmcdot11 \pmdot & \pmithm \pmdott \pmnot(p \pmand q \pmdot \pmimp \pmdot \pmnot r) \pmdot\; &\pmiff \pmdot \pmnot\{p \pmdot \pmimp \pmdot \pmnot(q \pmand r)\} \pmdott & && \\
	&& &[(\pmast1\pmcdot01 \pmand \pmast3\pmcdot01)] & \pmithm \pmdot \pmprop \hspace{2.25cm} && &&
\end{flalign*}

\textit{Note}. Here ``(1)" stands for ``$\pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmiff \pmdott p \pmdot \pmimp \pmdot \pmnot(q \pmand r)$," which is obtained from the above steps by $\pmast4\pmcdot22$. The use of $\pmast4\pmcdot22$ will often be tacit, as above. The principle is the same as that explained in respect of implication in $\pmast2\pmcdot31$.
\begin{flalign*}
	& \mathbf{\pmast4\pmcdot33}. \quad \pmthm \pmdott (p \pmor q) \pmor r \pmdot \pmiff \pmdot p \pmor (q \pmor r)  & 
\end{flalign*}

The above are the associative laws for multiplication and addition. To avoid brackets, we introduce the following definition:
\begin{flalign*} \pagefirst{124} %4.34 %4.36 %4.37 %4.38 %4.39 %4.4
	& \mathbf{\pmast4\pmcdot34}. \quad p \pmand q \pmand r \pmdot \pmiddf \pmdot (p \pmand q) \pmand r \pmdf & & & \\
	& \mathbf{\pmast4\pmcdot36}. \quad \pmthm \pmdottt p \pmiff q \pmdot \pmimp \pmdott p \pmand r \pmdot \pmiff \pmdot q \pmand r & &[\text{Fact}\pmand\pmast3\pmcdot47] &\\
	& \mathbf{\pmast4\pmcdot37}. \quad \pmthm \pmdottt p \pmiff q \pmdot \pmimp \pmdott p \pmor r \pmdot \pmiff \pmdot q \pmor r & &[\text{Sum}\pmand\pmast3\pmcdot47] &\\
	& \mathbf{\pmast4\pmcdot38}. \quad \pmthm \pmdottt p \pmiff r \pmand q \pmiff s \pmdot \pmimp \pmdott p \pmand q \pmdot \pmiff \pmdot r \pmand s & &[\pmast3\pmcdot47\pmand\pmast4\pmcdot32\pmand\pmast3\pmcdot22] &\\
	& \mathbf{\pmast4\pmcdot39}. \quad \pmthm \pmdottt p \pmiff r \pmand q \pmiff s \pmdot \pmimp \pmdott p \pmor q \pmdot \pmiff \pmdot r \pmor s & &[\pmast3\pmcdot48\pmcdot47\pmand\pmast4\pmcdot32\pmand\pmast3\pmcdot22] &\\
	& \mathbf{\pmast4\pmcdot4}. \quad \pmthm \pmdottt p \pmand q \pmor r \pmdot \pmiff \pmdott p \pmand q \pmdot \pmor \pmdot p \pmand r & &&
\end{flalign*}

This is the first form of the distributive law.

\pmdemi
\begin{flalign*} %4.4
	&& &\pmthm \pmdot \pmast3\pmcdot2 \pmdot & &\pmithm \pmdotttt p \pmdot \pmimp \pmdott q \pmdot \pmimp p \pmand q \pmanddd p \pmdot \pmimp \pmdott r \pmdot \pmimp \pmdot p \pmand r \pmdotttt & && \\
	&& &[\text{Comp}] & &\pmithm \pmdotttt p \pmdot \pmimp \pmdottt q \pmdot \pmimp \pmdot p \pmand p \pmandd r \pmdot \pmimp \pmdot p \pmand r \pmdottt & && \\
	&& &[\pmast3\pmcdot48]  & & \hspace{1.5cm} \pmimp \pmdottt q \pmor r \pmdot \pmimp \pmdott p \pmand q \pmdot \pmor \pmdot p \pmand r & && (1) \\
	&& &\pmthm \pmdot (1) \pmand \text{Imp} \pmdot & &\pmithm \pmdottt p \pmand q \pmor r \pmdot \pmimp \pmdott p \pmand q \pmdot \pmor \pmdot p \pmand r & && (2) \\
	&& &\pmthm \pmdot \pmast3\pmcdot26 \pmdot & &\pmithm \pmdottt p \pmand q \pmdot \pmimp \pmdot p \pmandd p \pmand r \pmdot \pmimp \pmdot p \pmdottt & && \\
	&& & [\pmast3\pmcdot44]  & &\pmithm \pmdottt p \pmand q \pmdot \pmor \pmdot p \pmand r \pmdott \pmimp \pmdot p & && (3) \\
	&& &\pmthm \pmdot \pmast3\pmcdot27 \pmdot & &\pmithm \pmdottt p \pmand q \pmdot \pmimp \pmdot q \pmandd p \pmand r \pmdot \pmimp \pmdot p \pmdottt & && \\
	&& & [\pmast3\pmcdot48]  & &\pmithm \pmdottt p \pmand q \pmdot \pmor \pmdot p \pmand r \pmdott \pmimp \pmdot q \pmor r & && (4) \\
	&& & \pmthm \pmdot (3) \pmand (4) \pmand \text{Comp} \pmdot & &\pmithm \pmdottt p \pmand q \pmdot \pmor \pmdot p \pmand r \pmdott \pmimp \pmdot p \pmand q \pmor r & && (5) \\
	&& &\pmthm \pmdot (2) \pmand (5) \pmdot & &\pmithm \pmdot \pmprop& && 
\end{flalign*}
\begin{flalign*}%4.41
	& \mathbf{\pmast4\pmcdot41}. \quad \pmthm \pmdottt p \pmor q \pmand r \pmdott \pmiff \pmdot p \pmor q \pmand p \pmor r &
\end{flalign*}

This is a second form of the distributive law---a form to which there is nothing analogous in ordinary algebra. By conventions as to dots, ``$p \pmdot \pmor \pmdot q \pmand r$" means ``$p \pmor (q \pmand r)$."

\pmdemi
\begin{flalign*} %4.41
&& &\pmthm \pmdot \pmast3\pmcdot26 \pmand \text{Sum} \pmdot & &\pmithm \pmdottt p \pmdot \pmor \pmdot q \pmand r \pmdott \pmimp \pmdot p \pmor q & && (1) \\
&& &\pmthm \pmdot \pmast3\pmcdot27 \pmand \text{Sum} \pmdot & &\pmithm \pmdottt p \pmdot \pmor \pmdot q \pmand r \pmdott \pmimp \pmdot p \pmor r & && (2) \\
&& &\pmthm \pmdot (1) \pmand (2) \pmand \text{Comm} \pmdot & &\pmithm \pmdottt p \pmdot \pmor \pmdot q \pmand r \pmdott \pmimp \pmdot p \pmor q \pmand p \pmor r & && (3) \\
&& & \pmthm \pmdot \pmast2\pmcdot53 \pmand \pmast3\pmcdot47 \pmdot  & &\pmithm \pmdottt p \pmor q \pmand p \pmor r \pmdot \pmimp \pmdott \pmnot p \pmimp q \pmand \pmnot p \pmimp r \pmdott & && \\
&& & [\text{Comm}] & &\hspace{3.4cm}\pmimp \pmdott \pmnot p \pmdot \pmimp \pmdot q \pmand r \pmdott & && \\
&& & [\pmast2\pmcdot54]  & &\hspace{3.4cm}\pmimp \pmdott p \pmdot \pmor \pmdot q \pmand r & && (4) \\
&& &\pmthm \pmdot (3) \pmand (4) \pmdot & &\pmithm \pmdot \pmprop& && 
\end{flalign*}
\begin{flalign*}%4.42
& \mathbf{\pmast4\pmcdot42}. \quad \pmthm \pmdottt p \pmdot \pmiff \pmdott p \pmand q \pmdot \pmor \pmdot p \pmand \pmnot q &
\end{flalign*}
\pmdemi
\begin{flalign*} %4.42
&& &\pmthm \pmdot \pmast3\pmcdot21 \pmdot & &\pmithm \pmdottt q \pmor \pmnot q \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot p \pmand q \pmor \pmnot q \pmdottt & && \\
&& &[\pmast2\pmcdot11]  & & \pmithm \pmdott p \pmdot \pmimp \pmdot p \pmand q \pmor \pmnot q & && (1) \\
&& &\pmthm \pmdot \pmast3\pmcdot26\pmdot & &\pmithm \pmdott p \pmand q \pmor \pmnot q \pmdot \pmimp \pmdot p  & && (2) \\
&& &\pmthm \pmdot (1) \pmand (2) \pmdot & &\pmithm \pmdottt p \pmdot \pmiff \pmdott p \pmand q \pmor \pmnot q \pmdott & && \\
&& &[\pmast4\pmcdot4]  & &\hspace{1.5cm} \pmiff \pmdott p \pmand q \pmdot \pmor \pmdot p \pmand \pmnot q \pmdottt \pmithm \pmdot \pmprop& && 
\end{flalign*}
\begin{flalign*} \pagefirst{125} %4.43
& \mathbf{\pmast4\pmcdot43}. \quad \pmthm \pmdottt p \pmdot \pmiff \pmdott p \pmor q \pmand p \pmor \pmnot q &
\end{flalign*}
\pmdemi
\begin{flalign*} %4.43
&& &\pmthm \pmdot \pmast2\pmcdot2 \pmdot & &\pmithm \pmdott p \pmdot \pmimp \pmdot p \pmor q \pmandd p \pmdot \pmimp \pmdot p \pmor \pmnot q \pmdott & && \\
&& &[\text{Comp}] & &\pmithm \pmdott p \pmdot \pmimp \pmdot p \pmor q \pmand p \pmor \pmnot q & && (1) \\
&& &\pmthm \pmdot \pmSUb{\pmast2\pmcdot65}{\pmnot p}{p} \pmdot & &\pmithm \pmdottt \pmnot p \pmimp q \pmdot \pmor \pmdott \pmnot p \pmimp \pmnot q \pmdot \pmimp \pmdot p \pmdottt & && \\
&& &[\text{Imp}] & &\pmithm \pmdottt \pmnot p \pmimp q \pmand \pmnot p \pmimp \pmnot q \pmdot \pmimp \pmdot p \pmdottt & && \\
&& & [\pmast2\pmcdot53 \pmand \pmast3\pmcdot47] \pmdot  & &\pmithm \pmdottt p \pmor q \pmand p \pmor \pmnot q \pmdot \pmimp \pmdot p & && (2) \\\
&& &\pmthm \pmdot (1) \pmand (2) \pmdot & &\pmithm \pmdot \pmprop& && 
\end{flalign*}
\begin{flalign*}%4.44
& \mathbf{\pmast4\pmcdot44}. \quad \pmthm \pmdottt p \pmdot \pmiff \pmdott p \pmdot \pmor \pmdot p \pmand q &
\end{flalign*}
\pmdemi
\begin{flalign*} %4.44
&& &\pmthm \pmdot \pmast2\pmcdot2 \pmdot & &\pmithm \pmdottt p \pmdot \pmimp \pmdottt p \pmdot \pmor \pmdot p \pmand q & && (1) \\
&& &\pmthm \pmdot \text{Id} \pmand \pmast3\pmcdot26\pmdot & &\pmithm \pmdott p \pmimp p \pmandd p \pmand q \pmdot \pmimp \pmdot p \pmdottt & && \\
&& &[\pmast3\pmcdot44]  & &\pmithm \pmdottt p \pmdot \pmor \pmdot p \pmand q \pmdott \pmimp \pmdot p & && (2) \\
&& &\pmthm \pmdot (1) \pmand (2) \pmdot & &\pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*}%4.45
& \mathbf{\pmast4\pmcdot45}. \quad \pmthm \pmdott p \pmdot \pmiff \pmdot p \pmand p \pmor q \quad [\pmast3\pmcdot26 \pmand \pmast2\pmcdot2]&
\end{flalign*}

The following formulae are due to De Morgan, or rather, are the propositional analogues of formulae given by De Morgan for classes. The first of them, it will be observed, merely embodies our definition of the logical product.
\begin{flalign*} %4.5 %4.51 %4.52 %4.53 %4.54 %4.55 %4.56 %4.57 
	& \mathbf{\pmast4\pmcdot5}. \quad \;\; \pmthm \pmdott & p \pmand q \pmdot \;&\pmiff \pmdot \pmnot(\pmnot p \pmor \pmnot q) & &[\pmast4\pmcdot2 \pmand (\pmast3\pmcdot01)] &\\
	& \mathbf{\pmast4\pmcdot51}. \quad \pmthm \pmdott & \pmnot(p \pmand q) \pmdot \;&\pmiff \pmdot \pmnot p \pmor \pmnot q & &[\pmast4\pmcdot5\pmcdot12] &\\
	& \mathbf{\pmast4\pmcdot52}. \quad \pmthm \pmdott & p \pmand \pmnot q \pmdot \;&\pmiff \pmdot \pmnot(\pmnot p \pmor q) & &\pmbr{\pmSUb{\pmast4\pmcdot5}{\pmnot q}{q} \pmand \pmast4\pmcdot13} &\\
	& \mathbf{\pmast4\pmcdot53}. \quad \pmthm \pmdott & \pmnot(p \pmand \pmnot q) \pmdot \;&\pmiff \pmdot \pmnot p \pmor q & &[\pmast4\pmcdot52\pmcdot12] &\\
	& \mathbf{\pmast4\pmcdot54}. \quad \pmthm \pmdott &  \pmnot p \pmand q \pmdot \;&\pmiff \pmdot \pmnot(p \pmor \pmnot q) & &\pmbr{\pmSUb{\pmast4\pmcdot5}{\pmnot p}{p} \pmand \pmast4\pmcdot13} &\\
	& \mathbf{\pmast4\pmcdot55}. \quad \pmthm \pmdott & \pmnot(\pmnot p \pmand  q) \pmdot \;&\pmiff \pmdot p \pmor \pmnot q & &[\pmast4\pmcdot54\pmcdot12] &\\
	& \mathbf{\pmast4\pmcdot56}. \quad \pmthm \pmdott & \pmnot p \pmand \pmnot q \pmdot \;&\pmiff \pmdot \pmnot(p \pmor q) & &\pmbr{\pmSUb{\pmast4\pmcdot54}{\pmnot q}{q} \pmand \pmast4\pmcdot13} &\\
	& \mathbf{\pmast4\pmcdot57}. \quad \pmthm \pmdott & \pmnot(\pmnot p \pmand \pmnot q) \pmdot \;&\pmiff \pmdot p \pmor q & &[\pmast4\pmcdot56\pmcdot12] &
\end{flalign*}

The following formulae are obtained immediately from the above. They are important as showing how to transform implications into sums or into denials of products, and vice versa. It will be observed that the first of them merely embodies the definition $\pmast1\pmcdot01$.
\begin{flalign*} \pagefirst{126} %4.6 %4.61 %4.62 %4.63 %4.64 %4.65 %4.66 %4.67 
	& \mathbf{\pmast4\pmcdot6}. \quad \;\; \pmthm \pmdott & p \pmimp q \pmdot \;&\pmiff \pmdot \pmnot p \pmor q & &[\pmast4\pmcdot2 \pmand (\pmast1\pmcdot01)] &\\
	& \mathbf{\pmast4\pmcdot61}. \quad \pmthm \pmdott & \pmnot(p \pmimp q) \pmdot \;&\pmiff \pmdot p \pmand \pmnot q & &[\pmast4\pmcdot6\pmcdot11\pmcdot52] &\\
	& \mathbf{\pmast4\pmcdot62}. \quad \pmthm \pmdott & p \pmimp \pmnot q \pmdot \;&\pmiff \pmdot \pmnot p \pmor \pmnot q & &\pmSub{\pmast4\pmcdot6}{\pmnot q}{q} &\\
	& \mathbf{\pmast4\pmcdot63}. \quad \pmthm \pmdott & \pmnot(p \pmimp \pmnot q) \pmdot \;&\pmiff \pmdot p \pmand q & &[\pmast4\pmcdot62\pmcdot11\pmcdot5] &\\
	& \mathbf{\pmast4\pmcdot64}. \quad \pmthm \pmdott &  \pmnot p \pmimp q \pmdot \;&\pmiff \pmdot p \pmor q & &[\pmast2\pmcdot53\pmcdot54]  &\\
	& \mathbf{\pmast4\pmcdot65}. \quad \pmthm \pmdott & \pmnot(\pmnot p \pmimp  q) \pmdot \;&\pmiff \pmdot \pmnot p \pmand \pmnot q & &[\pmast4\pmcdot64\pmcdot11\pmcdot56] &\\
	& \mathbf{\pmast4\pmcdot66}. \quad \pmthm \pmdott & \pmnot p \pmimp \pmnot q \pmdot \;&\pmiff \pmdot p \pmor \pmnot q & &\pmSub{\pmast4\pmcdot64}{\pmnot q}{q} &\\
	& \mathbf{\pmast4\pmcdot67}. \quad \pmthm \pmdott & \pmnot(\pmnot p \pmimp \pmnot q) \pmdot \;&\pmiff \pmdot \pmnot p \pmand q & &[\pmast4\pmcdot66\pmcdot11\pmcdot54]  &
\end{flalign*}
\begin{flalign*}%4.7
	& \mathbf{\pmast4\pmcdot7}. \;\;\quad \pmthm \pmdottt p \pmimp q \pmdot \pmiff \pmdott p \pmdot \pmimp \pmdot p \pmand q &
\end{flalign*}
\pmdemi
\begin{flalign*} %4.7
&& &\pmthm \pmdot \pmast3\pmcdot27 \pmand \text{Syll} \pmdot & &\pmithm \pmdottt p \pmdot \pmimp \pmdot p \pmand q \pmdott \pmimp \pmdot p \pmimp q & && (1) \\
&& &\pmthm \pmdot \text{Comp} \pmdot & &\pmithm \pmdottt p \pmimp p \pmand p \pmimp q \pmdot \pmimp \pmdott p \pmand q \pmdottt & && \\
&& &[\text{Exp}]  & &\pmithm \pmdotttt p \pmimp p \pmdot \pmimp \pmdottt p \pmimp q \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot p \pmand q \pmdotttt & && \\
&& & [\text{Id}] & &\pmithm \pmdottt p \pmimp q \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot p \pmand q & && (2) \\
&& &\pmthm \pmdot (1) \pmand (2) \pmdot & &\pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*}%4.71
& \mathbf{\pmast4\pmcdot71}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmiff \pmdott p \pmdot \pmiff \pmdot p \pmand q &
\end{flalign*}
\pmdemi
\begin{flalign*} %4.71
&& &\pmthm \pmdot \pmast3\pmcdot21 \pmdot & &\pmithm \pmdotttt p \pmand q \pmdot \pmimp \pmdot p \pmdott \pmimp \pmdottt p \pmand q \pmdott \pmimp \pmdott p \pmdot \pmiff \pmdot p \pmand q \pmdotttt & && \\
&& &[\pmast3\pmcdot26] & &\pmithm \pmdottt p \pmdot \pmimp \pmdot p \pmand q \pmdott \pmimp \pmdott p \pmdot \pmiff \pmdot p \pmand q & && (1) \\
&& &\pmthm \pmdot \pmast3\pmcdot26 \pmdot & &\pmithm \pmdottt p \pmdot \pmiff \pmdot p \pmand q \pmdott \pmimp \pmdott p \pmdot \pmimp \pmdot p \pmand q & && (2) \\
&& &\pmthm \pmdot (1) \pmand (2) \pmdot & &\pmithm \pmdottt p \pmdot \pmimp \pmdot p \pmand q \pmdott \pmiff \pmdott p \pmdot \pmiff \pmdot p \pmand q & && (3) \\
&& &\pmthm \pmdot (3) \pmand \pmast4\pmcdot7\pmcdot22 \pmdot & &\pmithm \pmdot \pmprop & && 
\end{flalign*}

The above proposition is constantly used. It enables us to transform every implication into an equivalence, which is an advantage if we wish to assimilate symbolic logic as far as possible to ordinary algebra. But when symbolic logic is regarded as an instrument of proof, we need implications, and it is usually inconvenient to substitute equivalences. Similar remarks apply to the following proposition.
\begin{flalign*}%4.72
& \mathbf{\pmast4\pmcdot72}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmiff \pmdott q \pmdot \pmiff \pmdot p \pmor q &
\end{flalign*}
\pmdemi
\begin{flalign*} %4.72
&& &\pmthm \pmdot \pmast4\pmcdot1 \pmdot & \pmithm \pmdottt p \pmimp q \pmdot \;&\pmiff \pmdott \pmnot q \pmimp \pmnot p \pmdott & && \\
&& & \pmSubb{\pmast4\pmcdot71}{\pmnot q}{p}{\pmnot p}{q} & &\pmiff \pmdott \pmnot q \pmdot \pmiff \pmdot \pmnot q \pmand \pmnot p \pmdott & && \\
&& &[\pmast4\pmcdot12]  & &\pmiff \pmdott \pmnot q \pmdot \pmiff \pmdot \pmnot(\pmnot q \pmand \pmnot p) \pmdott & && \\
&& &[\pmast4\pmcdot57]  & &\pmiff \pmdott \pmnot q \pmdot \pmiff \pmdot q \pmor p \pmdott & && \\
&& &[\pmast4\pmcdot31]  & &\pmiff \pmdott \pmnot q \pmdot \pmiff \pmdot p \pmor q \pmdottt \pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} \pagefirst{127} %4.73
& \mathbf{\pmast4\pmcdot73}. \quad \pmthm \pmdottt q \pmdot \pmimp \pmdott p \pmdot \pmiff \pmdot p \pmand q \quad [\text{Simp}\pmand \pmast4\pmcdot71] &
\end{flalign*}

This proposition is very useful, since it shows that a true factor may be omitted from a product without altering its truth or falsehood, just as a true hypothesis may be omitted from an implication.
\begin{flalign*} %4.74 %4.76 %4.77
	& \mathbf{\pmast4\pmcdot74}. \quad \pmthm \pmdottt \pmnot p \pmdot \pmimp \pmdott q \pmdot \pmiff \pmdot p \pmor q & & [\pmast2\pmcdot21 \pmand \pmast4\pmcdot72] & \\
	& \mathbf{\pmast4\pmcdot76}. \quad \pmthm \pmdottt p \pmimp q \pmand p \pmimp r \pmdot \pmiff \pmdott p \pmdot \pmimp \pmdot q \pmand r & & \pmbr{\pmSUb{\pmast4\pmcdot41}{\pmnot p}{p} \pmand (\pmast1\pmcdot01)} & \\
	& \mathbf{\pmast4\pmcdot77}. \quad \pmthm \pmdottt q \pmimp p \pmand r \pmimp p \pmdot \pmiff \pmdott q \pmor r \pmdot \pmimp \pmdot p  & & [\pmast3\pmcdot44 \pmand \text{Add} \pmand \pmast2\pmcdot2] & 
\end{flalign*}
\begin{flalign*} %4.78
	& \mathbf{\pmast4\pmcdot78}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmor \pmdot p \pmimp r \pmdott \pmiff \pmdott p \pmdot \pmimp \pmdot q \pmor r & 
\end{flalign*}
\pmdemi
\begin{flalign*} %4.78
&& &\pmthm \pmdot \pmast4\pmcdot2 \pmand (\pmast1\pmcdot01) \pmdot & \pmithm \pmdottt p \pmimp q \pmdot \pmor \pmdot p \pmimp r \pmdott \;&\pmiff \pmdott \pmnot p \pmor q \pmdot \pmor \pmdot \pmnot p \pmor r \pmdott & && \\
&& & [\pmast4\pmcdot33] & &\pmiff \pmdot \pmnot p \pmdot \pmor \pmdot q \pmor \pmnot p \pmor r \pmdott & && \\
&& &[\pmast4\pmcdot31\pmcdot37]  & &\pmiff \pmdott \pmnot p \pmdot \pmor \pmdot \pmnot p \pmor q \pmor r \pmdott & && \\
&& &[\pmast4\pmcdot33]  & &\pmiff \pmdott \pmnot p \pmor \pmnot p \pmdot \pmor \pmdot q \pmor r \pmdott & && \\
&& &[\pmast4\pmcdot25\pmcdot37]  & &\pmiff \pmdott \pmnot p \pmdot \pmor \pmdot q \pmor r \pmdott & && \\
&& &[\pmast4\pmcdot2 \pmand (\pmast1\pmcdot01)]  & &\pmiff \pmdott p \pmdot \pmimp \pmdot q \pmor r \pmdottt \pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} %4.79
& \mathbf{\pmast4\pmcdot79}. \quad \pmthm \pmdottt q \pmimp p \pmdot \pmor \pmdot r \pmimp p \pmdott \pmiff \pmdott q \pmand r \pmdot \pmimp \pmdot p & 
\end{flalign*}
\pmdemi
\begin{flalign*} %4.79
&& &\pmthm \pmdot \pmast4\pmcdot1\pmcdot39 \pmdot & \pmithm \pmdottt q \pmimp p \pmdot \pmor \pmdot r \pmimp p \pmdott \;&\pmiff \pmdott \pmnot p \pmimp \pmnot q \pmdot \pmor \pmdot \pmnot p \pmimp \pmnot r \pmdott & && \\
&& & [\pmast4\pmcdot78] & &\pmiff \pmdot \pmnot p \pmdot \pmimp \pmdot \pmnot q \pmor \pmnot r \pmdott & && \\
&& &[\pmast2\pmcdot15]  & &\pmiff \pmdott \pmnot(\pmnot q \pmor \pmnot r) \pmdot \pmimp \pmdot p \pmdott & && \\
&& &[\pmast4\pmcdot33]  & &\pmiff \pmdott \pmnot p \pmor \pmnot p \pmdot \pmor \pmdot q \pmor r \pmdott & && \\
&& &[\pmast4\pmcdot2 \pmand (\pmast3\pmcdot01)]  & &\pmiff \pmdott q \pmand r \pmdot \pmimp \pmdot p\pmdottt \pmithm \pmdot \pmprop & && 
\end{flalign*}

Note. The analogues, for classes, of $\pmast4\pmcdot78\pmcdot79$ are false. Take, \textit{e.g.}\ $\pmast4\pmcdot78$, and put $p = \text{English people}$, $q = \text{men}$, $r = \text{women}$. Then $p$ is contained in $q$ or $r$, but is not contained in $q$ and is not contained in $r$.
\begin{flalign*}  %4.8 %4.81 %4.82 %4.83
	& \mathbf{\pmast4\pmcdot8}.\;\; \quad \pmthm \pmdott p \pmimp \pmnot p \pmdot \pmiff \pmdot \pmnot p  & &[\pmast2\pmcdot01\pmand\text{Simp}] &\\
	& \mathbf{\pmast4\pmcdot81}. \quad \pmthm \pmdott \pmnot p \pmimp p \pmdot \pmiff \pmdot p & &[\pmast2\pmcdot18\pmand\text{Simp}] &\\
	& \mathbf{\pmast4\pmcdot82}. \quad \pmthm \pmdott p \pmimp q \pmand p \pmimp \pmnot q \pmdot \pmiff \pmdot \pmnot p & &[\pmast2\pmcdot65\pmand\text{Imp} \pmand \pmast2\pmcdot21 \pmand \text{Comp}] &\\
	& \mathbf{\pmast4\pmcdot83}. \quad \pmthm \pmdott p \pmimp q \pmand \pmnot p \pmimp q \pmdot \pmiff \pmdot q & &[\pmast2\pmcdot61\pmand\text{Imp} \pmand \text{Simp} \pmand \text{Comp}] &
\end{flalign*}

Note. $\pmast4\pmcdot82\pmcdot83$ may also be obtained from $\pmast4\pmcdot83$, of which they are virtually other forms.
\begin{flalign*} %4.84 %4.85 %4.86 %4.87
	& \mathbf{\pmast4\pmcdot84}. \quad \pmthm \pmdottt p \pmiff q \pmdot \pmimp \pmdott p \pmimp r \pmdot \pmiff \pmdot q \pmimp r & &[\pmast2\pmcdot06\pmand\pmast3\pmcdot47] &\\
	& \mathbf{\pmast4\pmcdot85}. \quad \pmthm \pmdottt p \pmiff q \pmdot \pmimp \pmdott r \pmimp p \pmdot \pmiff \pmdot r \pmimp q & &[\pmast2\pmcdot05\pmand\pmast3\pmcdot47] &\\
	& \mathbf{\pmast4\pmcdot86}. \quad \pmthm \pmdottt p \pmiff q \pmdot \pmimp \pmdott p \pmiff r \pmdot \pmiff \pmdot q \pmiff r & &[\pmast4\pmcdot21\pmcdot22] &\\
	& \mathbf{\pmast4\pmcdot87}. \quad \pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmiff \pmdott p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmiff \pmdott q \pmdot \pmimp \pmdot p \pmimp r \pmdott \pmiff \pmdott q \pmand p \pmdot \pmimp \pmdot r & &[\text{Exp} \pmand \text{Comm} \pmand \text{Imp}] &
\end{flalign*}

$\pmast4\pmcdot87$ embodies in one proposition the principles of exportation and importation and the commutative principle.

\chapter*{\centering \pmast5. MISCELLANEOUS PROPOSITIONS.} \addcontentsline{toc}{chapter}{❋5. MISCELLANEOUS PROPOSITIONS.} \pagefirst{128} \noindent
\indent \textit{Summary of $\pmast$5.}
The present number consists chiefly of propositions of two sorts: (1) those which will be required as lemmas in one or more subsequent proofs, (2) those which are on their own account illustrative, or would be important in other developments than those that we wish to make. A few of the propositions of this number, however, will be used very frequently. These are:
\begin{flalign*} %5.1
	& \mathbf{\pmast5\pmcdot1}. \quad \pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot p \pmiff q & 
\end{flalign*}

\textit{I.e.}\ two propositions are equivalent if they are both true. (The statement that two propositions are equivalent if they are both false is $\pmast5\pmcdot21$.)
\begin{flalign*} %5.32
& \mathbf{\pmast5\pmcdot32}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmiff r \pmdott \pmiff \pmdott p \pmand q \pmdot \pmiff \pmdot p \pmand r & 
\end{flalign*}

\textit{I.e.}\ to say that, on the hypothesis $p$, $q$ and $r$ are equivalent, is equivalent to saying that the joint assertion of $p$ and $q$ is equivalent to the joint assertion of $p$ and $r$. This is a very useful rule in inference.
\begin{flalign*} %5.6
& \mathbf{\pmast5\pmcdot6}. \quad \pmthm \pmdottt p \pmand \pmnot q \pmdot \pmimp \pmdot r \pmdott \pmiff \pmdott p \pmdot \pmimp \pmdot q \pmor r & 
\end{flalign*}

\textit{I.e.}\ ``$p$ and not-$q$ imply $r$" is equivalent to ``$p$ implies $q$ or $r$."

Among propositions never subsequently referred to, but inserted for their intrinsic interest, are the following: $\pmast5\pmcdot11\pmcdot12\pmcdot13\pmcdot14$, which state that, given any two propositions $p$, $q$, either $p$ or $\pmnot p$ must imply $q$, and $p$ must imply either $q$ or not-$q$, and either $p$ implies $q$ or $q$ implies $p$; and given any third proposition $r$, either $p$ implies $q$ or $q$ implies $r$\footnote{Cf. Schr\"oder, \textit{Vorlesungen \"uber Algebra der Logik}, Zweiter Band (Leipzig, 1891), pp. 270--271, where the apparent oddity of the above proposition is explained.}.

Other propositions not subsequently referred to are $\pmast5\pmcdot22\pmcdot23\pmcdot24$; in these it is shown that two propositions are not equivalent when, and only when, one is true and the other false, and that two propositions are equivalent when, and only when, both are true or both false. It follows ($\pmast5\pmcdot24$) that the negation of ``$p \pmand q \pmdot \pmor \pmdot q \pmand \pmnot p$" is equivalent to ``$p \pmand q \pmdot \pmor \pmdot q \pmand \pmnot p$." $\pmast5\pmcdot54\pmcdot55$ state that both the product and the sum of $p$ and $q$ are equivalent, respectively, either to $p$ or to $q$.

The proofs of the following propositions are all easy, and we shall therefore often merely indicate the propositions used in the proofs.
\pmfd
\begin{flalign*} \pagefirst{129} %5.1 %5.11 %5.12 %5.13 %5.14
	& \mathbf{\pmast5\pmcdot1}. \;\;\quad \pmthm \pmdott p \pmand q \pmdot \pmimp \pmdot p \pmiff q & &[\pmast3\pmcdot4\pmcdot22]& \\
	& \mathbf{\pmast5\pmcdot11}. \quad \pmthm \pmdott p \pmimp q \pmdot \pmor \pmdot \pmnot p \pmimp q & &[\pmast2\pmcdot51\pmcdot54]& \\
	& \mathbf{\pmast5\pmcdot12}. \quad \pmthm \pmdott p \pmimp q \pmdot \pmor \pmdot p \pmimp \pmnot q & &[\pmast2\pmcdot52\pmcdot54]& \\
	& \mathbf{\pmast5\pmcdot13}. \quad \pmthm \pmdott p \pmimp q \pmdot \pmor \pmdot q \pmimp p & &[\pmast2\pmcdot5\pmcdot21]& \\
	& \mathbf{\pmast5\pmcdot14}. \quad \pmthm \pmdott p \pmimp q \pmdot \pmor \pmdot q \pmimp r & &[\text{Simp}\pmand\text{Transp}\pmand\pmast2\pmcdot21]& 
\end{flalign*}
\begin{flalign*} %5.15
& \mathbf{\pmast5\pmcdot15}. \quad \pmthm \pmdott p \pmiff q \pmdot \pmor \pmdot p \pmiff \pmnot q & 
\end{flalign*}
\pmdemi
\begin{flalign*} %5.15
	&& &\pmthm \pmdot \pmast4\pmcdot61 \pmdot & &\pmithm \pmdott \pmnot(p \pmimp q) \pmdot \pmimp \pmdot p \pmand \pmnot q \pmdot & && \\
	&& &[\pmast5\pmcdot1]& & \hspace{2.8cm} \pmimp \pmdot p \pmiff \pmnot q \pmdott& && \\
	&& &[\pmast2\pmcdot54] & &\pmithm \pmdott p \pmimp q \pmdot \pmor \pmdot p \pmiff \pmnot q & && (1) \\
	&& &\pmthm \pmdot \pmast4\pmcdot61 \pmdot & &\pmithm \pmdott \pmnot(q \pmimp p) \pmdot \pmimp \pmdot q \pmand \pmnot p \pmdot & && \\
	&& &[\pmast5\pmcdot1]& & \hspace{2.8cm} \pmimp \pmdot q \pmiff \pmnot p \pmdot& && \\
	&& &[\pmast4\pmcdot12]& & \hspace{2.8cm} \pmimp \pmdot p \pmiff \pmnot q \pmdott& && \\
	&& &[\pmast2\pmcdot54] & &\pmithm \pmdott q \pmimp p \pmdot \pmor \pmdot p \pmiff \pmnot q & && (2) \\
	&& &\pmthm\pmdot (1)\pmand(2) \pmand \pmast4\pmcdot41 \pmdot & &\pmithm \pmdot \pmprop & &&
\end{flalign*}
\begin{flalign*} %5.16
& \mathbf{\pmast5\pmcdot16}. \quad \pmthm \pmdot \pmnot(p \pmiff q \pmand p \pmiff \pmnot q) & 
\end{flalign*}
\pmdemi
\begin{flalign*} %5.16
&& &\pmthm \pmdot \pmast3\pmcdot26 \pmdot & &\pmithm \pmdott p \pmiff q \pmand p \pmimp \pmnot q \pmdot \pmimp \pmdot p \pmimp q \pmand p \pmimp \pmnot q \pmdot & && \\
&& &[\pmast4\pmcdot82]& & \hspace{3.7cm} \pmimp \pmdot \pmnot p & && (1) \\
&& &\pmthm \pmdot \pmast3\pmcdot27 \pmdot & &\pmithm \pmdott p \pmiff q \pmand p \pmimp \pmnot q \pmdot \pmimp \pmdot q \pmimp p \pmand p \pmimp \pmnot q \pmdot & && \\
&& &[\text{Syll}]& & \hspace{3.7cm} \pmimp \pmdot q \pmimp \pmnot q & && \\
&& &[\text{Abs}]& & \hspace{3.7cm} \pmimp \pmdot \pmnot q & && (2) \\
&& &\pmthm\pmdot (1)\pmand(2) \pmand \text{Comp} \pmdot & &\pmithm \pmdott p \pmiff q \pmand p \pmimp \pmnot q \pmdot \pmimp \pmdot \pmnot p \pmand \pmnot q \pmdot & && \\
&& &\pmSubb{\pmast4\pmcdot65}{q}{p}{p}{q}& & \hspace{3.7cm} \pmimp \pmdot \pmnot(\pmnot q \pmimp p) & && (3) \\
&& &\pmthm \pmdot (3) \pmand \text{Exp} \pmdot & &\pmithm \pmdottt p \pmiff q \pmdot \pmimp \pmdott p \pmimp \pmnot q \pmdot \pmimp \pmdot \pmnot(\pmnot q \pmimp p) \pmdott & && \\
&& &[\text{Id}\pmand(\pmast2\pmcdot01)] & &\hspace{3.7cm} \pmimp \pmdott \pmnot(p \pmimp \pmnot q) \pmdot \pmor \pmdot \pmnot(\pmnot q \pmimp p) \pmdott & && \\
&& &[\pmast4\pmcdot51\pmand(\pmast4\pmcdot01)] & &\hspace{3.7cm} \pmimp \pmdott \pmnot(p \pmiff \pmnot q)\pmdottt \pmithm \pmdot \pmprop & &&
\end{flalign*}
\begin{flalign*} %5.17
& \mathbf{\pmast5\pmcdot17}. \quad \pmthm \pmdott p \pmor q \pmand \pmnot(p \pmand q) \pmdot \pmiff \pmdot p \pmiff \pmnot q & 
\end{flalign*}
\pmdemi
\begin{flalign*} %5.17
&& &\pmthm \pmdot \pmast4\pmcdot64\pmcdot21 \pmdot & &\pmithm \pmdott p \pmor q \pmdot \pmiff \pmdot \pmnot q \pmimp p & && (1) \\
&& &\pmthm \pmdot \pmast4\pmcdot63 \pmand \text{Transp} \pmdot & &\pmithm \pmdott \pmnot(p \pmand q) \pmdot \pmimp \pmdot p \pmimp \pmnot q & && (2) \\
&& &\pmthm\pmdot (1)\pmand(2) \pmand \pmast4\pmcdot38\pmcdot21 \pmdot & &\pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} \pagefirst{130} %5.18 %5.19 %5.21 %5.22 %5.23 %5.24 %5.25
& \mathbf{\pmast5\pmcdot18}. \quad \pmthm \pmdott p \pmiff q \pmdot \pmiff \pmdot \pmnot(p \pmiff \pmnot q) & &\pmbr{\pmast5\pmcdot15\pmcdot16\pmand\pmSUbb{\pmast5\pmcdot17}{p \pmiff q}{p}{p \pmiff \pmnot q}{q}}& \\
& \mathbf{\pmast5\pmcdot19}. \quad \pmthm \pmnot(p \pmiff \pmnot p)  & &\pmbr{\pmSUb{\pmast5\pmcdot18}{p}{q}\pmand\pmast4\pmcdot2}& \\
& \mathbf{\pmast5\pmcdot21}. \quad \pmthm \pmdott \pmnot p \pmand \pmnot q \pmdot \pmimp \pmdot p \pmiff q & &[\pmast5\pmcdot1\pmand\pmast4\pmcdot11]& \\
& \mathbf{\pmast5\pmcdot22}. \quad \pmthm \pmdottt \pmnot(p \pmiff q) \pmdot \pmiff \pmdott p \pmand \pmnot q \pmdot \pmor \pmdot q \pmand \pmnot p & &[\pmast4\pmcdot61\pmcdot51\pmcdot39]& \\
& \mathbf{\pmast5\pmcdot23}. \quad \pmthm \pmdottt p \pmiff q \pmdot \pmiff \pmdott p \pmand q \pmdot \pmor \pmdot \pmnot p \pmand \pmnot q & &\pmbr{\pmast5\pmcdot18\pmand\pmSUb{\pmast5\pmcdot22}{\pmnot q}{q}\pmand\pmast4\pmcdot13\pmcdot36}& \\
& \mathbf{\pmast5\pmcdot24}. \quad \pmthm \pmdottt \pmnot(p \pmand q \pmdot \pmor \pmdot \pmnot p \pmand \pmnot q) \pmdot \pmiff \pmdott p \pmand \pmnot q \pmdot \pmor \pmdot q \pmand \pmnot p & &[\pmast5\pmcdot22\pmcdot23]& \\
& \mathbf{\pmast5\pmcdot25}. \quad \pmthm \pmdottt p \pmor q \pmdot \pmiff \pmdott p \pmimp q \pmdot \pmimp \pmdot q & &[\pmast2\pmcdot62\pmcdot68]&  
\end{flalign*}

From $\pmast5\pmcdot25$ it appears that we might have taken implication, instead of disjunction, as a primitive idea, and have defined ``$p \pmor q$" as meaning ``$p \pmimp q \pmdot \pmimp \pmdot q$." This course, however, requires more primitive propositions than are required by the method we have adopted.
\begin{flalign*} %5.3 %5.31 %5.32 
	& \mathbf{\pmast5\pmcdot3}. \;\;\quad \pmthm \pmdottt p \pmand q \pmdot \pmimp \pmdot r \pmdott \pmiff \pmdott p \pmand q \pmdot \pmimp \pmdot p \pmand r & &[\text{Simp}\pmand\text{Comp}\pmand\text{Syll}]& \\
	& \mathbf{\pmast5\pmcdot31}. \quad \pmthm \pmdottt r \pmand p \pmimp q \pmdott \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmand r & &[\text{Simp}\pmand\text{Comp}]& \\
	& \mathbf{\pmast5\pmcdot32}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmiff r \pmdott \pmiff \pmdott p \pmand q \pmdot \pmiff \pmdot p \pmand r & &[\pmast4\pmcdot76\pmand \pmast3\pmcdot3\pmcdot31 \pmand \pmast5\pmcdot3]& 
\end{flalign*}

This proposition is constantly required in subsequent proofs.
\begin{flalign*} %5.33 %5.35 %5.36 %5.4 %5.41 %5.42 %5.44 %5.5 %5.501 %5.53 %5.54 %5.55 %5.6 %5.61 %5.62 %5.63 %5.7
	& \mathbf{\pmast5\pmcdot33}. \quad \pmthm \pmdottt p \pmand q \pmimp r \pmdot \pmiff \pmdott p \pmandd p \pmand q \pmdot \pmimp \pmdot r & &[\pmast4\pmcdot73\pmcdot84\pmand\pmast5\pmcdot32]& \\
	& \mathbf{\pmast5\pmcdot35}. \quad \pmthm \pmdottt p \pmimp q \pmand p \pmimp r \pmdot \pmimp \pmdott p \pmdot \pmimp \pmdot q \pmiff r & &[\text{Comp}\pmand\pmast5\pmcdot1]& \\
	& \mathbf{\pmast5\pmcdot36}. \quad \pmthm \pmdott p \pmand p \pmiff q \pmdot \pmiff \pmdot q \pmand p \pmiff q & &[\text{Ass}\pmand\pmast4\pmcdot38]& \\
	& \mathbf{\pmast5\pmcdot4}. \;\;\quad \pmthm \pmdottt p \pmdot \pmimp \pmdot p \pmimp q \pmdott \pmiff \pmdot p \pmimp q & &[\text{Simp}\pmand\pmast2\pmcdot43]& \\
	& \mathbf{\pmast5\pmcdot41}. \quad \pmthm \pmdottt p \pmimp q \pmdot \pmimp \pmdot p \pmimp r \pmdott \pmiff \pmdott p \pmdot \pmimp \pmdot q \pmimp r & &[\pmast2\pmcdot77\pmcdot86]& \\
	& \mathbf{\pmast5\pmcdot42}. \quad \pmthm \pmdotttt p \pmdot \pmimp \pmdot q \pmimp r \pmdott \pmiff \pmdottt p \pmdot \pmimp \pmdott q \pmdot \pmimp \pmdot p \pmand r  & &[\pmast5\pmcdot3\pmand\pmast4\pmcdot87]& \\
	& \mathbf{\pmast5\pmcdot44}. \quad \pmthm \pmdotttt p \pmimp q \pmdot \pmimp \pmdottt p \pmimp r \pmdot \pmiff \pmdott p \pmdot \pmimp \pmdot q \pmand r & &[\pmast4\pmcdot76\pmand\pmast5\pmcdot3\pmcdot32]& \\
	& \mathbf{\pmast5\pmcdot5}. \;\;\quad \pmthm \pmdottt p \pmdot \pmimp \pmdott p \pmimp q \pmdot \pmiff \pmdot q & &[\text{Ass}\pmand\text{Exp}\pmand\text{Simp}]&  \\ %[\text{Ass}\pmand\text{Ass}\pmand\text{Ass}]
	& \mathbf{\pmast5\pmcdot501}. \hspace{.2cm} \pmthm \pmdottt p \pmdot \pmimp \pmdott q \pmdot \pmiff \pmdot p \pmiff q & &[\pmast5\pmcdot1\pmand\text{Exp}\pmand\text{Ass}]& \\
	& \mathbf{\pmast5\pmcdot53}. \quad \pmthm \pmdottt p \pmor q \pmor r \pmdot \pmimp \pmdot s \pmdott \pmiff \pmdott p \pmimp s \pmand q \pmimp s \pmand r \pmimp s & &[\pmast4\pmcdot77]& \\
	& \mathbf{\pmast5\pmcdot54}. \quad \pmthm \pmdottt p \pmand q \pmdot \pmiff \pmdot p \pmdott \pmor \pmdott p \pmand q \pmdot \pmiff \pmdot q & &[\pmast4\pmcdot73\pmand\pmast4\pmcdot44 \pmand \text{Transp} \pmand \pmast5\pmcdot1]& \\
	& \mathbf{\pmast5\pmcdot55}. \quad \pmthm \pmdottt p \pmor q \pmdot \pmiff \pmdot p \pmdott \pmor \pmdott p \pmor q \pmdot \pmiff \pmdot q & &[\pmast1\pmcdot3\pmand\pmast5\pmcdot1\pmand\pmast4\pmcdot74]& \\
	& \mathbf{\pmast5\pmcdot6}. \;\;\quad \pmthm \pmdottt p \pmand \pmnot q \pmdot \pmimp \pmdot r \pmdott \pmiff \pmdott p \pmdot \pmimp \pmdot q \pmor r & &\pmbr{\pmSUb{\pmast4\pmcdot87}{\pmnot q}{q} \pmand \pmast4\pmcdot64\pmcdot85}&  \\
	& \mathbf{\pmast5\pmcdot61}. \quad \pmthm \pmdott p \pmor q \pmand \pmnot q \pmdot \pmiff \pmdot p \pmand \pmnot q & &[\pmast4\pmcdot74\pmand \pmast5\pmcdot32]&  \\
	& \mathbf{\pmast5\pmcdot62}. \quad \pmthm \pmdott p \pmand q \pmdot \pmor \pmdot \pmnot q \pmdott \pmiff \pmdot p \pmor \pmnot q & &\pmSubb{\pmast4\pmcdot7}{q}{p}{p}{q} & \\
	& \mathbf{\pmast5\pmcdot63}. \quad \pmthm \pmdottt p \pmor q \pmdot \pmiff \pmdott p \pmdot \pmor \pmdot \pmnot p \pmand q & &\pmSubb{\pmast5\pmcdot62}{\pmnot p}{q}{q}{p}& \pagefirst{131} \\
	& \mathbf{\pmast5\pmcdot7}. \;\;\quad \pmthm \pmdottt p \pmor r \pmdot \pmiff \pmdot q \pmor r \pmdott \pmiff \pmdott r \pmdot \pmor \pmdot p \pmiff q & &[\pmast4\pmcdot74\pmand\pmast1\pmcdot3\pmand\pmast5\pmcdot1\pmand\pmast4\pmcdot37]&  
\end{flalign*} 
\begin{flalign*} %5.71
	& \mathbf{\pmast5\pmcdot71}. \quad \pmthm \pmdottt q \pmimp \pmnot r \pmdot \pmimp \pmdott p \pmor q \pmand r \pmdot \pmiff \pmdot p \pmand r & 
\end{flalign*}

In the following proof, as always henceforth, ``$\pmhp$" means the hypothesis of the proposition to be proved.

\pmdemi
\begin{flalign*} %5.71
	&& &\pmthm \pmdot \pmast4\pmcdot4 \pmdot & &\pmithm \pmdottt p \pmor q \pmand r \pmdot \pmiff \pmdott p \pmand r \pmdot \pmor \pmdot q \pmand r  & && (1) \\
	&& &\pmthm \pmdot \pmast4\pmcdot62\pmcdot51 \pmdot & &\pmithm \pmdotttt \pmhp \pmdot \pmimp \pmdottt \pmnot(q \pmand r) \pmdottt & && \\
	&& &[\pmast4\pmcdot71]& &\hspace{1.825cm} \pmimp \pmdottt p \pmand r \pmdot \pmor \pmdot q \pmand r \pmdott \pmiff \pmdott p \pmand r & && (2) \\
	&& &\pmthm\pmdot (1)\pmand(2) \pmand \pmast4\pmcdot22 \pmdot & &\pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} %5.74
& \mathbf{\pmast5\pmcdot74}. \quad \pmthm \pmdottt p \pmdot \pmimp \pmdot q \pmiff r \pmdott \pmiff \pmdott p \pmimp q \pmdot \pmiff \pmdot p \pmimp r & 
\end{flalign*}
\pmdemi
\begin{flalign*} %5.74
&& &\pmthm \pmdot \pmast5\pmcdot41 \pmdot & &\pmithm \pmdotttt p \pmimp q \pmdot \pmimp \pmdot p \pmimp r \pmdott \pmiff \pmdott p \pmdot \pmimp \pmdot q \pmimp r \pmanddd p \pmimp r \pmdot \pmimp \pmdot p \pmimp q \pmdott \pmiff \pmdott p \pmdot \pmimp \pmdot r \pmimp q  & && (1) \\
&& &\pmthm \pmdot (1) \pmand \pmast4\pmcdot38 \pmdot & &\pmithm \pmdotttt p \pmimp q \pmdot \pmiff \pmdot p \pmimp r \pmdot \pmiff \pmdottt p \pmdot \pmimp \pmdot q \pmimp r \pmandd p \pmdot \pmimp \pmdot r \pmimp q \pmdottt & && \\
&& &[\pmast4\pmcdot76]& &\hspace{4.125cm} \pmiff \pmdottt p \pmdot \pmimp \pmdot q \pmiff r \pmdotttt \pmithm \pmdot \pmprop & && 
\end{flalign*}
\begin{flalign*} %5.75
& \mathbf{\pmast5\pmcdot75}. \quad \pmthm \pmdottt r \pmimp \pmnot q \pmandd p \pmdot \pmiff \pmdot q \pmor r \pmdott \pmimp \pmdott p \pmand \pmnot q \pmdot \pmiff \pmdot r & 
\end{flalign*}
\pmdemi
\begin{flalign*} %5.75
&& &\pmthm \pmdot \pmast5\pmcdot6 \pmdot & &\pmithm \pmdottt \pmhp \pmdot \pmimp \pmdott p \pmand \pmnot q \pmdot \pmimp \pmdot r  & && (1) \\
&& &\pmthm \pmdot \pmast3\pmcdot27 \pmdot & &\pmithm \pmdottt \pmhp \pmdot \pmimp \pmdott q \pmor r \pmdot \pmimp \pmdot p \pmdott & && \\
&& &[\pmast4\pmcdot77]& &\hspace{1.825cm} \pmimp \pmdott r \pmimp p & && (2) \\
&& &\pmthm \pmdot \pmast3\pmcdot26 \pmdot & &\pmithm \pmdottt \pmhp \pmdot \pmimp \pmdott r \pmimp \pmnot q  & && (3) \\
&& &\pmthm \pmdot (2) \pmand (3) \pmand \text{Comp} \pmdot & &\pmithm \pmdottt \pmhp \pmdot \pmimp \pmdott r \pmimp p \pmand r \pmimp \pmnot q \pmdott & && \\
&& &[\text{Comp}]& &\hspace{1.825cm} \pmimp \pmdott r \pmdot \pmimp \pmdot p \pmand \pmnot q & && (4) \\
&& &\pmthm\pmdot (1)\pmand(4) \pmand \text{Comp} \pmdot & &\pmithm \pmdottt \pmhp \pmdot \pmimp \pmdott p \pmand \pmnot q \pmdot \pmiff \pmdot r \pmdottt \pmithm \pmdot \pmprop & && 
\end{flalign*}
\end{document}